{"meta":{"title":"伊成个人站-热衷于技术分享，源码分享的个人网站","subtitle":"伊成个人站","description":"伊成个人站 www.devcheng.net 一个致力于技术分享，源码分享及工作经历分享的个人网站","author":"伊成","url":"http://www.devcheng.net"},"pages":[{"title":"关于","date":"2018-12-04T04:47:13.000Z","updated":"2022-12-16T03:15:26.049Z","comments":false,"path":"about/index.html","permalink":"http://www.devcheng.net/about/index.html","excerpt":"","text":"关于博主博主是一名Java码农。虽然还未走上人生巅峰，但是一直保持着一个码农的自我修养。用一句话概括博主：每天瞎逼忙，还没赚到钱。但是博主有一颗分享技术的心，我会尽量用通俗易懂的方式，分享个人的知识。 关于网站网站的宗旨就是分享知识，分享技术，不一定高深，但一定是博主用心写作而成的。所有人都是从0开始起步，在学习过程中，会遇到各种困难，这个时候如果可以借鉴别人的经验，会让我们省力不少，希望本网站也能帮助到你。 关于写码 Happy Coding ❤︎"}],"posts":[{"title":"Dockerfile构建SpringBoot镜像并推送到docker公共镜像仓库Dockerhub","slug":"Dockerfile构建SpringBoot镜像并推送到docker公共镜像仓库Dockerhub","date":"2023-04-29T06:44:43.000Z","updated":"2023-04-29T06:56:55.386Z","comments":false,"path":"post/7b83f9aa.html","link":"","permalink":"http://www.devcheng.net/post/7b83f9aa.html","excerpt":"","text":"写在前面前期准备工作主要有：准备好必要的环境，确保安装了docker，以及有一个Spring boot项目。 1tips：本文所有操作均在宿主机上的 VMware (centos 7)中进行. 使用Dockerfile构建SpringBoot镜像1.新建一个文件夹 1mkdir /yicheng/passwordGenerator/ 2.把Spring boot项目打包成jar放在此目录下，并且新建文件Dockerfile 12345678910111213# 使用Java8FROM java:8# 作者MAINTAINER yicheng# VOLUME 指定临时文件目录为/tmp，在主机/var/lib/docker目录下创建了一个临时文件并链接到容器的/tmpVOLUME /tmp# 将jar包添加到容器中并更名ADD passwordGenerator-0.0.1-SNAPSHOT.jar pwdGenerator_docker.jar# 运行jar包RUN bash -c &apos;touch /pwdGenerator_docker.jar&apos;ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/pwdGenerator_docker.jar&quot;]#暴露8889端口作为微服务EXPOSE 8999 12[root@localhost passwordGenerator]# lsDockerfile passwordGenerator-0.0.1-SNAPSHOT.jar 3.开始构建镜像 1docker build -t pwdgenerator_docker:1.0 . 主要镜像名不能大写！ 4.运行镜像 1docker run -d -p 8080:8080 【容器id】 123456789101112131415[root@localhost passwordGenerator]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 7d229f7ebdd4 33 minutes ago 680MBpwdgenerator_docker 1.0 e6c6bbfe9344 33 minutes ago 680MBneosmemo/memos latest 322df040d768 11 days ago 36MBtomcat latest 6dd589e60602 6 months ago 474MBdataengine_docker 1.0 3080d43f20c2 8 months ago 853MBmysql 5.7 3147495b3a5c 9 months ago 431MBnacos/nacos-server 1.4.2 938169b118c7 24 months ago 956MBportainer/portainer latest 980323c8eb3f 2 years ago 196MBredis 5.0.9-alpine 4e5490070cce 2 years ago 29.2MBredis 6.0.8 16ecd2772934 2 years ago 104MBjava 8 d23bdf5b1b1b 6 years ago 643MB[root@localhost passwordGenerator]#[root@localhost passwordGenerator]# docker run -d -p 8999:8999 7d229f7ebdd4 到此我们完成了第一个小目标，使用Dockerfile构建SpringBoot镜像并且成功的运行了。 发布镜像到Docker-hub1.访问 https://hub.docker.com 注册账号，这里的用户名和密码一定要记住了，后续需要。 2.登录docker-hub,输入用户名和密码 123456789[root@localhost passwordGenerator]# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one.Username: 输入你的用户名Password:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded 3.提交镜像至Docker-hub命令：docker push / : 12345678910111213[root@localhost passwordGenerator]# docker push yicheng2023/pwdgenerator:1.0The push refers to repository [docker.io/yicheng2023/pwdgenerator]f6462cee0153: Pusheddd456a172e38: Pushed35c20f26d188: Mounted from library/javac3fe59dd9556: Mounted from library/java6ed1a81ba5b6: Mounted from library/javaa3483ce177ce: Mounted from library/javace6c8756685b: Mounted from library/java30339f20ced0: Mounted from library/java0eb22bfb707d: Mounted from library/javaa2ae92ffcd29: Mounted from library/java1.0: digest: sha256:273386989c0f4cf97842dc0cf3187ab2788564528cd642cbd11159c6693636fc size: 2424 到此就完成了将镜像推送到Docker-hub公共仓库的所有步骤。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Dockerfile","slug":"Dockerfile","permalink":"http://www.devcheng.net/tags/Dockerfile/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"docker开启和关闭容器自启动","slug":"docker开启和关闭容器自启动","date":"2023-04-29T06:40:12.000Z","updated":"2023-04-29T06:43:24.928Z","comments":false,"path":"post/50c46cfa.html","link":"","permalink":"http://www.devcheng.net/post/50c46cfa.html","excerpt":"","text":"简单记录一下，docker中开启和关闭容器自启动两种情况的命令。 开启容器的自启动1.在docker启动容器时可以增加参数。1docker run --restart=always 2.容器已经启动但是没有开启自启动,可以通过update命令进行修改。1docker update --restart=always &lt;CONTAINER ID&gt; 关闭容器的自启动1.关闭一个容器的自启动1docker update --restart=no &lt;CONTAINER ID&gt; 2.关闭所有容器的自启动1docker update --restart=no $(docker ps -q) The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"docker容器自启动","slug":"docker容器自启动","permalink":"http://www.devcheng.net/tags/docker容器自启动/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"2023年金三银四怎么不见了？","slug":"2023年金三银四怎么不见了？","date":"2023-03-16T05:03:06.000Z","updated":"2023-03-16T05:08:38.552Z","comments":true,"path":"post/408b0414.html","link":"","permalink":"http://www.devcheng.net/post/408b0414.html","excerpt":"","text":"写在前面不少人都应该发现了今年的工作不是很好找，无论是什么行业什么岗位都比之前难找了。往年的金三银四怎么不见了呢，前段时间还和朋友聊天说到，去年疫情大家几乎都被感染过了一次，今年疫情逐渐好转了许多。年后应该会好找一点，可结果却不是这样的情况。 工作难找现状在各种招聘软件投简历基本都是石沉大海的结果，回复的寥寥无几。新开的岗位分分钟都可以收到上百份简历。 2023年有1150万的应届大学毕业生要找工作；各行各业都不景气，很多企业都在大幅裁员；物价在不断上涨等多方面原因。 2022年上半年，就有46万家企业倒闭，113万家个体工商户注销，现在的生意是越来越难做了。而即使各地放开了对疫情的防控措施，现在老百姓也都不敢去人流较多的商店或超市，所以逛街的人也越来越少。 如今很多家庭面临投资困境：一边是通货膨胀越来越厉害，另一边是银行存款利率越来越低，而各类理财品种的风险却在不断的上升。这就意味着，如果你把钱存在银行里面，就要面对货币贬值。 而如果你把资金购买股票、基金、银行理财、期权等高收益投资品，却很可能面临资产缩水的风险，投资者真的不知道该怎么办？ 国内物价上涨的原因，除了输入性通胀之外，还有就是我国央行的货币政策的持续宽松，当然，也有受疫情影响，社会生产能力减弱等因素。 现在老百姓深感生活支出成本上升了，而物价上涨的情况在2023年还将会继续。 结束语金三银四看来今年不存在的，各位还是不要裸辞的好","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"工作","slug":"工作","permalink":"http://www.devcheng.net/tags/工作/"},{"name":"金三银四","slug":"金三银四","permalink":"http://www.devcheng.net/tags/金三银四/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"基于SpringBoot开发的垃圾分类回收管理系统源码分享","slug":"基于SpringBoot开发的垃圾分类回收管理系统源码分享","date":"2023-03-06T12:04:50.000Z","updated":"2023-03-06T12:09:35.525Z","comments":true,"path":"post/2a7e1341.html","link":"","permalink":"http://www.devcheng.net/post/2a7e1341.html","excerpt":"","text":"写在前面本项目是基于Spring Boot 2.x 开发的垃圾分类回收管理系统。本项目也可以当作毕业设计，期末课程作业等，也可以当作学习、进阶Spring Boot 的资料。 功能描述本项目分为三种角色，分别为 超级管理员，管理员和员工。不同的角色享有不同的权限。 员工管理模块 管理员管理模块 个人信息模块 在库垃圾查询模块 垃圾去向模块 公告管理模块 垃圾回收模块 … 开发环境（运行环境） 系统环境：Windows 11 开发工具：IntelliJ IDEA 2020.3 Java版本：JDK 1.8 Mysql版本：5.7 Maven版本：3.6.3 项目技术栈 Spring Boot 2.3.4.RELEASE Mybatis Maven 3.X Mysql layui Jquery … 登录地址项目访问路径：http://localhost:8085 超级管理员 用户名 / 密码 18612341234 / asdfghjk 管理员 用户名 / 密码 17859865548 / asdfghjk 员工 用户名 / 密码 13055879915 / 12345678 项目截图 项目演示视频链接: https://pan.baidu.com/s/1cxmMqstpxiu1--elpNGXfg 提取码: xkmy 联系我们如有需要源码可以通过QQ 搜索：792435323联系我！请备注：垃圾分类源码 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的DemoApplication直接运行吧！ 其它说明白嫖怪，伸手党 请绕道！！！ The end.","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"垃圾分类系统","slug":"垃圾分类系统","permalink":"http://www.devcheng.net/tags/垃圾分类系统/"},{"name":"垃圾分类回收管理系统","slug":"垃圾分类回收管理系统","permalink":"http://www.devcheng.net/tags/垃圾分类回收管理系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"springboot项目对数据库密码加解密","slug":"springboot项目对数据库密码加解密","date":"2023-02-18T01:41:46.000Z","updated":"2023-02-18T01:59:09.296Z","comments":true,"path":"post/1663aa3c.html","link":"","permalink":"http://www.devcheng.net/post/1663aa3c.html","excerpt":"","text":"写在前面我相信大多数人在配置文件中都是以明文的形式配置数据库的用户名和密码的，如下展示： 12345// 明文形式spring.datasource.mysql.jdbc-url=jdbc:mysql://127.0.0.1:3306/data?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai&amp;allowMultiQueries=truespring.datasource.mysql.driverClassName=com.mysql.cj.jdbc.Driverspring.datasource.mysql.username=rootspring.datasource.mysql.password=123456 显然这样配置不是很安全，所以我们可以对用户名和密码进行加密，这样配置后需要进行解密才知道我们配置的用户名和密码具体是什么。 接下来跟着步骤 do it 步骤第一步 添加引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 第二步 制定私钥和生成对应的加密串在你的配置文件中配置好你的私钥字符串1jasypt.encryptor.password=私钥字符串 第一步完成后找到对应依赖文件夹里面 org\\jasypt\\jasypt\\1.9.2&gt;进行加密操作 123C:\\Users\\usmart\\.m2\\repository\\org\\jasypt\\jasypt\\1.9.2&gt;java -cp jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=&quot;root&quot; password=data algorithm=PBEWithMD5AndDES input 里面就是你要加密的字符串 password 就是你的私钥字符串 algorithm=PBEWithMD5AndDES 固定的不需要改 解密命令 （一般不需要）1234567891011121314151617C:\\Users\\usmart\\.m2\\repository\\org\\jasypt\\jasypt\\1.9.2&gt;java -cp jasypt-1.9.2.jar org.jasypt.intf.cli.JasyptPBEStringDecryptionCLI input=&quot;ri60tsMfnqk+usK+nXjQuQ==&quot; password=data algorithm=PBEWithMD5AndDES----ENVIRONMENT-----------------Runtime: Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 25.271-b09----ARGUMENTS-------------------algorithm: PBEWithMD5AndDESinput: ri60tsMfnqk+usK+nXjQuQ==password: data----OUTPUT----------------------root 到这里就结束了，两步就搞定了。 The end","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://www.devcheng.net/tags/springboot/"},{"name":"数据库加密解密","slug":"数据库加密解密","permalink":"http://www.devcheng.net/tags/数据库加密解密/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"IDEA 高频实用快捷键","slug":"IDEA-高频实用快捷键","date":"2022-12-16T02:27:13.000Z","updated":"2022-12-16T02:34:52.633Z","comments":true,"path":"post/8666c7d8.html","link":"","permalink":"http://www.devcheng.net/post/8666c7d8.html","excerpt":"","text":"写在前面最近翻阅之前的笔记，重新整理了一番。把IDEA中比较高频实用的快捷键重新整理了一下，自己备忘记录一下。 IDEA高频实用快捷键Ctrl + Alt + O : 移除未使用的包可能会和QQ 屏幕识图快捷键冲突，解决方法可重新自定义QQ快捷键。 Ctrl + Alt + M：重构函数:将选中代码提取为函数Ctrl + Alt + L：代码格式化可能会和QQ 中的快捷键冲突，解决方法可重新自定义QQ快捷键。 Ctrl + Alt + T：可以把代码包在一个块内，例如：try/catchCtrl + Alt + B：定位至选中类或者方法的具体实现Ctrl + Shift + F：全局查找快捷键Ctrl + Shift + R：全局替换Ctrl + Shift + U：大小写切换Ctrl + Shift + /：使用 /**/ 注释Ctrl + /：使用 // 注释Ctrl + X（Ctrl + Y）：删除行Ctrl + D：复制行Ctrl+Shift+Alt+J：批量修改变量快捷键F2 或 Shift+F2：快速定位高亮错误或警告Shift+Click：可以关闭文件 如果还有什么其他高频实用的快捷键，欢迎留言，我看到后会持续更新补充进来~ The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"IDEA快捷键","slug":"IDEA快捷键","permalink":"http://www.devcheng.net/tags/IDEA快捷键/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MYSQL中如何调用存储过程","slug":"MYSQL中如何调用存储过程","date":"2022-11-24T02:17:03.000Z","updated":"2022-11-24T02:33:26.367Z","comments":true,"path":"post/c68e4207.html","link":"","permalink":"http://www.devcheng.net/post/c68e4207.html","excerpt":"","text":"背景最近公司有一个需求每天晚上定时需要往某个表里面插入一条汇总数据。解决方案有几个，可以通过编写代码添加一个定时任务接口；还有一个则可以利用MYSQL中的定时调度存储过程解决，其实两种方案都可以，这里我选择的是 MYSQL 定时调用 存储过程。 具体实现过程1.先看看定时器的状态，执行如下命令： 1show VARIABLES LIKE &apos;%sche%&apos;; event_scheduler : OFF 代表没有开启。这里需要执行以下命令开启： 1SET GLOBAL event_scheduler = 1; 2.编写存储过程，格式如下： 123456-- 存储过程 CREATE PROCEDURE 存储过程名() BEGIN -- 这里编写你的业务逻辑SQL END; 3.测试写好的存储过程 1call 存储过程名 4.开启事件，定时调用 123create event 事件名on schedule EVERY 1 DAY STARTS &apos;2022-11-10 23:51:00&apos; -- 执行时间 do call 存储过程名; 到此，完整流程就是以上这些了。最后附上我的完整SQL，供参考。 12345678910111213141516171819202122232425-- 查看定时器的状态show VARIABLES LIKE &apos;%sche%&apos;;-- 开启SET GLOBAL event_scheduler = 1;-- 存储过程 CREATE PROCEDURE saveTownActiveRateSortDataDaily() BEGIN set @sumactivenums =(select sum(activenums) from t_table_town_active_rate_sort_data); set @sumbicyclenums =(select sum(bicyclenums) from t_table_town_active_rate_sort_data); set @cnt = (SELECT DATE_FORMAT(SYSDATE(),&apos;%Y-%m-%d %H:%i:%s&apos;)); insert into t_table_bicycle_diagram_info(sum_active_num,sum_bicycle_num,insert_date) VALUES (@sumactivenums, @sumbicyclenums, @cnt); END;-- 调用call saveTownActiveRateSortDataDaily-- 开启事件，定时调用create event save_dataon schedule EVERY 1 DAY STARTS &apos;2022-11-10 23:51:00&apos;do call saveTownActiveRateSortDataDaily(); The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"http://www.devcheng.net/tags/MYSQL/"},{"name":"定时调用存储过程","slug":"定时调用存储过程","permalink":"http://www.devcheng.net/tags/定时调用存储过程/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于Spring Boot开发的酒店管理系统","slug":"基于Spring-Boot开发的酒店管理系统","date":"2022-11-22T06:43:51.000Z","updated":"2022-11-22T06:57:25.764Z","comments":true,"path":"post/cc09a51.html","link":"","permalink":"http://www.devcheng.net/post/cc09a51.html","excerpt":"","text":"本项目是基于Spring Boot 2.x 开发的，酒店管理系统分三种角色：经理（管理员）和员工（普通用户）两种用户， 其中经理（管理员）具有查看所有预定、删除客房、查看员工、添加员工等功能权限 员工（普通用户）具有查看空房、客户预订、修改预订、删除预订、注册新客户等功能权限。 大体流程如下： 1.经理（系统管理员）设置客房状态并且设置每晚价格。 2.客户可以通过员工预定房间，或者自己预定房间，并且可以选择预定时间（包含钟点房） 3.当客户退房后，通知保洁员进行卫生打扫，保洁员确定卫生情况后，客房重新变为可预定，并且密码重新随机生成 5.老板可以设置经理，员工，保洁员的工资，根据业绩比例进行分配 主要功能预订管理 添加客房的预订，当客房被预定后，在预订时间到之前均显示不可用。 删除客人的预订，当客人取消预定,或者到达预定保留时间后，要求取消预定。在前台管理人员确定后,系统将已经预订的房间改为空房。 更改预定状态，当客人在规定的时间范围内到达，由管理员将客人所定房间的状态改为有人。 订房管理 房间查询，查询房间的状态(包括房间是否为空，以及房间的类型)。 分配房间，根据查询的结果，以及客人的要求，将空房改为占用状态,并确认房间的类型。 结账，先结账后付钱的客人先记录在系统中，在付钱后将纪录状态改为已经付帐。 退房等。 客房管理 客房退房后，保洁阿姨打扫完房间后可设置已打扫。 财务管理 收入和房间数的统计。 人事管理 员工信息管理，包括员工工资、提成等 开发环境（运行环境） 系统环境：Windows 11 开发工具：IntelliJ IDEA 2020.3 Java版本：JDK 1.8 Mysql版本：5.7 Maven版本：3.6.3 项目技术栈 Spring Boot 2.0.X.RELEASE Bootstrap Maven 3.X Mysql thymeleaf js Jquery … 登录地址访问路径：http://localhost:8088 管理员账号/密码： admin / admin 员工账号/密码：tom@jiudian.com/ 123456 保洁员账号/密码：zhangyi@clean.com/ 123456 项目演示视频链接: https://pan.baidu.com/s/12qd637UuboPqVMi_1Iyjeg?pwd=m6md 提取码: m6md 项目截图 联系我们如有需要源码可以通过QQ 搜索：792435323联系我！请备注：酒店源码 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的ManageApplication直接运行吧！ 其它说明白嫖怪（伸手党）请绕道！ The end.","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"酒店管理系统","slug":"酒店管理系统","permalink":"http://www.devcheng.net/tags/酒店管理系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"SpringBoot统计接口请求耗时","slug":"SpringBoot统计接口请求耗时","date":"2022-11-19T12:24:22.000Z","updated":"2022-11-24T02:20:27.064Z","comments":true,"path":"post/789179de.html","link":"","permalink":"http://www.devcheng.net/post/789179de.html","excerpt":"","text":"写在前面接口请求时间的快慢就代表着获取到对应的数据的快慢，也代表着用户请求页面数据的快慢，常常可以借助接口请求快慢进行相应的优化！ 以往我们的做法可能是在每一个接口的方法中的开始添加当前时间，结尾用当前时间减去开始时间就表示该接口的访问时间。 具体代码如下： 1234567@RequestMapping(\"/test\")public String test()&#123; long startTime = System.currentTimeMillis(); //此处的调用业务代码省略 System.out.println(\"访问时间为：\"+(System.currentTimeMillis()-startTime)); return \"访问接口成功\";&#125; 那如果有几百个接口的话，每一个接口都需要统计对应的访问时间的话，那就要写几百遍，这很不符合我们的常理，所以有没有一种办法是可以不修改对应的接口方法，并且只需要写一遍就能够应用到所有的接口上面或者指定的接口上面。 我们第一时间就可以想到AOP技术，AOP是在Spring当中比较常见的技术， AOP就是在不修改原来的代码就可以对接口方法进行增强的作用，利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 解决方案根据上述，我们需要到AOP,第一个不能少的则是对应的依赖。 引入对应依赖123456&lt;!--aspectj--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;version&gt;2.7.4&lt;/version&gt;&lt;/dependency&gt; 自定义注解统计接口的耗时和访问次数也不需要每一个接口都使用，比如说一些不经常访问的接口就没有统计他的访问次数，所以我们可以自定义一个注解，只要对应的接口方法上应用了这个注解，Spring会进行扫描，并执行对应的统计耗时操作即可。 1234567891011121314151617import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * 统计 方法/接口耗时 注解 * * @author devcheng */@Documented@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface CostTime &#123;&#125; 定义AOP切面如果接口方法上应用了自定义的注解，那么就会被Spring扫描到，这里我用的是 @Pointcut 和 @Around 配合使用。 123456789101112131415161718192021222324252627282930313233343536373839404142import lombok.extern.slf4j.Slf4j;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;/** * 统计 方法/接口耗时 注解 * * @author devcheng */@Aspect@Component@Slf4jpublic class CostTimeAspect &#123; @Pointcut(value = \"@annotation(net.devcheng.www.data.annotation.CostTime)\") public void costTime() &#123; &#125; @Around(\"costTime()\") public Object costTimeAround(ProceedingJoinPoint joinPoint) &#123; Object obj = null; try &#123; long beginTime = System.currentTimeMillis(); obj = joinPoint.proceed(); //获取方法名称 String method = joinPoint.getSignature().getName(); //获取类名称 String className=joinPoint.getSignature().getDeclaringTypeName(); //计算耗时 long cost = System.currentTimeMillis() - beginTime; log.error(\"类:[&#123;&#125;]，方法:[&#123;&#125;] 接口耗时:[&#123;&#125;]\", className,method, cost + \"毫秒\"); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; return obj; &#125;&#125; 使用用在统计接口上123456789@GetMapping(\"/V4/getSignsPredictDetail\")@ResponseBody@CostTimepublic String getSignsPredictDetail(String name) &#123; if (StringUtils.isEmpty(name)) &#123; return \"[]\"; &#125; return cityBrain4Service.getSignsPredictDetailByName(name);&#125; 用在统计定时任务上12345@Scheduled(cron = \"55 */5 * * * ?\")@CostTimepublic void scenesSignTask() &#123; // 业务逻辑&#125; 运行输出12342022-11-18 10:31:51.523 [http-nio-8886-exec-8] ERROR net.devcheng.www.data.config.CostTimeAspect Line:32 - 类:[net.devcheng.www.data.controller.SpecialInterfaceController]，方法:[getWeather] 接口耗时:[0毫秒]2022-11-18 10:31:52.122 [http-nio-8886-exec-9] ERROR net.devcheng.www.data.config.CostTimeAspect Line:32 - 类:[net.devcheng.www.data.controller.SpecialInterfaceController]，方法:[getWeather] 接口耗时:[1毫秒]2022-11-18 10:31:55.073 [http-nio-8886-exec-15] ERROR net.devcheng.www.data.config.CostTimeAspect Line:32 - 类:[net.devcheng.www.data.controller.CityBrain4Controller]，方法:[getScrollingMessages] 接口耗时:[2毫秒]2022-11-18 10:31:55.076 [http-nio-8886-exec-3] ERROR net.devcheng.www.data.config.CostTimeAspect Line:32 - 类:[net.devcheng.www.data.controller.SpecialInterfaceController]，方法:[getWeather] 接口耗时:[1毫秒] The end","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.devcheng.net/tags/SpringBoot/"},{"name":"接口耗时统计","slug":"接口耗时统计","permalink":"http://www.devcheng.net/tags/接口耗时统计/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"努力做一个“不要脸”的人","slug":"努力做一个“不要脸”的人","date":"2022-09-04T07:16:49.000Z","updated":"2022-09-04T07:29:05.526Z","comments":true,"path":"post/633a5847.html","link":"","permalink":"http://www.devcheng.net/post/633a5847.html","excerpt":"","text":"“你的脸还在脸上，有的人脸能放在兜里，有的人脸能撂在地下。” 这是我给一个小兄弟的建议：出来混，别太把脸当回事。当你放下面子去搞钱的时候，说明你成熟了；当你用钱挣回面子的时候，说明你成长了。 “不要脸”是一种境界人生的三种境界：第一，太要脸；第二，脸皮厚；第三，不要脸。 本文聊的不要脸，并非不知羞耻，指的是放下你的面子。面子是不能当饭吃的，这个世界上最不值钱的，就是所谓的面子。 比尔盖茨在一次大学毕业典礼上，讲过这样一句话：“这个世界不会在乎你的自尊，你必须先有所成就，然后再去强调自己的感受。” 乔布斯生前也说过一句很著名的话：“我特别喜欢和聪明人在一起工作，因为最大的好处是不用考虑他们的尊严。” 面子是无能者维护自己的盾牌。 你见没见过有的人明明知道自己错了，为了面子他就是死活不承认。 聪明人更关注自己的成长，他会保持开放的心态，而不是捍卫自己的面子，不是过度的自我防卫，想方设法证明“我没错”。 做到“不要脸”其实不容易，你必须内心极其强大。内心的强大来自于什么？是你的实力。只有没本事的人才会处处在乎面子，只有弱者才在乎面子，强者都活成了里子。 面对批评的正确姿势闻过则喜，永远感谢愿意花时间在你身上的人。 有的人被批评了，像刺猬似的缩成一团竖起硬刺，“这不是我的错”；有的人被批评了，像鸵鸟一样把头钻进沙堆，“这和我没关系”；有的人被批评了，像寒风中哆哆嗦嗦的鹌鹑，“我也好可怜啊”；还有的人使出金蝉脱壳大法，“谁谁谁犯的错比我还大”，或是指东打西来找补，“我还干了很多好事呢”…… 一味在意对方的态度，在乎自己的感受，就容易忘了事情的根本：别人为什么批评你？ 一个比你更强的人批评你，你要明白一点：牛人没时间攻击你，也没时间浪费在一个他认为没有价值的人身上。牛人之所以批评你，是认为你还有潜力，他在帮助你成长。 面对批评，输球不要输姿势，你的心态应该是：把“为什么受伤的总是我”，变成“我能从这件事上学到什么”。 如果你觉得批评是一种刁难，一开始就输了；如果你觉得批评是一种雕刻，迟早都会赢的。 哪怕别人批评时严厉了点，甚至苛刻了些，你要做的不是愤怒、不是羞愧、不是执念于“我的面子啪叽掉地下了”的狭隘。错了咱就认，认了咱就改，改了就不再犯。 别人批评你不是坏事。就像情侣吵架，有的吵就挺好，说明还期望对方会改变，因为在意所以争吵，如果有一天不吵了，就是要分手了。褒贬是买主，喝彩是闲人。如果有一天老板都懒得批评你了，说明他已经放弃了。 丑闻是成功者的奖励难听的大实话：真比你强很多的人，根本没空搭理你。 一位创业的朋友有点小郁闷，他的同行四处造谣他和公司的女性高管有事。 我和他说你应该高兴，这说明你在圈子里已经有一号了，这是一种变相的认可。你的面子不是撂地下了，是被竞争对手供起来了。如果你公司干得稀碎，同行都不带正眼瞧你的。 当一个人有了丑闻，他一定达到了相当的高度。 人们不会去毒舌一个毫无建树的人。一旦你有所成就，你的竞争对手就会乐于制造你的丑闻，而吃瓜群众也乐于把你的丑闻当做谈资，尤其是男女关系这种下三滥的东西。 没必要把别人的造谣中伤当回事，你对待丑闻的态度，决定了你职业发展的高度。 以前我写一本书，发现盗版，我会郁闷；现在我写一本书，发现盗版，我很开心。因为，这也算是一种变相的认可，多少书首印都卖不掉，盗版的人都不稀罕去盗版。 雷霆雨露，蜚短流长，俱是天恩。 结束语如果你想干成点什么事，给你三条建议：第一，坚持；第二，不要脸；第三，坚持不要脸！","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.devcheng.net/tags/职场/"},{"name":"程序人生","slug":"程序人生","permalink":"http://www.devcheng.net/tags/程序人生/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"基于SpringBoot开发的家庭财务管理系统","slug":"基于SpringBoot开发的家庭财务管理系统","date":"2022-07-08T07:12:55.000Z","updated":"2022-07-08T07:19:05.514Z","comments":true,"path":"post/fb09f6bd.html","link":"","permalink":"http://www.devcheng.net/post/fb09f6bd.html","excerpt":"","text":"前言本项目是基于Spring Boot 2.x 开发的，家庭财务管理系统分三种角色，分别是：系统管理员，家主，用户。本项目可以当作毕业设计也有对应的毕业论文可参考(毕业论文不是免费的)，期末课程作业等，也可以当作学习、进阶Spring Boot 的资料。 功能描述本项目通过不同的角色登录显示不同角色对应的菜单，不用角色之间查看到对应的功能菜单数据。其中系统管理员拥有系统所有菜单和功能，其次是家主，家主下拥有的是用户。 主要功能 收支管理（支出详情，收入详情） 理财管理（活期资产，理财详情，负债详情，理财产品） 财务统计（统计报表） 系统管理（用户管理，角色管理） 我的主页 安全退出 修改密码 开发环境（运行环境） 系统环境：Windows 11 开发工具：IntelliJ IDEA 2020.3 Java版本：JDK 1.8 Mysql版本：5.7 Maven版本：3.6.3 项目技术栈 Spring Boot 2.1.X.RELEASE Spring Boot JPA Maven 3.X Mysql thymeleaf layui Jquery … 登录地址访问路径：http://localhost:8080/ 管理员账号/密码： admin / admin 家主账号/密码：house1 / 123456 用户账号/密码：yangtwo / 123456 项目演示视频视频链接： 链接: https://pan.baidu.com/s/1ttuRq_9vkfjq320MarTFIA?pwd=fptq 提取码: fptq 项目截图 联系我们如有需要源码可以通过QQ 搜索：792435323联系我！请备注：源码 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的FfmsApplication直接运行吧！ 其它说明白嫖怪（伸手党）请绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.devcheng.net/tags/SpringBoot/"},{"name":"家庭财务管理系统","slug":"家庭财务管理系统","permalink":"http://www.devcheng.net/tags/家庭财务管理系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"解决github无法访问的方法之修改hosts文件","slug":"解决github无法访问的方法之修改hosts文件","date":"2022-06-17T03:23:41.000Z","updated":"2022-11-30T06:02:27.508Z","comments":true,"path":"post/768a5c50.html","link":"","permalink":"http://www.devcheng.net/post/768a5c50.html","excerpt":"","text":"写在前面github有的朋友访问不了，今天就介绍一种解决方法。 解决方法根据修改hosts文件，配置github 对应ip从而达到可以访问github的目的，所以前提条件需要可以修改hosts文件。 hosts文件路径： C:\\Windows\\System32\\drivers\\etc 假如你无法修改对应的这个hosts文件，请移步百度一波先解决这个问题。 1.输入网站 https://www.ipaddress.com/ 2.按照下列清单在以上网站输入对于网址，得到的对应IP写入hosts文件即可。1234567891011121314github.global.ssl.fastly.netgithub.comassets-cdn.github.comdocumentcloud.github.comgist.github.comhelp.github.comnodeload.github.comraw.github.comstatus.github.comtraining.github.comwww.github.comavatars0.githubusercontent.comavatars1.githubusercontent.comcodeload.github.com 如果你嫌麻烦你可以直接复制下面的内容到你的hosts文件。 1234567891011121314146.75.77.194 github.global.ssl.fastly.net140.82.113.4 github.com185.199.109.153 assets-cdn.github.com185.199.109.153 documentcloud.github.com140.82.114.3 gist.github.com140.82.112.17 help.github.com140.82.112.10 nodeload.github.com185.199.108.133 raw.github.com140.82.114.18 status.github.com185.199.108.153 training.github.com140.82.113.4 www.github.com185.199.108.133 avatars0.githubusercontent.com185.199.109.133 avatars1.githubusercontent.com140.82.114.9 codeload.github.com 如果发现哪一天，这个不可用了，可以留言评论告知我！ 更新补充 有朋友反应这么改没啥用，正好最近朋友推荐了一个新的利器！ 这玩意叫 fastgithub , 有需要的自行下载即可！ 链接: https://pan.baidu.com/s/1Jtl292N8XuLq_A3yCQM1TA?pwd=8ttt 提取码: 8ttt The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"github无法访问","slug":"github无法访问","permalink":"http://www.devcheng.net/tags/github无法访问/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"如何将 swagger接口导出成PDF、markdown","slug":"如何将-swagger接口导出成PDF、markdown","date":"2022-06-15T05:05:15.000Z","updated":"2022-06-15T05:26:05.256Z","comments":true,"path":"post/76a1c264.html","link":"","permalink":"http://www.devcheng.net/post/76a1c264.html","excerpt":"","text":"写在前面swagger提供了UI页面，假如需要给合作伙伴对应的开发者，一般都需要提供一份接口PDF文件或是对应的markdown文件，这个时候就需要将对应swagger接口进行导出操作了。 具体步骤第一步：准备swagger json文件1.打开 swagger ui 的页面 2.点击 swagger json 的链接，具体如下图： tips：如果你没有看到这个链接，使用F12打开开发者工具重新刷新后，复制 api-docs 的响应内容。 一定要保存成 json 文件。 第二步： 把swagger json文件导入 docway1.登录 http://docway.net （如果第一次使用，需要注册） 2.在控制台中，新增项目，选择 导入 3.选择 swagger 导入，并根据自己的 swagger json 选择是“上传文件方式”还是“粘贴json方式” 4.导入成功后，就可以看到对应的信息了 第三步：导出PDF或markdown1.在项目的“更多设置”中，找到“项目导出”功能。可以选择 PDF或Markdown 导出即可 小结总体来说docway导出的PDF接口文件还是不错的，如果选择 PDF(浏览器版)对应的接口文件则是带有颜色的。如果选择的是 仅仅 PDF生成的接口文件页脚是带有docway的网站链接的。 docway除了 PDF、markdown 导出， 还支持接口设计、接口分享、接口mock、接口历史记录、接口版本管理、团队管理等功能。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"swagger2","slug":"swagger2","permalink":"http://www.devcheng.net/tags/swagger2/"},{"name":"导出PDF","slug":"导出PDF","permalink":"http://www.devcheng.net/tags/导出PDF/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"分享一个Joda-Time日期时间工具类","slug":"分享一个Joda-Time日期时间工具类","date":"2022-05-28T02:33:33.000Z","updated":"2022-05-28T02:44:04.665Z","comments":true,"path":"post/33ca8774.html","link":"","permalink":"http://www.devcheng.net/post/33ca8774.html","excerpt":"","text":"写在前面在JDK1.8之前，处理日期和时间的方式比较单一，Java中提供了Calendar来处理日期，但是过程较为繁琐。但是在JDK1.8之后，Java更新了time包提供了LocalDate,LocalTime,LocalDateTime等日期时间类来处理较为复杂的关于日期和时间的业务逻辑的方法。 现在介绍Joda-Time日期时间工具类，该类库的开发者参与了JDK1.8中time包的开发，所以在那些使用JDK1.8之前的项目，Joda-Time是一个不错的选择。而在JDK1.8之后，该工具类也是值得推荐使用的，其原因在于高效和安全。 完整代码展示引入必要的依赖： 123456789101112&lt;!-- https://mvnrepository.com/artifact/joda-time/joda-time --&gt;&lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;2.9.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt;&lt;/dependency&gt; Joda-Time工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455package com.h.util.time;import com.sun.istack.internal.Nullable;import org.apache.commons.lang3.StringUtils;import org.joda.time.DateTime;import org.joda.time.DateTimeZone;import org.joda.time.Days;import org.joda.time.LocalDate;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.TimeZone;/** * * 时间工具类 * Joda-Time提供了一组Java类包用于处理包括ISO8601标准在内的date和time. * 可以利用它把JDK Date和Calendar类完全替换掉，而且仍然能够提供很好的集成. * 尤其对时间的加减处理起来特别方便,快速. */public class TimeUtil &#123; public static final long SECOND = 1000; //1秒,毫秒为单位 public static final long MINUTE = SECOND * 60; //一分钟 public static final long HOUR = MINUTE * 60; // 一小时 public static final long DAY= HOUR * 24; //一天 public static final long WEEK = DAY * 7; //一周 public static final long YEAR = DAY * 365; //一年 public static final String FORMAT_TIME = \"yyyy-MM-dd HH:mm:ss\"; //默认时间格式 public static final String FORMAT_TIME_MINUTE = \"yyyy-MM-dd HH:mm\"; //默认时间格式 public static final String FORTER_DATE = \"yyyy-MM-dd\"; //默认日 /** * 获取当前系统时间 * @return yyyy-MM-dd HH:mm:ss */ public static String getCurrentTime() &#123; return getCurrentTimePattern(FORMAT_TIME); &#125; /** * 获取系统当前时间按照指定格式返回 * @param pattern yyyy/MM/dd hh:mm:ss * @return */ public static String getCurrentTimePattern(String pattern) &#123; DateTime dt = new DateTime(); String time = dt.toString(pattern); return time; &#125; /** * 按照时区转换时间 * @param date * @param timeZone 时区 * @param parrten * @return */ @Nullable public static String format(Date date, TimeZone timeZone, String parrten) &#123; if (date == null) &#123; return null; &#125; SimpleDateFormat sdf = new SimpleDateFormat(parrten); sdf.setTimeZone(timeZone); return sdf.format(date); &#125; /** * 获取当前日期是星期几 * @return */ public static String getCurrentWeek()&#123; return getWeek(new DateTime()); &#125; /** * 获取指定时间 * @param year 年 * @param month 月 * @param day 天 * @param hour 小时 * @param minute 分钟 * @param seconds 秒 * @return yyyy-MM-dd HH:mm:ss */ public static String getPointTime(Integer year, Integer month, Integer day, Integer hour, Integer minute, Integer seconds) &#123; return getPointTimePattern(year,month,day,hour,minute,seconds,FORMAT_TIME); &#125; /** * * @param year 年 * @param month 月 * @param day 天 * @param hour 小时 * @param minute 分钟 * @param seconds 秒 * @param parrten 自定义格式 * @return parrten */ public static String getPointTimePattern(Integer year, Integer month, Integer day, Integer hour, Integer minute, Integer seconds, String parrten) &#123; DateTime dt = new DateTime(year, month, day, hour, minute, seconds); String date = dt.toString(parrten); return date; &#125; /** * 获取指定日期 * @param year * @param month * @param day * @return */ public static String getPointDate(Integer year, Integer month, Integer day) &#123; return getPointDatParrten(year,month,day,FORTER_DATE); &#125; /** * 获取指定日期 返回指定格式 * @param year * @param month * @param day * @param parrten * @return */ public static String getPointDatParrten(Integer year, Integer month, Integer day, String parrten) &#123; LocalDate dt = new LocalDate(year, month, day); String date = dt.toString(parrten); return date; &#125; /** * 获取指定时间是一周的星期几 * @param year * @param month * @param day * @return */ public static String getWeekPoint(Integer year, Integer month, Integer day) &#123; LocalDate dts = new LocalDate(year, month, day); return getWeek(dts); &#125; /** * 获取指定日期是星期几 * @param dts * @return 如星期一 */ public static String getWeek(LocalDate dts)&#123; return WeekEnum.getDesc(dts.getDayOfWeek()); &#125; /** * 获取指定日期是星期几 * @param dts * @return 如星期一 */ public static String getWeek(DateTime dts)&#123; return WeekEnum.getDesc(dts.getDayOfWeek()); &#125; /** * 格式化日期 * @param date * @return yyyy-MM-dd HH:mm:ss */ @Nullable public static String format(Date date) &#123; return format(date,FORMAT_TIME); &#125; /** * 格式化日期字符串 * @param date 日期 * @param pattern 日期格式 * @return */ @Nullable public static String format(Date date, String pattern) &#123; if (date == null) &#123; return null; &#125; SimpleDateFormat format = new SimpleDateFormat(pattern); return format.format(date); &#125; /** * 解析日期yyyy-MM-dd HH:mm:ss * @param date 日期字符串 * @return */ @Nullable public static Date parse(String date) &#123; return parse(date,FORMAT_TIME); &#125; /** * 解析日期 * @param date 日期字符串 * @param pattern 日期格式 * @return */ @Nullable public static Date parse(String date, String pattern) &#123; if (date == null) &#123; return null; &#125; Date resultDate = null; try &#123; resultDate = new SimpleDateFormat(pattern).parse(date); &#125; catch (ParseException e) &#123; throw new RuntimeException(\"日期解析错误!\"); &#125; return resultDate; &#125; /** * 解析日期 yyyy-MM-dd HH:mm:ss * @param timestamp * @return */ public static String format(Long timestamp) &#123; return format(timestamp,FORMAT_TIME); &#125; /** * 解析日期 yyyy-MM-dd HH:mm:ss * @param timestamp * @return */ public static String format(Long timestamp, String pattern) &#123; String dateStr = \"\"; if (null == timestamp || timestamp.longValue() &lt; 0) &#123; return dateStr; &#125; try &#123; Date date = new Date(timestamp); SimpleDateFormat format = new SimpleDateFormat(pattern); dateStr = format.format(date); &#125; catch (Exception e) &#123; // ignore &#125; return dateStr; &#125; /** *获取当前时间前几天时间 * @param days * @return */ public static Date forwardDay(int days) &#123; DateTime dt = new DateTime(); DateTime y = dt.minusDays(days); return y.toDate(); &#125; /** *获取当前时间前几天时间,按指定格式返回 * @param days * @return */ public static String forwardDay(int days, String format) &#123; DateTime dt = new DateTime(); DateTime y = dt.minusDays(days); return y.toString(format); &#125; public static Date forwardDay(Date date,Integer days)&#123; DateTime dt = new DateTime(date); DateTime y = dt.minusDays(days); return y.toDate(); &#125; public static String forwardDay(Date date,Integer days,String format)&#123; DateTime dt = new DateTime(date); DateTime y = dt.minusDays(days); return y.toString(format); &#125; /** * 获取指定时间之后或者之前的某一天00:00:00 默认返回当天 * @param days * @return */ public static Date day00(Integer days, String date, String zimeZone) throws Throwable &#123; DateTime dt; TimeZone timeZone; try &#123; if (StringUtils.isBlank(zimeZone)) &#123; timeZone = TimeZone.getDefault(); &#125; else &#123; timeZone = TimeZone.getTimeZone(zimeZone); &#125; if (StringUtils.isBlank(date)) &#123; dt = new DateTime().withZone(DateTimeZone.forTimeZone(timeZone)).toLocalDateTime().toDateTime(); &#125; else &#123; dt = new DateTime(date).withZone(DateTimeZone.forTimeZone(timeZone)).toLocalDateTime().toDateTime(); &#125; &#125; catch (Exception e) &#123; throw new Throwable(e); &#125; DateTime y = dt.minusDays(days).withHourOfDay(0).withMinuteOfHour(0).withSecondOfMinute(0); return y.toDate(); &#125; /** *获取指定时间之后或者之前的某一天23:59:59 默认返回当天 * @param days 偏移量 * @return */ public static Date day59(Integer days, String date, String zimeZone) throws Throwable &#123; DateTime dt; TimeZone timeZone; try &#123; if (StringUtils.isBlank(zimeZone)) &#123; timeZone = TimeZone.getDefault(); &#125; else &#123; timeZone = TimeZone.getTimeZone(zimeZone); &#125; if (StringUtils.isBlank(date)) &#123; dt = new DateTime().withZone(DateTimeZone.forTimeZone(timeZone)).toLocalDateTime().toDateTime(); &#125; else &#123; dt = new DateTime(date).withZone(DateTimeZone.forTimeZone(timeZone)).toLocalDateTime().toDateTime(); &#125; &#125; catch (Exception e) &#123; throw new Throwable(e); &#125; DateTime y = dt.minusDays(days).withHourOfDay(23).withMinuteOfHour(59).withSecondOfMinute(59); return y.toDate(); &#125; /** * 计算两个时间相差多少天 * @param startDate * @param endDate * @return */ @Nullable public static Integer diffDay(Date startDate, Date endDate) &#123; if (startDate == null || endDate == null) &#123; return null; &#125; DateTime dt1 = new DateTime(startDate); DateTime dt2 = new DateTime(endDate); int day = Days.daysBetween(dt1, dt2).getDays(); return Math.abs(day); &#125; /** * 获取某月之前,之后某一个月最后一天,24:59:59 * @return */ public static Date lastDay(Date date, Integer month) &#123; DateTime dt1; if (month == null) &#123; month = 0; &#125; if (date == null) &#123; dt1 = new DateTime().minusMonths(month); &#125; else &#123; dt1 = new DateTime(date).minusMonths(month); &#125; DateTime lastDay = dt1.dayOfMonth().withMaximumValue(). withHourOfDay(23).withMinuteOfHour(59).withSecondOfMinute(59); return lastDay.toDate(); &#125; /** *获取某月月之前,之后某一个月第一天,00:00:00 * @return */ public static Date firstDay(Date date, Integer month) &#123; DateTime dt1; if (month == null) &#123; month = 0; &#125; if (date == null) &#123; dt1 = new DateTime().minusMonths(month); &#125; else &#123; dt1 = new DateTime(date).minusMonths(month); &#125; DateTime lastDay = dt1.dayOfMonth().withMinimumValue(). withHourOfDay(0).withMinuteOfHour(0).withSecondOfMinute(0); return lastDay.toDate(); &#125; public static Date addDay(Date date, int offset) &#123; DateTime dt1; if (date == null) &#123; dt1 = new DateTime().plusDays(offset); return dt1.toDate(); &#125; dt1 = new DateTime(date).plusDays(offset); return dt1.toDate(); &#125; /** * 传入日期时间与当前系统日期时间的比较, * 若日期相同，则根据时分秒来返回 , * 否则返回具体日期 * @return 日期或者 xx小时前||xx分钟前||xx秒前 */ @Nullable public static String getNewUpdateDateString(Date now, Date createDate) &#123; if (now == null || createDate == null) &#123; return null; &#125; Long time = (now.getTime() - createDate.getTime()); if (time &gt; (24 * 60 * 60 * 1000)) &#123; return time / (24 * 60 * 60 * 1000) + \"天前\"; &#125; else if (time &gt; (60 * 60 * 1000)) &#123; return time / (60 * 60 * 1000) + \"小时前\"; &#125; else if (time &gt; (60 * 1000)) &#123; return time / (60 * 1000) + \"分钟前\"; &#125; else if (time &gt;= 1000) &#123; return time / 1000 + \"秒前\"; &#125; return \"刚刚\"; &#125; enum WeekEnum&#123; MONDAY(1,\"星期一\"), TUESDAY(2,\"星期二\"), WEDNESDAY(3,\"星期三\"), THURSDAY(4,\"星期四\"), FRIDAY(5,\"星期五\"), SATURDAY(6,\"星期六\"), SUNDAY(7,\"星期日\"); private int index; private String desc; WeekEnum(int index, String desc) &#123; this.index = index; this.desc = desc; &#125; public static String getDesc(int index)&#123; String desc = \"\"; WeekEnum[] values = WeekEnum.values(); for (WeekEnum weekEnum:values)&#123; if (weekEnum.index == index)&#123; desc = weekEnum.desc; &#125; &#125; return desc; &#125; &#125;&#125; The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Joda-Time","slug":"Joda-Time","permalink":"http://www.devcheng.net/tags/Joda-Time/"},{"name":"日期时间工具类","slug":"日期时间工具类","permalink":"http://www.devcheng.net/tags/日期时间工具类/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MindManager2018试用期过后破解使用","slug":"MindManager2018试用期过后破解使用","date":"2022-05-12T12:28:35.000Z","updated":"2022-11-30T06:18:52.247Z","comments":true,"path":"post/a39ed45b.html","link":"","permalink":"http://www.devcheng.net/post/a39ed45b.html","excerpt":"","text":"写在前面前段时间无意入坑 MindManager 2018 ，可以免费体验一个月没来的及用几次一个月就过去了，再次打开就提示 “你的30天评估期已结束” 。瞬间觉得失去了几百万，急得直拍大腿啊，无奈从网上找到了破解之法，遂记录一下。（还是得说一句违心的话，如果你是土豪就买正版支持一下吧。） 破解方法步骤一：根据路径：C:\\Users\\xxx\\AppData\\Roaming\\MindManager\\MindManager2018.ini找到MindManager2018.ini文件，使用任意编辑器打开。 tips: C:\\Users\\xxx 这里的 xxx 每个人的都不一样的 替换成自己的哦！ MindManager2018.ini123[MindManager]InstallTime=1537004338LastLoading=1537004338 InstallTime代表安装时间，LastLoading记录最后一次启动时间。 步骤二：使用 win+R 接着输入 regedit ，找到路径HKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Mindjet\\MindManager\\18\\Installer 找到项Install，修改里面的InstallTime的值。记住修改的这个时间，接着 可以使用计算时间戳的网址 使用在线计算时间戳的网站 ，把转换后的时间戳复制到 MindManager2018.ini 文件中的InstallTime中，保存重新打开MindManager即可。 小小的总结以上的方法也不是完全之策，修改之后也是只能使用30天，到时间后还是会提示30天评估期结束的话语，如果你不嫌弃这样的方法，可以继续使用这个方法。如果家中有矿，正好你也喜欢拿就可以使用 钞能力 解决！ 后续更新补充 有的朋友留言说这个改了没啥用，或是不会该！ 我只能说 我改了是可以用的，你们的留言我这里都收到了，但是这个留言插件的原因有的人可以展示出来，有的展示不出来。 好像跑题了，以上破解的方法确实折腾，所以 我找了一个 MindManager14 可汉化，可破解。链接如下，喜欢的自己拿去吧！ 链接: https://pan.baidu.com/s/1vAA841g1n0VG4qC8EaEezg?pwd=hs4e 提取码: hs4e The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"MindManager2018","slug":"MindManager2018","permalink":"http://www.devcheng.net/tags/MindManager2018/"},{"name":"过期破解","slug":"过期破解","permalink":"http://www.devcheng.net/tags/过期破解/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"面试题：int(1)和int(10)有区别吗","slug":"面试题：int-1-和int-10-有区别吗","date":"2022-04-30T06:17:58.000Z","updated":"2022-04-30T06:28:57.557Z","comments":true,"path":"post/9ada137e.html","link":"","permalink":"http://www.devcheng.net/post/9ada137e.html","excerpt":"","text":"先给答案int(1)和int(10)有区别吗？ 没有区别 背景工作中不乏见过定义各种类型像varchar(4),char(2)等,里面的数字一般指的是字符长度。所以很多人也会觉得int(1)里面只能存1位数，殊不知是理解错了。下面具体讲解一下！ 讲解INT[(M)] [UNSIGNED] [ZEROFILL] 普通大小的整数。 带符号的范围是-2147483648到2147483647 无符号的范围是0到4294967295。 INT(1) 和 INT(10)本身没有区别，但是加上(M)值后，会有显示宽度的设置。 测试1123create table test(id int(3));insert into test values(12);insert into test values(1234); 1234567mysql&gt; select * from test;+------+| id |+------+| 12 || 1234 |+------+ 从这个测试可以看出定义的id int(3)是可以存下1234的，接着带上ZEROFILL做测试。 测试2和测试1一样创建一个表，也是定义id int(3) 带上zerofill，测试结果如下：123456789101112131415161718192021mysql&gt; create table test1(id int(3) zerofill);Query OK, 0 rows affected (0.52 sec)mysql&gt; insert into test1 value(12);Query OK, 1 row affected (0.15 sec)mysql&gt; insert into test1 value(1234);Query OK, 1 row affected (0.16 sec)mysql&gt; insert into test1 value(666666);Query OK, 1 row affected (0.14 sec)mysql&gt; select * from test1;+--------+| id |+--------+| 012 | # 这个地方不够三位宽度会自动补零| 1234 || 666666 |+--------+3 rows in set (0.00 sec) 测试3利用 test表（不带zerofill）和 test1表（带zerofill） 测试插入负数看看。 test表(可以正常存进去)123456789101112mysql&gt; insert into test value(-1234);Query OK, 1 row affected (0.07 sec)mysql&gt; select * from test;+-------+| id |+-------+| 12 || 1234 || -1234 |+-------+3 rows in set (0.00 sec) test1表 12mysql&gt; insert into test1 value(-1234);ERROR 1264 (22003): Out of range value for column &apos;id&apos; at row 1 从这个测试可以发现添加zerofill的时候，无法添加负数到表里。 12345678910111213mysql&gt; insert into test1 value(0);Query OK, 1 row affected (0.10 sec)mysql&gt; select * from test1;+--------+| id |+--------+| 012 || 1234 || 666666 || 000 |+--------+4 rows in set (0.00 sec) 小结以上测试中用到的 zerofill 翻译过来就是 零填充。 int后面的数字不能表示字段的长度，int(num)一般加上zerofill，才有效果。zerofill的作用一般可以用在一些编号相关的数字中，比如学生的编号 001 002 … 999这种，如果mysql没有零填充的功能，但是你又要格式化输出等长的数字编号时，那么你只能自己处理了。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"int(1)和int(10)有区别吗","slug":"int-1-和int-10-有区别吗","permalink":"http://www.devcheng.net/tags/int-1-和int-10-有区别吗/"},{"name":"面试题","slug":"面试题","permalink":"http://www.devcheng.net/tags/面试题/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"程序员如何走出自己的安逸环境","slug":"程序员如何走出自己的安逸环境","date":"2022-04-17T07:24:55.000Z","updated":"2022-06-17T07:34:08.031Z","comments":true,"path":"post/c0cb035d.html","link":"","permalink":"http://www.devcheng.net/post/c0cb035d.html","excerpt":"","text":"前言过去的几个月里发生的几件事情，让给政府做软件开发的人感受到压力的陡增，从奥巴马的医保网站饱受诟病到美国退伍军人事务部官方网站的预约系统从1985年起就没有更新过，这些事情让我回忆起曾经作为政府程序员的经历，以及这段经历如何变成一种一直督促我努力工作的思想动力。 我曾在某个政府部门维护过一个写于1990年代的老系统。当一个新的系统启动开发来替代部分的老系统功能时，很多的程序员对开发新系统的工作产生的严重的抵制心里。起初，我并不知道为什么他们会有这么大的反感。对这个系统维护一段时间之后，我才慢慢明白，有些程序员是专门维护系统，时间长达15年之久。当被邀请开发新系统时，他们对新事物和新技术都感到心里没底。 这让我警醒：这种事情也会很容易发生在我的职业生涯中。我可能会安逸的干着某一种工作，安逸的年年维护着某个系统。当这个系统长岁数时，我对它也变的更有价值，我的角色会最终变成专职维护它。我的余生也就整天执行相同的任务，直到退休。而当有一天，当这个系统不再被人需要时，我会发现外面的世界已经日新月异，我需要从头学起。 这可不是我希望的生活轨迹；我作为程序员喜欢的方式是学习新思路来解决新问题，而不是安于现状。我们程序员很容易迷住某一项技术而将全部精力都放在上面，对于其它的毫不关心。虽然这样可以让你在某一个领域成为专家，但你却得不到探索其它领域获得的更多好处。当意识到这种目光狭窄会扼杀我的进取心后，我开始避免让所有鸡蛋都放到一个篮子里，我开始走出自己职业仕途中的安逸环境。 学习新技术你一直在用PHP编程吗？尝试一下使用Rails或ASP.NET。也许尝试一种新的语言或框架会让你感到受挫和沮丧，但探索的趣味也就在这里。至少，你应该看看同一种功能用其它语言是如何实现的。如何你只会用锤子，那你眼里所有的东西看起来都像钉子。 不惧怕老代码虽然上面我举例的那个老代码的例子有些极致，但我并不认为所有的老代码都应该立刻替换掉、删掉。在如今的软件中，有很多稳固的、良好设计的程序代码，它们对那些只会使用集成开发组件的现代程序员来说是很好的学习教材。如果你的公司里有老项目、老代码需要你去维护，研究一下！你会吃惊于从中学到那么多的编程知识以及公司的业务规则。还会发现一些当前正在研究的问题，其实几年以前就有人已经解决了。 了解你的敌人程序员很容易对某种语言或框架产生宗教式的虔诚。如果你发现自己曾经痛恨或鄙视某种技术(参看JeffAtwood的一篇经典文章)，也许你应该强迫自己去研究一下它们。最不济，至少你能证明讨厌它们是有理由的。最好的情况是，你会从它们中学到很多东西。不要让你的偏见阻挡了你的探索道路。 不要太贪心程序员很容易被各种层出不穷的新平台、新语言、新工具、新类库吓倒。你很容易产生一种恐惧心理，感觉自己已经落后——那些程序员谈论的技术我怎么从来没有听说过？当你发现一种新技术看起来很有用或很有趣时，做个笔记，几周或几月后在回来看看它，如果人们还在谈论它，那么，你就应该进一步研究它。事实上很多热门新技术都是昙花一现，你完全可以忽略它，不要让它们浪费了你的大脑。 学无止境程序员都有着一种天生的好奇心，这种好奇心引导着我们的编程生涯。写几行代码，装载到计算机里，让它按照你的思路工作，这是非常有趣的事情。但随着开发的东西越来越多，我们变的越来越忙，这种好奇心会慢慢的减退。我们应该时不时的用一些新思路挑战自己，让自己的思想保持锋锐和专注，提醒自己为什么当初选择码农这条道路。 英文原文：Getting Out Of Your Comfort Zone The end.","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"程序员","slug":"程序员","permalink":"http://www.devcheng.net/tags/程序员/"},{"name":"职业规划","slug":"职业规划","permalink":"http://www.devcheng.net/tags/职业规划/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"java设计模式之组合模式","slug":"java设计模式之组合模式","date":"2022-02-23T01:01:33.000Z","updated":"2022-02-23T01:15:11.036Z","comments":true,"path":"post/d4faf60.html","link":"","permalink":"http://www.devcheng.net/post/d4faf60.html","excerpt":"","text":"组合模式介绍又叫整体-部分模式，它是一种将对象组合成树状的层次结构的模式，用来表示“整体-部分”的关系，使用户对单个对象和组合对象具有一致的访问性，属于结构型设计模式。 组合模式一般用来描述整体与部分的关系，它将对象组织到树形结构中，顶层的节点被称为根节点，根节点下面可以包含树枝节点和叶子节点，树枝节点下面又可以包含树枝节点和叶子节点，树形结构图如下。 组合模式UML类图 模式构造 Component: 抽象构件。 Leaf: 叶子构件。 Composite: 容器构件。 组合模式分为 透明式 的组合模式和 安全式的组合模式。 (1) 透明方式在该方式中，由于抽象构件声明了所有子类中的全部方法，所以客户端无须区别树叶对象和树枝对象，对客户端来说是透明的。但其缺点是：树叶构件本来没有 Add()、Remove() 及 GetChild() 方法，却要实现它们（空实现或抛异常），这样会带来一些安全性问题。其结构图如图 1 所示。 (2) 安全方式在该方式中，将管理子构件的方法移到树枝构件中，抽象构件和树叶构件没有对子对象的管理方法，这样就避免了上一种方式的安全性问题，但由于叶子和分支有不同的接口，客户端在调用时要知道树叶对象和树枝对象的存在，所以失去了透明性。其结构图如图 2 所示。 举个例子下面就演示两种模式的实例的demo。 透明组合模式下面为透明式的组合模式的实现代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class CompositePattern &#123; public static void main(String[] args) &#123; Component c0 = new Composite(); Component c1 = new Composite(); Component leaf1 = new Leaf(\"1\"); Component leaf2 = new Leaf(\"2\"); Component leaf3 = new Leaf(\"3\"); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation(); &#125;&#125;//抽象构件interface Component &#123; public void add(Component c); public void remove(Component c); public Component getChild(int i); public void operation();&#125;//树叶构件class Leaf implements Component &#123; private String name; public Leaf(String name) &#123; this.name = name; &#125; public void add(Component c) &#123; &#125; public void remove(Component c) &#123; &#125; public Component getChild(int i) &#123; return null; &#125; public void operation() &#123; System.out.println(\"树叶\" + name + \"：被访问！\"); &#125;&#125;//树枝构件class Composite implements Component &#123; private ArrayList&lt;Component&gt; children = new ArrayList&lt;Component&gt;(); public void add(Component c) &#123; children.add(c); &#125; public void remove(Component c) &#123; children.remove(c); &#125; public Component getChild(int i) &#123; return children.get(i); &#125; public void operation() &#123; for (Object obj : children) &#123; ((Component) obj).operation(); &#125; &#125;&#125; 运行结果： 123树叶1：被访问！树叶2：被访问！树叶3：被访问！ 安全组合模式安全式的组合模式与透明式组合模式的实现代码类似，只要对其做简单修改就可以了，代码如下。 首先修改 Component 代码，只保留层次的公共行为。 123interface Component &#123; public void operation();&#125; 然后修改客户端代码，将树枝构件类型更改为 Composite 类型，以便获取管理子类操作的方法。 1234567891011121314public class CompositePattern &#123; public static void main(String[] args) &#123; Composite c0 = new Composite(); Composite c1 = new Composite(); Component leaf1 = new Leaf(\"1\"); Component leaf2 = new Leaf(\"2\"); Component leaf3 = new Leaf(\"3\"); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation(); &#125;&#125; 组合模式的优缺点优点 高层模块调用简单。一棵树形机构中的所有节点都是Component，局部和整体对调用者来说没有任何区别，高层模块不必关心自己处理的是单个对象还是整个组合结构。 符合“开闭原则”。在组合模式中新增叶子构件和容器构件都很方便。缺点 使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒转原则。 应用场景前面分析了组合模式的结构与优缺点点，下面分析它适用的以下应用场景。 在需要表示一个对象整体与部分的层次结构的场合。 要求对用户隐藏组合对象与单个对象的不同，用户可以用统一的接口使用组合结构中的所有对象的场合。 组合模式使用案例 JDK中AWT包和Swing包的设计是基于组合模式 ，在这些界面包中为用户提供了大量的容器构件（如 Container ）和成员构件（如 Checkbox 、 Button 和 TextComponent 等），他们都是继承、关联自抽象组件类Component。 2.JDK中的Container类和HashMap类。 通过看它的行为方法add()可以看出，它添加的是它的父类，符合组合模式的设计 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"http://www.devcheng.net/tags/java设计模式/"},{"name":"组合模式","slug":"组合模式","permalink":"http://www.devcheng.net/tags/组合模式/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"java设计模式之桥接模式","slug":"java设计模式之桥接模式","date":"2022-02-22T12:57:12.000Z","updated":"2022-02-22T13:10:10.389Z","comments":true,"path":"post/84fa502e.html","link":"","permalink":"http://www.devcheng.net/post/84fa502e.html","excerpt":"","text":"桥接模式介绍桥接模式的定义：桥接模式是将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体(Handle and Body)模式或接口(interface)模式。 【GOF95】在提出桥梁模式的时候指出，桥梁模式的用意是”将抽象化(Abstraction)与实现化(Implementation)脱耦，使得二者可以独立地变化”。这句话有三个关键词，也就是 抽象化、 实现化和 脱耦。 桥接模式UML类图 模式构造 Abstraction：定义抽象接口，拥有一个Implementor类型的对象引用 RefinedAbstraction：扩展Abstraction中的接口定义 Implementor：是具体实现的接口，Implementor和RefinedAbstraction接口并不一定完全一致，实际上这两个接口可以完全不一样Implementor提供具体操作方法，而Abstraction提供更高层次的调用 ConcreteImplementor：实现Implementor接口，给出具体实现 举个例子使用以上的类图结构，写一个实例demo 。 Abstraction抽象类12345678910111213141516171819 1 public abstract class Abstraction &#123; 2 3 private Implementor imp; 4 5 //约束子类必须实现该构造函数 6 public Abstraction(Implementor imp) &#123; 7 this.imp = imp; 8 &#125; 9 10 public Implementor getImp() &#123;11 return imp;12 &#125;13 14 //自身的行为和属性15 public void request() &#123;16 this.imp.doSomething();17 &#125;18 19 &#125; Implementor抽象类1234561 public abstract class Implementor &#123;2 3 public abstract void doSomething();4 public abstract void doAnything();5 6 &#125; ConcreteImplementor具体实现类123456789101112 1 public class ConcreteImplementorA extends Implementor &#123; 2 3 @Override 4 public void doSomething() &#123; 5 System.out.println(\"具体实现A的doSomething执行\"); 6 &#125; 7 8 @Override 9 public void doAnything() &#123;10 System.out.println(\"具体实现A的doAnything执行\");11 &#125;12 &#125; RefinedAbstraction 类123456789101112131415 1 public class RefinedAbstraction extends Abstraction &#123; 2 3 //覆写构造函数 4 public RefinedAbstraction(Implementor imp) &#123; 5 super(imp); 6 &#125; 7 8 //修正父类行为 9 @Override10 public void request() &#123;11 super.request();12 super.getImp().doAnything();13 &#125;14 15 &#125; Client客户端1234567891 public class Client &#123;2 3 public static void main(String[] args) &#123;4 Implementor imp = new ConcreteImplementorA();5 Abstraction abs = new RefinedAbstraction(imp);6 abs.request();7 &#125;8 9 &#125; 运行结果 桥接模式的优缺点优点 抽象和实现分离。桥梁模式完全是为了解决继承的缺点而提出的设计模式 优秀的扩展能力 实现细节对客户透明。客户不用关心细节的实现，它已经由抽象层通过聚合关系完成了封装 缺点 增加系统的理解与设计难度。由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程 桥接模式要求正确识别出系统中两个独立变化的维度，因此其使用范围具有一定的局限性。 使用场景1.一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。2.对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。3.如果你不希望在抽象和实现部分采用固定的绑定关系，可以采用桥接模式，来把抽象和实现部分分开，然后在程序运行期间来动态的设置抽象部分需要用到的具体的实现，还可以动态切换具体的实现。 桥接模式使用案例1.在JDK中的应用了桥接模式的类。 java.util.logging是JDK自带的日志包，可以将日志输出到文件、内存或者控制台，作用与我们常用的log4j类似。包中的Handler类和Formatter类在设计上利用了桥接模式，首先看类关系图： 2.JDBC中的DriverManager接口也使用了桥接模式。 mysql的Driver类123456789101112public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; public Driver() throws SQLException &#123; &#125; static &#123; try &#123; DriverManager.registerDriver(new Driver()); &#125; catch (SQLException var1) &#123; throw new RuntimeException(\"Can't register driver!\"); &#125; &#125;&#125; DriverManager类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class DriverManager &#123; public static Connection getConnection(String url, String user, String password) throws SQLException &#123; java.util.Properties info = new java.util.Properties(); if (user != null) &#123; info.put(\"user\", user); &#125; if (password != null) &#123; info.put(\"password\", password); &#125; return (getConnection(url, info, Reflection.getCallerClass())); &#125; private static Connection getConnection( String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException &#123; /* * When callerCl is null, we should check the application's * (which is invoking this class indirectly) * classloader, so that the JDBC driver class outside rt.jar * can be loaded from here. */ ClassLoader callerCL = caller != null ? caller.getClassLoader() : null; synchronized(DriverManager.class) &#123; // synchronize loading of the correct classloader. if (callerCL == null) &#123; callerCL = Thread.currentThread().getContextClassLoader(); &#125; &#125; if(url == null) &#123; throw new SQLException(\"The url cannot be null\", \"08001\"); &#125; println(\"DriverManager.getConnection(\\\"\" + url + \"\\\")\"); // Walk through the loaded registeredDrivers attempting to make a connection. // Remember the first exception that gets raised so we can reraise it. SQLException reason = null; for(DriverInfo aDriver : registeredDrivers) &#123; // If the caller does not have permission to load the driver then // skip it. if(isDriverAllowed(aDriver.driver, callerCL)) &#123; try &#123; println(\" trying \" + aDriver.driver.getClass().getName()); Connection con = aDriver.driver.connect(url, info); if (con != null) &#123; // Success! println(\"getConnection returning \" + aDriver.driver.getClass().getName()); return (con); &#125; &#125; catch (SQLException ex) &#123; if (reason == null) &#123; reason = ex; &#125; &#125; &#125; else &#123; println(\" skipping: \" + aDriver.getClass().getName()); &#125; &#125; // if we got here nobody could connect. if (reason != null) &#123; println(\"getConnection failed: \" + reason); throw reason; &#125; println(\"getConnection: no suitable driver found for \"+ url); throw new SQLException(\"No suitable driver found for \"+ url, \"08001\"); &#125;&#125;&#125; 上面是简化的代码，可以看到需要返回的是Connection对象。在Java中通过Connection提供给各个数据库一样的操作接口，这里的Connection可以看作抽象类。可以说我们用来操作不同数据库的方法都是相同的，不过MySQL有自己的ConnectionImpl类，同样Oracle也有对应的实现类。这里Driver和Connection之间是通过DriverManager类进行桥接的。 小结1、桥接模式实现了抽象化与实现化的脱耦。他们两个互相独立，不会影响到对方。 2、对于两个独立变化的维度，使用桥接模式再适合不过了。 3、对于”具体的抽象类”所做的改变，是不会影响到客户。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"http://www.devcheng.net/tags/java设计模式/"},{"name":"桥接模式","slug":"桥接模式","permalink":"http://www.devcheng.net/tags/桥接模式/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"领导跳槽想带我走，我要不要跟","slug":"领导跳槽想带我走，我要不要跟","date":"2022-02-20T07:56:17.000Z","updated":"2022-02-20T08:05:57.605Z","comments":true,"path":"post/bd5b017a.html","link":"","permalink":"http://www.devcheng.net/post/bd5b017a.html","excerpt":"","text":"前几天看到有网友问了这样一个问题：上司跳槽想带他一起走，薪资待遇都不错。但他不太喜欢这个领导，也知道领导只是想带个熟悉的人好干活，所以他很犹豫要不要跟。 另一名网友则贴了自己的经历： 领导另谋高就，想带你一起飞，看上去跟和不跟都有风险。“跟还是不跟”这个问题不能搞一刀切或二元论，得考虑清楚以下三个问题后再做决定。 你如何评价想要挖走自己的领导你对这位领导有多信任？合作这些年他的工作能力如何？平时对待下属怎么样？他此次跳槽是深思熟虑还是一时冲动……考虑这些问题的原因，无非是需要判断这个领导值不值得跟随，但在判断的过程中很多人想岔了，以为只要领导为人nice就行。但实际上，有时候上司性格nice并不代表他就是一个好领导。世界经济论坛全球青年领袖Greg McKeown曾做过一项调研，在十二个月内收集了超过一百家公司的一千位经理人的资料，其中包括苹果、思科、IBM、英特尔、微软等公司，他想了解员工在什么环境下具备最佳的职业表现。结果调研后发现，有一半的员工生产力折损在所谓的好领导手里。这些好领导的共同特征是很亲切，让你觉得舒服。“好领导”这个词，首先落脚点是”领导”、其次才是”好”。领导的首要任务是让团队和下属有利可图，而不是让员工心情愉悦、如沐春风。而有些领导的 “坏”只是表征，在抽丝剥茧后，你会发现他们其实值得跟随。 1）“压榨”下属，但承认下属的价值我的一位读者朋友曾给我留言晒过自己的领导。当年，他被现在的公司录用，但因为经验欠缺，所以和同岗的同事相比月薪低了30%。第一年，他拿着低于平均水平的工资却干着和大家一样的活，为了能尽快上手，他加了不少没有加班费的班，父母都劝他换份工作，省得被领导压榨得连骨头都不剩，但这位朋友还是坚持了下来。第二年他独当一面后，当年完成了两个不错的项目，进步和成绩被领导看在了眼里，工资直接翻倍。《奇葩说》辩手傅首尔曾在节目里说过：”职场老大义气，无非加钱二字，没有甜头、哪有劲头”。这种心里算得清下属价值的领导，无疑是值得跟随的。 2）让人加班，但不会让人被工作完全绑架我弟弟的老板就是一个”极端”的领导。忙的时候拉着下属一天工作10小时，好多次午饭都顾不上吃。但高峰一旦忙完、或临近节假日没有项目时，他知道大家的心思不在工作上，所以会让大家提前收工、赶紧回家。“回去多陪陪家人不好么？干嘛在办公室耗费时间！”是他领导的经典语录。从来都不加班的职场人少之又少，但最怕的就是那种自己是工作狂，就号召下属也24小时待命、见不得一点清闲、企图让工作成为你人生唯一目标的领导。 3）比起秋后算账、更愿意遏制苗头秋后算账多容易，甩锅甩得漂亮、还能抖威风，”你看你，当时我就说xxx。”事后诸葛型领导不少见。比起”算账”，好领导们更愿意及时指出问题、让员工免于犯错。和这种并不nice的领导共事，一开始往往会让人觉得不舒服，但日久见人心，当你看到工资卡上增长的数字和自己能力的成长时，你会知道没有跟错人。 你如何评价现在的公司？除了仔细评估上司值不值得跟随外，也要对老东家来一次“全面体检”。比如，领导挪窝后你是否有上位的机会？在原公司你和其他同事相处得如何（去新公司意味着你要重新花费成本在人际关系上）？新上任的领导你是否熟悉、是否是好共事的人？他有没有能力带着部门更上一层楼？说到底，你要考量的是：目前，这是不是一家值得自己留下来的公司？这里有三个评判标准—— 1）公司的经营状况利润是衡量一家公司好坏的最硬标尺。如果一家公司盈利不佳，再好的模式和概念也毫无价值。多观察公司有没有客户经常往来、销售人员的精气神、领导整天都在忙什么、上一年的财报。一家持续盈利的公司是你留任的底线。 2）公司给你的安全感公司盈利尚可，未必就代表能给员工带来安全感。根据猎聘大数据研究院发布的《未来职场”六感”研究白皮书》显示，职场人安全感的基石是薪资福利这些与钱有关的因素，但职场人需要的安全感不止是钱能满足的。职场人最看重的企业提升安全感的举措首先是契约精神；其次是”健康、绿色的办公环境”和”保护员工条例(如反性骚扰、反职场霸凌等)”。领导是否兑现承诺、福利保障是否到位、办公室文化是否健康……这些都是你在选择留下来时要考虑的问题。 3）你的升职空间你在现有公司你的升职空间到底有多大？留下来三五年后你可能的状况是什么样的？如果没有升职机会，单从工资收入这一点来说可能三五年后，你和现在生活的状况差不多。如果现在都是咬牙过日子，以后也可能是如此的现状，若干年后年龄大了，生活的压力更大，自己更没有勇气求变，只有被淘汰的份儿。扫描一遍老东家后，也许你会发现比起离开，目前这里才是你更好的容身之地。 你如何评价可能会去的新公司？领导想要挖走你的时候，肯定会对新公司做出更好的评价，但这个结论是从他的立场上作出的，很可能并不适用于你，所以你也需要对新公司有所了解。宏观层面，要去了解与目前你所在的公司相比，新公司的优劣势（薪资福利、培训、技能、公司氛围）在哪里？做的事情你是否喜欢？如果一切如旧，离开原公司的意义在哪里？微观层面。最重要的是了解清楚你加入后的职责——你在部门的角色是什么？你的加入会给整个部门带来哪些作用？公司看重你的哪些技能？为什么需要你在这里工作？考量这些问题无非是想弄清楚一件事：排除原上司这个因素，这家新公司值不值得你加入？而你在新公司的眼里，会是一个独立的职场人抑或只是你领导的“附属品”？ 额外的“难题”——如果选择留下，我如何面对新上司？ 如果原领导离开，自己选择留任，公司空降了新上司。这时，我们将面临一个经典的职场问题：自己如何与新领导相处？作为老员工的我们与新领导相处时，最好能守住“二要”和“三不要”原则。 1）要尊重新领导也许你对新上任的领导并不满意，但只要你的前途仰赖于他，该有的恭敬态度和礼貌还是要做到位。尤其当自己是老骨干、领导资浅（或者比自己年轻时）时，更不该摆谱儿。越资深、越恭谦，越容易得到新上司的赏识和重用。 2）要主动与新领导沟通，帮助新领导我们对新领导多数时候会采取敬而远之的态度，原因有二，一是不知道新领导的脾气秉性，怕贸然去打招呼会碰钉子、闹尴尬；二是怕别的员工说自己拍马屁、主动向新领导献殷勤。其实新官上任心里也很慌，如果我们能主动询问领导的需求，与领导积极沟通，新上司会对你心存感激的。 3）不要在新领导面前评价前任领导前任领导的功过是否新上司可以从其他渠道得之，但从你口中得之，无论评价好坏，新领导都不会领情。 4）不要议论部门同事有些领导喜欢从老员工那里打听团队成员的情况，点评每个人的优缺点，看似帮助领导熟悉人员情况，但你不知道新领导与其他员工的关系。贸然点评可能会给自己惹麻烦，还是让新领导自己去观察、评价比较好。 5）不要急于向新领导表忠心虽然我们尊重新领导、愿意积极沟通，但也不要靠得太近，给自己贴上“我是新领导的人”的标签，在同事中难做人。职场人想要有前途，平台、领导、自身能力三样缺一不可。好的领导是伯乐，可以助我们一臂之力，但说到底大家是利益联盟关系，我们不能将自己的前途过于依赖在某位领导的去留上。无论是跟随领导高就、还是留在原地，最终，打铁还需自身硬，要能做到走可以走得潇洒、留可以留得安心。 转载链接：https://www.wxnmh.com/thread-10047990.htm","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.devcheng.net/tags/职场/"},{"name":"跳槽","slug":"跳槽","permalink":"http://www.devcheng.net/tags/跳槽/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"Mysql5.7主从配置保姆级别教程","slug":"Mysql5-7主从配置保姆级别教程","date":"2021-12-31T13:53:10.000Z","updated":"2022-01-01T11:54:30.116Z","comments":true,"path":"post/a1790e9a.html","link":"","permalink":"http://www.devcheng.net/post/a1790e9a.html","excerpt":"","text":"MySQL主从配置指一台服务器充当主数据库服务器，另一台或多台服务器充当从数据库服务器，主服务器中的数据自动复制到从服务器之中。 对于多级复制，数据库服务器即可充当主机，也可充当从机。MySQL主从复制的基础是主服务器对数据库修改记录二进制日志，从服务器通过主服务器的二进制日志自动执行更新。 一句话表示就是，主数据库做什么，从数据库就跟着做什么。 主从复制的工作原理① Master 数据库只要发生变化，立马记录到Binary log 日志文件中。② Slave数据库启动一个I/O thread连接Master数据库，请求Master变化的二进制日志。③ Slave I/O获取到的二进制日志，保存到自己的Relay log 日志文件中。④ Slave 有一个 SQL thread定时检查Realy log是否变化，变化那么就更新数据。 三种复制方式（1）STATEMENT模式：基于语句的复制，在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高。一旦发现没法精确复制时，会自动选择基于行的复制。 （2）ROW模式：基于行的复制，把改变的内容复制过去，而不是把命令在从服务器上执行一遍。从MySQL5.0开始支持。 （3）MIXED模式：混合类型复制，默认采用基于语句的复制，一旦发现基于语句无法精确复制时，就会采用基于行的复制。 主从配置的优点 提高数据库系统的可用性。读写分离，提高查询访问性能，有效减少主数据库访问压力。数据汇总，可将多个主数据库同步汇总到一个从数据库中，方便数据统计分析。实时灾备，主数据库出现故障时，可快速切换到从数据库。 环境准备建议本机安装虚拟机，准备两个MySQL，具体环境详情如下： 宿主机 centos7MySQL版本 5.7MySQL Master: 192.168.191.130MySQL Slave : 192.168.191.131 主库配置① 修改主库的 my.cnf 文件，添加如下配置。1vim /etc/my.cnf 123456789server-id=1 #服务器idlog-bin=mysql-bin #打开日志，master需要打开binlog-do-db=db_ly #这里写你需要同步的数据库名！这里一定要写对你要同步的数据库名binlog-ignore-db=mysql #忽略不需要同步给从库的数据库名binlog-ignore-db=information_schemabinlog-ignore-db=performance_schemabinlog-ignore-db=sysexpire_logs_days=7 #自动清理7天前的log文件,可根据需要修改 tips ：修改完成后按esc 按：wq 回车 保存并退出！ ② 重启mysql服务，输入以下命令。1service mysqld restart ③ 登录MySQL查看测试log_bin是否成功开启 （ON 代表已开启）1mysql -uroot -proot # 登录mysql 执行以下命令：1show variables like &apos;%log_bin%&apos;; 1234567891011121314151617181920212223242526[root@jenkins /]# mysql -uroot -proot mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 2Server version: 5.7.35-log MySQL Community Server (GPL)Copyright (c) 2000, 2021, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.mysql&gt; show variables like &apos;%log_bin%&apos;;+---------------------------------+--------------------------------+| Variable_name | Value |+---------------------------------+--------------------------------+| log_bin | ON || log_bin_basename | /var/lib/mysql/mysql-bin || log_bin_index | /var/lib/mysql/mysql-bin.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || sql_log_bin | ON |+---------------------------------+--------------------------------+6 rows in set (0.01 sec) ④ 创建master的数据库中建立备份账号：root 为用户名，%表示任何远程地址。如下表示密码为 root 的任何远程地址的root都可以连接master主机。1grant replication slave on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;root&apos;; ⑤ 查看刚刚创建的账号是否存在。123456789101112131415mysql&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select user,authentication_string,host from user;+---------------+-------------------------------------------+-----------+| user | authentication_string | host |+---------------+-------------------------------------------+-----------+| root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | localhost || mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost || mysql.sys | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost || root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | % |+---------------+-------------------------------------------+-----------+5 rows in set (0.00 sec) ⑥ 查看主服务器上当前的二进制日志名。1234567mysql&gt; show master status;+------------------+----------+--------------+-------------------------------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+-------------------------------------------------+-------------------+| mysql-bin.000001 | 439 | master | mysql,information_schema,performance_schema,sys | |+------------------+----------+--------------+-------------------------------------------------+-------------------+1 row in set (0.00 sec) Tips: 到此MySQL master的设置就设置完毕！ 从库设置 ① 修改从库的 my.cnf 文件，添加如下配置。1vim /etc/my.cnf 123server_id=2 #从库的服务器id，不能和主库的一样！切记！！！master_info_repository=TABLErelay_log_info_repostitory=TABLE ② 登录MySQL，设置上面主库对应的参数。1[root@localhost /]# mysql -uroot -proot 执行以下命令：123change master to master_host=&apos;192.168.191.130&apos;,master_user=&apos;root&apos;,master_password=&apos;root&apos;,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=439; 12345678910mysql&gt; stop slave #记得先关闭 -&gt; ;Query OK, 0 rows affected, 1 warning (0.04 sec)mysql&gt; change master to master_host=&apos;192.168.191.130&apos;, -&gt; master_user=&apos;root&apos;,master_password=&apos;root&apos;, -&gt; master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=439;Query OK, 0 rows affected, 2 warnings (0.04 sec)mysql&gt; start slave;#设置好了之后记得从新start slave ③ 查看slave 的状态，执行一下命令。1show slave status \\G 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960mysql&gt; show slave status \\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.191.130 Master_User: root Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000008 Read_Master_Log_Pos: 847 Relay_Log_File: localhost-relay-bin.000013 Relay_Log_Pos: 1060 Relay_Master_Log_File: mysql-bin.000008 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 847 Relay_Log_Space: 1437 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 99e35046-6492-11ec-b188-000c2902ba69 Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.01 sec) Slave_IO_Running: Yes Slave_SQL_Running: Yes看到 Slave_IO_Running 和 Slave_SQL_Running 均为YES 则说明我们配置的主从已经成功了！ 测试主从① 切换至主库，创建主库中指定的 db_ly 数据库测试一下。123456789101112mysql&gt; use db_ly;Database changedmysql&gt; mysql&gt; mysql&gt; mysql&gt; create table `tb_001`(`id` int(11) not null,`tb_user` int(11) not null,primary key(`id`)) engine=InnoDB DEFAULT CHARSET=latin1;Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into tb_001 value(&apos;1&apos;,&apos;1&apos;);Query OK, 1 row affected (0.09 sec)mysql&gt; ② 查看同步后的数据。 到此主从配置就成功了！ 常见问题集合 常见问题一： ERROR 2003 (HY000): Can’t connect to MySQL server on ‘192.168.191.130’ (113)解决方法：① 尝试远程连接数据库 (通常都是这个原因无法远程连上MySQL)1mysql -h192.168.191.130 -uroot -proot 如果无法登录 则使用下面命令：重新复权1234567grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;root&apos;;Query OK, 0 rows affected (0.00 sec)#这条命令也别忘记了flush privileges;Query OK, 0 rows affected (0.00 sec) 然后可以再次尝试远程登录MySQL。 ② 测试能否ping通远程IP1ping 192.168.191.130 ③ 如果IP是通的，则测试能否访问到端口。1telnet 192.168.191.130 3306 如果通不了，则说明防火墙是开启的，直接关闭防火墙即可（生产环境不推荐这么玩啊~）。 ④ 查看my.cnf文件是不是没有注释 bind-address = 127.0.0.1 常见问题二：Last_IO_Errno: 1593① 可能是server-id重复。 解决方法：任意选一个服务器修改对应的server-id 即可，输入命令如下，找到对应的 server-id 修改保存即可。1vim /etc/my.cnf ② 可能是server-uuid重复。一般导致这个问题就是在虚拟机中装好MySQL之后，直接copy导致的。 解决方法：先登录MySQL使用命令，产生一个uuid。1234567mysql&gt; select uuid();+--------------------------------------+| uuid() |+--------------------------------------+| 0eec5819-78a2-11e9-84d0-525400534aff |+--------------------------------------+1 row in set (0.04 sec) 然后修改其中一个MySQL的auto.cnf配置文件，修改完成后保存退出。 12345[root@centos-cluster-s19423 ~]# vim /var/lib/mysql/auto.cnf [auto]server-uuid=b1bfa5f4-6a95-11e9-8049-525400534aee~~ 重启这个MySQL即可。 tips: 如果主从配置有问题通常 Last_IO_Errno 和 Last_IO_Error 会有对应提示的错误码和错误信息。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.devcheng.net/tags/Mysql/"},{"name":"主从配置","slug":"主从配置","permalink":"http://www.devcheng.net/tags/主从配置/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于SpringBoot开发的新闻发布管理系统源码分享","slug":"基于SpringBoot开发的新闻发布管理系统源码分享","date":"2021-12-29T01:16:41.000Z","updated":"2021-12-29T02:00:15.458Z","comments":true,"path":"post/f563b3cc.html","link":"","permalink":"http://www.devcheng.net/post/f563b3cc.html","excerpt":"","text":"前言本项目是基于Spring Boot 2.x 开发的，新闻发布管理系统分为前台和后台两个部分。本项目可以当作毕业设计，期末课程作业等，也可以当作学习、进阶Spring Boot 的资料。 功能描述本项目前台系统主要是新闻数据展示，便于用户阅读对应的新闻，支持用户阅读新闻后留言和打赏的功能；后台新闻发布管理系统提供给管理员新增、编辑以及删除新闻等操作，同时支持新闻分类，新闻标签等功能操作。 主要功能有： 新闻搜索 新闻留言 新闻打赏 管理员登录 新闻管理 分类管理 标签管理 管理员退出 … 开发环境（运行环境） 系统环境：Windows 10 开发工具：IntelliJ IDEA 2020.3 Java版本：JDK 1.8 Mysql版本：5.7 Maven版本：3.6.3 项目技术栈 Spring Boot 2.3.X.RELEASE Spring Boot JPA Maven 3.X Mysql thymeleaf Semantic UI 2.4.2 Jquery … 登录地址访问路径：http://localhost:8082 管理员登录路径：http://localhost:8082/admin管理员账号： admin管理员密码： 123456 项目截图 联系我们如有需要源码可以通过QQ 搜索：792435323联系我！请备注：新闻发布系统 项目演示视频链接: https://pan.baidu.com/s/1VAnfIm4UnZ2gwZJvjWRTyQ提取码: gjk2 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的NewsApplication直接运行吧！ 其它说明白嫖怪请绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://www.devcheng.net/tags/springboot/"},{"name":"新闻发布管理系统","slug":"新闻发布管理系统","permalink":"http://www.devcheng.net/tags/新闻发布管理系统/"},{"name":"毕设","slug":"毕设","permalink":"http://www.devcheng.net/tags/毕设/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"基于SpringBoot开发的宠物管理系统源码分享","slug":"基于SpringBoot开发的宠物管理系统源码分享","date":"2021-12-16T11:48:47.000Z","updated":"2021-12-16T12:04:46.600Z","comments":true,"path":"post/eb48f8f9.html","link":"","permalink":"http://www.devcheng.net/post/eb48f8f9.html","excerpt":"","text":"前言本项目是基于Spring Boot 2.x 开发的，宠物管理系统分为前台系统和后台数据管理系统，可以当作毕业设计，期末课程作业等，也可以当作学习、进阶Spring Boot 的资料。 项目描述本项目前台系统主要是数据展示，提供给用户领养宠物和购买宠物用品等功能；后台数据管理系统分为普调用户和管理员两种角色。管理员可以管理用户，宠物信息，商品信息，订单信息等。 主要功能有： 数据分析 会员管理 宠物信息管理 管理员管理 商品管理 订单管理 登录&amp;注册功能 购物车功能 个人信息功能 宠物领养功能 … 开发环境（运行环境）系统环境：Windows 10 开发工具：IntelliJ IDEA 2020.3 Java版本：JDK 1.8 Mysql版本：5.7 Maven版本：3.6.3 项目技术栈 Spring Boot 2.3.7.RELEASE Mybatis Maven 3.X Mysql thymeleaf Layui Jquery Echarts … 登录地址http://localhost:8081/index管理员账号： admin@pet.com管理员密码： 1234qwer 其它用户账号密码默认均为：1234qwer 项目截图 联系我们如有需要源码可以通过QQ 搜索：792435323联系我！请备注：宠物管理系统 项目演示视频链接: https://pan.baidu.com/s/1pvYZIQ3DmBqfXw13AhuhkA提取码: gid8 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的PetManagerApplication直接运行吧！ 其它说明白嫖怪请绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.devcheng.net/tags/SpringBoot/"},{"name":"毕业设计","slug":"毕业设计","permalink":"http://www.devcheng.net/tags/毕业设计/"},{"name":"宠物管理系统","slug":"宠物管理系统","permalink":"http://www.devcheng.net/tags/宠物管理系统/"},{"name":"源码","slug":"源码","permalink":"http://www.devcheng.net/tags/源码/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"java设计模式之抽象工厂模式","slug":"java设计模式之抽象工厂模式","date":"2021-12-13T12:54:39.000Z","updated":"2021-12-13T13:01:38.174Z","comments":true,"path":"post/6f820280.html","link":"","permalink":"http://www.devcheng.net/post/6f820280.html","excerpt":"","text":"抽象工厂模式介绍抽象工厂模式的定义：为创建一组相关或者互相依赖的对象提供一个接口，而无需指定它们对应的具体类。 具体可以这样理解，世界各地都有自己的水果园，我们将这些水果园抽象为一个水果园接口，在中国、英国和美国都有水果园，种植不同的水果，比如苹果、香蕉和梨等。这里将苹果进行抽象，所以，苹果又分为中国苹果，英国苹果和美国苹果。中国的水果园中有苹果、香蕉和梨等。抽象工厂中声明生产苹果、香蕉和梨等水果，那么具体的工厂相当于中国、英国和美国的水果园，各个水果园负责生产水果、香蕉和梨等。 抽象工厂模式UML类图 对比工厂方法模式，通过它们之间的类图对比，得知工厂方法模式中也是可以有多个具体工厂，也是可以有多个抽象产品，和多个具体工厂、具体产品类。 区别是在抽象工厂接口类中，能创建几个产品对象。抽象工厂模式的工厂能创建多个相关的产品对象，而工厂方法模式的工厂只创建一个产品对象。 举个例子利用抽象工厂模式演示文中开头提及的世界各地都有自己的水果园的理解，下面请看代码。 1.创建Fruit接口、Apple抽象类、ChinaApple类等 Fruit(interface):123public interface Fruit &#123; public void get();&#125; Apple抽象类:123public abstract class Apple implements Fruit&#123; public abstract void get();&#125; ChinaApple类:1234567public class ChinaApple extends Apple &#123; @Override public void get() &#123; System.out.println(\"中国的苹果...\"); &#125;&#125; 2.创建抽象工厂、具体工厂 抽象工厂：123456public interface FruitFactory &#123; //实例化苹果 public Fruit getApple(); //实例化香蕉 public Fruit getBanana();&#125; 具体工厂：123456789101112 public class ChinaFactory implements FruitFactory &#123; @Override public Fruit getApple() &#123; return new ChinaApple(); &#125; @Override public Fruit getBanana() &#123; return new ChinaBanana(); &#125;&#125; 客户端调用12345678910111213141516171819202122public class MainClass &#123; public static void main(String[] args)&#123; //创建中国工厂 FruitFactory chinaFactory = new ChinaFactory(); //通过中国工厂生产中国苹果实例 Fruit apple = chinaFactory.getApple(); apple.get(); //通过中国工厂生产中国香蕉实例 Fruit banana = chinaFactory.getBanana(); banana.get(); //创建英国工厂 FruitFactory englandFactory = new EnglandFactory(); //通过英国工厂生产英国苹果实例 Fruit apple1 = englandFactory.getApple(); apple1.get(); //通过英国工厂生产英国香蕉实例 Fruit banana2 = englandFactory.getBanana(); banana2.get(); &#125;&#125; 结果输出如下： 抽象工厂模式的优缺点优点： 1.针对同一组产品创建新的生产线，只需实现那组产品的抽象工厂接口即可创建新的工厂类。 缺点：抽象工厂模式的最大缺点就是产品族本身的扩展非常困难。如果在产品族中增加一个新的产品类型，则需要修改多个接口，并影响现已有的工厂类。 抽象工厂模式使用案例1.在JDK中的应用，Collection接口 Collection就是一个抽象工厂，它提供了一个产品类的库，所有产品都以同样接口出现，从而使客户端不依赖于具体实现。工厂方法则是抽象工厂里面的其中一个产品类，并且把这个方法的实例化放入具体的实现类中 。 小结工厂模式有三种：简单工厂模式，工厂方法模式，抽象工厂模式。三种工厂模式个人感觉最大的区别就是，每种模式抽象的层级不一样，抽象的程度不一样。不存在那种设计模式比较好，存在即合理。特定场景使用符合的设计模式才是正确的选择。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"http://www.devcheng.net/tags/java设计模式/"},{"name":"抽象工厂模式","slug":"抽象工厂模式","permalink":"http://www.devcheng.net/tags/抽象工厂模式/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"java设计模式之工厂方法模式","slug":"java设计模式之工厂方法模式","date":"2021-12-12T06:42:49.000Z","updated":"2021-12-12T06:49:29.896Z","comments":true,"path":"post/bca6e87b.html","link":"","permalink":"http://www.devcheng.net/post/bca6e87b.html","excerpt":"","text":"工厂方法模式介绍定义了一个创建对象的抽象方法，由子类决定要实例化的类，工厂方法模式将对象的实例化推迟到子类。 介绍工厂方法模式之前，整个工厂方法模式分为： 简单工厂模式，工厂方法模式，抽象工厂模式三种。 简单工厂模式 的创建意图就是，把对类的创建初始化全都交给一个工厂来执行，而用户不需要去关心创建的过程是什么样的，只用告诉工厂我想要什么就行了。 而这种方法的缺点也很明显，违背了设计模式的开闭原则，因为如果你要增加工厂可以初始化的类的时候，你必须对工厂进行改建。 工厂方法模式UML类图 模式结构ConcreteCreator： 抽象工厂角色，担任这个角色是工厂方法模式的核心，它是与应用程序无关的。任何在模式中创建对象的工厂类必须实现这个接口。 Creator： 具体工厂角色，担任这个角色的是实现了抽象工厂接口的具体Java类，具体工厂角色含有与应用密切相关的逻辑，并且受到应用程序的调用以创建产品对象。 ConcreteProduct： 抽象产品角色，工厂方法模式所创建的对象的超类型，也就是产品对象的共同父类或共同拥有的接口。 Product： 具体产品角色，这个角色实现了抽象产品角色所申明的接口。工厂方法模式所创建的每一个对象都是某个具体产品角色的实例。 举个栗子一个厨师（工厂类）负责所有的烤披萨任务，太累了。于是招了两个厨师分别负责烤披萨和切披萨，之前的厨师升级为厨师长（抽象工厂类），负责教那两位厨师（具体工厂类）烤披萨，自己则不用亲自动手烤披萨了。 下面是抽象产品的角色Pizza的源代码： 12345public abstract class Pizza&#123; public abstract void prepare(); public abstract void bake(); public abstract void cut();&#125; 具体角色CheesePizza的源代码1234567891011121314public class CheesePizza extends Pizza&#123; public void prepare()&#123; System.out.pringln(\"准备CheesePizza\"); &#125; public void bake()&#123; System.out.pringln(\"准备CheesePizza\"); &#125; public void cut()&#123; System.out.pringln(\"准备CheesePizza\"); &#125; public void box()&#123; System.out.pringln(\"准备CheesePizza\"); &#125;&#125; 具体角色GreekPizza的源代码1234567891011121314public class GreekPizza extends Pizza&#123; public void prepare()&#123; System.out.pringln(\"准备GreekPizza\"); &#125; public void bake()&#123; System.out.pringln(\"准备GreekPizza\"); &#125; public void cut()&#123; System.out.pringln(\"准备GreekPizza\"); &#125; public void box()&#123; System.out.pringln(\"准备GreekPizza\"); &#125;&#125; 抽象工厂角色PizzaFactory的代码，这个角色是使用一个Java接口实现，它声明了一个工厂方法，要求所有的具体工厂角色实现这个工厂方法：1234public interface PizzaFactory&#123; //工厂方法 public Pizza createPizza();&#125; 下面是具体工厂角色CheesePizzaFactory的代码，这个角色实现了抽象工厂角色PizzaFactory所声明的工厂方法：123456public class CheesePizzaFactory implements PizzaFactory&#123; @Override public Pizza createPizza()&#123; return new CheesePizza(); &#125;&#125; 具体工厂角色GreekPizzaFactory的代码，这个角色实现了抽象工厂角色PizzaFactory所声明的工厂方法：123456public class GreekPizzaFactory implements PizzaFactory&#123; @Override public Pizza createPizza()&#123; return new GreekPizza(); &#125;&#125; 客户端角色的源代码：123456789101112131415161718public class OrderPizaa&#123; public static void main(String[] args)&#123; //创建CheesePizzaFactory--具体工厂类 //可以通过反射和配置文件来获取和存储具体工厂类的类名，更换新的具体工厂时无须修改源代码，系统扩展更为方便 PizzaFactory factory = new CheesePizzaFactory(); Pizza pizza = factory.createPizza(); pizza.prepare(); pizza.bake(); pizza.cut(); pizza.box(); //创建GreekPizzaFactory()--具体工厂类 pizza = factory.createPizza(); pizza.prepare(); pizza.bake(); pizza.cut(); pizza.box(); &#125;&#125; 输出结果如下：12345678准备CheesePizza正在烤CheesePizza正在切CheesePizza正在打包CheesePizza准备GreekPizza正在烤GreekPizza正在切GreekPizza正在打包GreekPizza 工厂方法模式的优缺点 优点： 1.遵循开闭原则，新增产品类时只需要增加相应的工厂以及产品即可，不需要修改原有的代码。 2.符合单一职责原则，每个工厂类只负责一种产品的创建 3.使用非静态方法来创建产品，利于后续对产品的拓展，可拓展性增加 缺点：1.一个工厂只能创建一种产品2.每次增加新的产品时都需要增加对应的工厂类，当产品越来越多的时候系统创建的工厂类就越多，越来越复杂，不利于后期维护。同时，类的创建和销毁可能会对系统造成一定的开销。 工厂方法模式使用案例1.JDK中体现：Collection.iterator方法 12345678910111213141516171819202122232425262728public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; /** * An optimized version of AbstractList.Itr */ private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings(\"unchecked\") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; Collection接口里面定义了许多方法就像size(),isEmpty(),iterator()等等这些方法可以认为是工厂里面的产品，Collection可以看作是一个总的抽象工厂。 它的一些实现这个接口的类，像ArrayList，LinkedHashSet等等可以看作一个个不同的品牌的工厂，而总的产品Iterator接口里面会定义产品所需功能的细节，然后在交给各个品牌不同的工厂来实现。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"http://www.devcheng.net/tags/java设计模式/"},{"name":"工厂方法模式","slug":"工厂方法模式","permalink":"http://www.devcheng.net/tags/工厂方法模式/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"java设计模式之建造者模式","slug":"java设计模式之建造者模式","date":"2021-12-06T11:56:18.000Z","updated":"2021-12-06T12:15:47.565Z","comments":true,"path":"post/cae13d29.html","link":"","permalink":"http://www.devcheng.net/post/cae13d29.html","excerpt":"","text":"建造者模式介绍建造者模式，顾名思义的就是类似建房子，有一个固定的流程。在大话设计模式中，有一个例子大概意思是同一道菜在中国的每一个地方都有不同的味道，而肯德基的鸡腿、汉堡在每一个城市都是一样的味道。我觉的这一个例子可以清楚的认识到建造者模式有一个固定的建造过程。建造者模式实现了依赖倒转原则，抽象不应该依赖细节，细节应该依赖与抽象。 建造者模式的定义是：将一个复杂对象的构造与它的表示分离，使同样的构建过程可以创建不同的表示，这样的设计模式被称为建造者模式。 建造者模式UML类图 模式结构Builder： 抽象建造者角色。为创建一个产品对象的各个部件指定抽象接口。 ConcreteBuilder：具体建造者角色。实现Builder的接口以构造和装配该产品的各个部件，定义并明确它所创建的表示，并提供一个检索产品的接口。 Director：指挥者角色。该角色负责调用具体建造者按照顺序建造产品。只负责调度，真正执行的是具体建造者角色。 Product：产品角色。该角色是建造的复杂对象，提供基本方法 举个栗子假如现在要造两辆豪车，一辆是兰博基尼，一辆是法拉利。那怎么用代码实现造这两辆豪车呢？首先看产品角色代码，如下： 1234567891011121314151617181920public class Production &#123; private String part1; private String part2; public String getPart1() &#123; return part1; &#125; public void setPart1(String part1) &#123; this.part1 = part1; &#125; public String getPart2() &#123; return part2; &#125; public void setPart2(String part2) &#123; this.part2 = part2; &#125;&#125; 抽象建造者角色代码如下：1234567891011public interface IBuilder &#123; // 产品有多少个组件，就有多少个建造方法 public void buildPart1(); public void buildPart2(); // 返回产品类 public Production build();&#125; 开始造兰博基尼： 12345678910111213141516171819202122 public class BuilderA implements IBuilder &#123; private Production production = new Production(); @Override public void buildPart1() &#123; System.out.println(\"构造兰博基尼的第一部分。\"); production.setPart1(\"This is part1 of Lamborghini\"); &#125; @Override public void buildPart2() &#123; System.out.println(\"构造兰博基尼的第二部分。\"); production.setPart2(\"This is part2 of Lamborghini\"); &#125; @Override public Production build() &#123; System.out.println(\"兰博基尼已造好！\"); return production; &#125;&#125; 开始造法拉利：12345678910111213141516171819202122public class BuilderB implements IBuilder &#123; private Production production = new Production(); @Override public void buildPart1() &#123; System.out.println(\"构造法拉利的第一部分。\"); production.setPart1(\"This is part1 of Ferrari\"); &#125; @Override public void buildPart2() &#123; System.out.println(\"构造法拉利的第二部分。\"); production.setPart2(\"This is part2 of Ferrari\"); &#125; @Override public Production build() &#123; System.out.println(\"法拉利已造好！\"); return production; &#125;&#125; 指挥者调度构建，返回对应产品。代码如下：123456789101112131415161718public class Director &#123; private IBuilder builder; public Director(IBuilder builder)&#123; this.builder = builder; &#125; /** * 构造顺序 */ public Production construct()&#123; builder.buildPart1(); builder.buildPart2(); return builder.build(); &#125;&#125; 客户端调用一下，查看输出结果：12345678910111213141516public class Client &#123; public static void main(String[] args) &#123; // 兰博基尼 IBuilder builderA = new BuilderA(); Director directorA = new Director(builderA); directorA.construct(); // 法拉利 IBuilder builderB = new BuilderB(); Director directorB = new Director(builderB); directorB.construct(); &#125;&#125; 输出结果如下：1234567构造兰博基尼的第一部分。构造兰博基尼的第二部分。兰博基尼已造好！构造法拉利的第一部分。构造法拉利的第二部分。法拉利已造好！ 建造者模式的优缺点 优点：1.封装性好，创建和使用分离2.扩展性好，建造类之间独立，一定程度上实现了解耦 缺点：1.产生多余的Builder对象2.产品内部发生变化时，建造者都需要修改，成本较大 建造者模式使用案例1.Spring框架中使用建造者模式Spring中的UriComponents和UriComponentsBuilder UriComponents基本方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140public abstract class UriComponents implements Serializable &#123; private static final String DEFAULT_ENCODING = \"UTF-8\"; // 用于分割uri的正则表达式，下面会说到 private static final Pattern NAMES_PATTERN = Pattern.compile(\"\\\\&#123;([^/]+?)\\\\&#125;\"); private final String scheme; private final String fragment; protected UriComponents(String scheme, String fragment) &#123; this.scheme = scheme; this.fragment = fragment; &#125; // 多个Components对应的getter方法 /** * 返回URL的scheme. */ public final String getScheme() &#123; return this.scheme; &#125; /** * 返回URL的fragment. */ public final String getFragment() &#123; return this.fragment; &#125; /** * 返回URL的schemeSpecificPar */ public abstract String getSchemeSpecificPart(); /** * 返回userInfo */ public abstract String getUserInfo(); /** * 返回URL的host */ public abstract String getHost(); /** * 返回URL的port */ public abstract int getPort(); /** * 返回URL的path */ public abstract String getPath(); /** * 返回URL的path部分的集合 */ public abstract List&lt;String&gt; getPathSegments(); /** * 返回URL的query部分 */ public abstract String getQuery(); /** * 返回URL的query参数map */ public abstract MultiValueMap&lt;String, String&gt; getQueryParams(); /** * 将URL的components用特定的编码规则编码并返回，默认为utf-8 */ public final UriComponents encode() &#123; try &#123; return encode(DEFAULT_ENCODING); &#125; catch (UnsupportedEncodingException ex) &#123; // should not occur throw new IllegalStateException(ex); &#125; &#125; /** * 编码的抽象方法，传入相应的编码规则 */ public abstract UriComponents encode(String encoding) throws UnsupportedEncodingException; /** * 将URL中的模板参数换成对应的值 */ public final UriComponents expand(Map&lt;String, ?&gt; uriVariables) &#123; Assert.notNull(uriVariables, \"'uriVariables' must not be null\"); return expandInternal(new MapTemplateVariables(uriVariables)); &#125; /** * 将URL中的模板参数换成对应的值，输入为数组 */ public final UriComponents expand(Object... uriVariableValues) &#123; Assert.notNull(uriVariableValues, \"'uriVariableValues' must not be null\"); return expandInternal(new VarArgsTemplateVariables(uriVariableValues)); &#125; /** * 将URL中的模板参数换成对应的值，输入为UriTemplateVariables */ public final UriComponents expand(UriTemplateVariables uriVariables) &#123; Assert.notNull(uriVariables, \"'uriVariables' must not be null\"); return expandInternal(uriVariables); &#125; /** * 将URL中的模板参数换成对应的值的最终的实现方法 */ abstract UriComponents expandInternal(UriTemplateVariables uriVariables); /** * 处理URL */ public abstract UriComponents normalize(); /** * 返回URL的string */ public abstract String toUriString(); /** * 返回URI格式的方法 */ public abstract URI toUri(); @Override public final String toString() &#123; return toUriString(); &#125; /** * 将这些Components的值赋给其builder类 */ protected abstract void copyToUriComponentsBuilder(UriComponentsBuilder builder); //……&#125; UriComponentsBuilder类1234567891011121314151617181920/** * 默认构造方法，其中path的构造类为CompositePathComponentBuilder，它为UriComponentsBuilder的内部静态类，主要实现对url的path部分进行构造。 */ protected UriComponentsBuilder() &#123; this.pathBuilder = new CompositePathComponentBuilder(); &#125; /** * 创建一个传入UriComponentsBuilder类的深拷贝对象 */ protected UriComponentsBuilder(UriComponentsBuilder other) &#123; this.scheme = other.scheme; this.ssp = other.ssp; this.userInfo = other.userInfo; this.host = other.host; this.port = other.port; this.pathBuilder = other.pathBuilder.cloneBuilder(); this.queryParams.putAll(other.queryParams); this.fragment = other.fragment; &#125; 2.JDK中使用建造者模式JDK中的StringBuilder1234567891011121314151617181920212223242526272829public StringBuilder append(boolean b) &#123; super.append(b); return this;&#125;public StringBuilder append(char c) &#123; super.append(c); return this;&#125;public StringBuilder append(int i) &#123; super.append(i); return this;&#125;public StringBuilder append(long lng) &#123; super.append(lng); return this;&#125;public StringBuilder append(float f) &#123; super.append(f); return this;&#125;public StringBuilder append(double d) &#123; super.append(d); return this;&#125; 由上图我们可以看出StringBuilder继承了AbstractStringBuilder，而AbstractStringBuilder实现了appendable。 StringBuilder：指挥者类，持有具体建造者的引用，由于StringBuilder继承了AbstractStringBuilder，这里StringBuilder通过super来作为具体建造者的引用。AbstractStringBuilder：具体建造者，它实现了appendable接口的append(Character c)方法。appendable：抽象建造者，定义了创建对象的接口。StringBuilder的append(Character c)方法： tips：基本上看到源码中以 Builder 结尾的类，大多数都属于 建造者模式~ The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"http://www.devcheng.net/tags/java设计模式/"},{"name":"建造者模式","slug":"建造者模式","permalink":"http://www.devcheng.net/tags/建造者模式/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"java设计模式之原型模式","slug":"java设计模式之原型模式","date":"2021-11-28T09:05:26.000Z","updated":"2021-11-28T09:16:32.711Z","comments":true,"path":"post/4365a411.html","link":"","permalink":"http://www.devcheng.net/post/4365a411.html","excerpt":"","text":"原型模式的介绍用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。在这里，原型实例指定了要创建的对象的种类。用这种方式创建对象非常高效，根本无须知道对象创建的细节。 这种模式存在的应用场景在于，能够复制当前对象，实现对象数据的克隆。比如：如果一个对象的数据需要经过较高代价的数据库操作，采用原型模式能够较好的缓存当前对象，减少数据库的访问量。 原型模式UML类图 模式结构原型模式包含如下角色：Prototype：抽象原型类ConcretePrototype：具体原型类Client：客户类 举个栗子在日本动漫《火影忍者》中鸣人有一个忍术叫影分身之术，使用查克拉制造出有实体的分身，它们可以和施术者一样行动战斗，具有独立于施术者本体的意识和一定的抗击打能力，解除后分身的记忆和经验会回到本体。 简言之，就是一个鸣人分身后变成了多个一模一样的鸣人，如同把一个鸣人复制出来了N个鸣人，其实这种场景就是我们所说的原型模式。 实例源码 MingRen 原型类 12345678910111213141516171819202122 public class MingRen implements Cloneable&#123; public String name = \"鸣人\"; public int age = 12; public String skill = \"影分身之术\"; public MingRen() &#123; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; @Override public String toString() &#123; return \"MingRen&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + \", skill='\" + skill + '\\'' + '&#125;'; &#125;&#125; Client类 1234567public static void main(String[] args) throws CloneNotSupportedException &#123; MingRen mingRen = new MingRen(); MingRen mingRen2 = (MingRen)mingRen.clone(); System.out.println(mingRen); System.out.println(mingRen2); System.out.println(mingRen == mingRen2);&#125; 程序的运行结果如下：12345MingRen&#123;name=&apos;鸣人&apos;, age=12, skill=&apos;影分身之术&apos;&#125;MingRen&#123;name=&apos;鸣人&apos;, age=12, skill=&apos;影分身之术&apos;&#125;falseProcess finished with exit code 0 由以上源码我们可以得知，核心就是类图中的原型类。原型类需要具备以下两个条件：实现Cloneable接口。在java语言有一个Cloneable接口，它的作用只有一个，就是在运行时通知虚拟机可以安全地在实现了此接口的类上使用clone方法。在java虚拟机中，只有实现了这个接口的类才可以被拷贝，否则在运行时会抛出CloneNotSupportedException异常。重写Object类中的clone方法。默认是浅拷贝。 浅拷贝和深拷贝的说明，就不展开聊了，可参考下文了解。点击了解 java对象的浅克隆和深克隆 原型模式的优缺点优点： 1.快速创建复杂对象实例，同时也提高了效率。 2.不用重新初始化对象，而是动态获得对象运行时的状态。 3.如果原始对象发生变化（增加或减少字段）其它克隆对象也会发生相应变化，无需修改代码。 缺点： 1.必须实现Cloneable接口。 2.实现深克隆的时候可能需要比较复杂的代码。 3.需要为每一个类配备一个克隆方法，这对全新的类来说不是很难，但对已有的类进行改造时，需要修改其源代码，违背了 ocp 原则。 原型模式使用案例1、Spring 中原型 bean 的创建，使用到了原型设计模式。 Tips：原型模式也叫克隆模式！ The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"http://www.devcheng.net/tags/java设计模式/"},{"name":"原型模式","slug":"原型模式","permalink":"http://www.devcheng.net/tags/原型模式/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"java设计模式之单例模式","slug":"java设计模式之单例模式","date":"2021-11-27T08:35:03.000Z","updated":"2021-11-27T08:54:30.886Z","comments":true,"path":"post/23a824cc.html","link":"","permalink":"http://www.devcheng.net/post/23a824cc.html","excerpt":"","text":"单例模式的介绍单例模式的定义就是确保某一个类只有一个实例，并且提供一个全局访问点。主要有三个特点： 只有一个实例。 自我实例化。 提供全局访问点。 当系统中只需要一个实例对象或者系统中只允许一个公共访问点，除了这个公共访问点外，不能通过其他访问点访问该实例时，就可以使用单例模式。 单例模式UML类图 单例模式的八种方式饿汉式（静态常量）饿汉式（静态代码块）懒汉式（线程不安全）懒汉式（线程安全，同步方法）懒汉式（线程安全，同步代码块）双重检查静态内部类枚举 1、饿汉式（静态常量）【可用】 1234567public class Singleton &#123; private final static Singleton INSTANCE = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return INSTANCE; &#125;&#125; 优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同步问题。缺点：在类装载的时候就完成实例化，没有达到Lazy Loading的效果。如果从始至终从未使用过这个实例，则会造成内存的浪费。 这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载时就实例化，在单例模式中大多数都是调用getlnstance方法，但是导致类装载的原因有很多种，因此不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance就没有达到 lazy loading的效果。 结论：这种单例模式可用，可能造成内存浪费。 2、饿汉式（静态代码块）【可用】 12345678910public class Singleton &#123; private static Singleton instance; static &#123; instance = new Singleton(); &#125; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 这种方式和上面的方式其实类似，只不过将类实例化的过程放在了静态代码块中，也是在类装载的时候，就执行静态代码块中的代码，初始化类的实例。优缺点和上面是一样的。 结论：这种单例模式可用，但可能造成内存浪费。 3、懒汉式（线程不安全）【不可用】 12345678910public class Singleton &#123; private static Singleton singleton; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; return singleton; &#125;&#125; 优点：起到了Lazy Loading的效果，但是只能在单线程下使用。缺点：在多线程下，一个线程进入if (singleton == null)判断语句块，还没来得及往下执行，另一个线程也通过这个判断语句，这时便会产生多个实例。所以在多线程环境下不可使用这种方式。 结论：在实际开发中，不要使用这种方式。 4、懒汉式（线程安全，同步方法）【不推荐使用】 12345678910public class Singleton &#123; private static Singleton singleton; private Singleton() &#123;&#125; public static synchronized Singleton getInstance() &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; return singleton; &#125;&#125; 优点：解决了线程不安全问题。缺点：效率太低了，每个线程想获得类的实例的时候，执行getInstance()方法都要进行同步。其实这个方法只执行一次实例化代码就可以了，后面的想获得类的实例，直接return就行了，方法进行同步效率太低。 结论：在实际开发中，不推荐使用这种方式。 5、懒汉式（线程安全，同步代码块）【不可用】 123456789101112public class Singleton &#123; private static Singleton singleton; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; singleton = new Singleton(); &#125; &#125; return singleton; &#125;&#125; 优点：这种方式本意是想对第四种方式的改进，以为前面同步方法效率太低，改为同步产生实例化的代码块。缺点：这种同步不能起到线程同步的作用。和第三种方式遇到的情形一致，如果一个线程进入了if (singleton == null) 判断语句块，还未来的及往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例。 结论：在实际开发中，不能使用这种方式。 6、双重检查 【推荐使用】 1234567891011121314public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 优点：Double Check概念是多线程开发中常使用到的，如代码中所示，我们进行两次 if (singleton == null)检查，这样可以保证线程安全。实例化代码只用执行一次，后面再次访问时，判断if (singleton == null)的时候，直接return实例化对象，也避免了反复进行方法同步。线程安全，延迟加载，效率较高。 结论：在实际开发中，推荐使用这种方式。 7、静态内部类 【推荐使用】 123456789public class Singleton &#123; private Singleton() &#123;&#125; private static class SingletonInstance &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonInstance.INSTANCE; &#125;&#125; 这种方式采用了类装载的机制来保证初始化实例时只有一个线程。静态内部类方式在singleton类被装载时并不会立即实例化，而是在需要实例化时，调用getInstance方法，才会装载singletonInstance类，从而完成Singleton的实例化。类的静态属性只会在第一次加载类的时候初始化，所以在这里，ⅣM帮助我们保证了线程的安全性，在类进行初始化时，别的线程是无法进入的。 优点：避免了线程不安全，利用静态内部类特点实现了延迟加载，效率高。 结论：在实际开发中，推荐使用。 8、枚举 [推荐使用] 12345public enum Singleton &#123; INSTANCE; public void whateverMethod() &#123; &#125;&#125; 优点：借助JDK1.5中添加的枚举来实现单例模式。不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象。 结论：推荐使用。 单例模式使用案例1、Runtime类中使用了饿汉式单例模式。如下代码： 12345678910111213141516171819public class Runtime &#123; private static Runtime currentRuntime = new Runtime(); /** * Returns the runtime object associated with the current Java application. * Most of the methods of class &lt;code&gt;Runtime&lt;/code&gt; are instance * methods and must be invoked with respect to the current runtime object. * * @return the &lt;code&gt;Runtime&lt;/code&gt; object associated with the current * Java application. */ public static Runtime getRuntime() &#123; return currentRuntime; &#125; /** Don't let anyone else instantiate this class */ private Runtime() &#123;&#125;&#125; 2、Spring源码中 AbstractBeanFactory 的 getBean 里， getBean 的 doGetBean 方法调用 getSingleton 进行bean的创建。 1234567891011121314151617181920212223242526272829303132/** * Return the (raw) singleton object registered under the given name. * &lt;p&gt;Checks already instantiated singletons and also allows for an early * reference to a currently created singleton (resolving a circular reference). * @param beanName the name of the bean to look for * @param allowEarlyReference whether early references should be created or not * @return the registered singleton object, or &#123;@code null&#125; if none found */ @Nullable protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject; &#125; 从上面代码可以看到，spring依赖注入时，使用了 双重判断加锁 的单例模式。 3、Spring aop中的GlobalAdvisorAdapterRegistry类 1234567891011121314151617181920212223242526272829303132/** * Singleton to publish a shared DefaultAdvisorAdapterRegistry instance. * * @author Rod Johnson * @author Juergen Hoeller * @author Phillip Webb * @see DefaultAdvisorAdapterRegistry */ public final class GlobalAdvisorAdapterRegistry &#123; private GlobalAdvisorAdapterRegistry() &#123; &#125; /** * Keep track of a single instance so we can return it to classes that request it. */ private static AdvisorAdapterRegistry instance = new DefaultAdvisorAdapterRegistry(); /** * Return the singleton &#123;@link DefaultAdvisorAdapterRegistry&#125; instance. */ public static AdvisorAdapterRegistry getInstance() &#123; return instance; &#125;&#125; The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"http://www.devcheng.net/tags/java设计模式/"},{"name":"单例模式","slug":"单例模式","permalink":"http://www.devcheng.net/tags/单例模式/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"JAVA之UML类图学习笔记","slug":"JAVA之UML类图学习笔记","date":"2021-11-16T12:09:40.000Z","updated":"2021-11-16T12:25:01.624Z","comments":true,"path":"post/385bde4f.html","link":"","permalink":"http://www.devcheng.net/post/385bde4f.html","excerpt":"","text":"JAVA之UML类图学习笔记学习设计模式必不可少需要了解熟悉各个模式的UML类图，为了了解每个设计模式之间各个类的关系和结构很有必要学习一下UML类图。 UML统一建模语言（Unified Modeling Language，UML）是用来设计软件蓝图的可视化建模语言，1997 年被国际对象管理组织（OMG）采纳为面向对象的建模语言的国际标准。它的特点是简单、统一、图形化、能表达软件设计中的动态与静态信息。 统一建模语言能为软件开发的所有阶段提供模型化和可视化支持。而且融入了软件工程领域的新思想、新方法和新技术，使软件设计人员沟通更简明，进一步缩短了设计时间，减少开发成本。它的应用领域很宽，不仅适合于一般系统的开发，而且适合于并行与分布式系统的建模。 UML 从目标系统的不同角度出发，定义了用例图、类图、对象图、状态图、活动图、时序图、协作图、构件图、部署图等9种图。 类和接口类（Class）指具有相同属性、方法和关系的对象的抽象，它封装了数据和行为，是面向对象程序设计（OOP）的基础，具有封装性、继承性和多态性等三大特性。 在UML中，类使用包含类名、属性和操作且带有分隔线的矩形来表示。 (1) 类名（Name）是一个字符串，例如，School。 (2) 属性（Attribute）是指类的特性，即类的成员变量。UML 按以下格式表示： 1[可见性]属性名:类型[=默认值] 举个栗子： -name:String tips: “可见性” 指的是该属性对类外的元素是否可见。 类图中表示可见性的符号如下： + public - private # protected ~ package (3) 操作（Operations）是类的任意一个实例对象都可以使用的行为，是类的成员方法。UML 按以下格式表示 1[可见性]名称(参数列表)[:返回类型] 举个栗子，类的表示参考下图： 接口 （interface）接口是指对象行为的描述，一个类可有一个或多个接口。 类图类图（ClassDiagram）是用来显示系统中的类、接口、协作以及它们之间的静态结构和关系的一种静态模型。它主要用于描述软件系统的结构化设计，帮助人们简化对软件系统的理解，它是系统分析与设计阶段的重要产物，也是系统编码与测试的重要模型依据。 类之间的关系UML 中的类图有以下几种关系： 依赖关系（Dependency）、关联关系（Association）、聚合关系（Aggregation）、组合关系（Composition）、泛化关系（Generalization）和实现关系 (Realization)。 其中泛化和实现的耦合度相等，它们是最强的。 依赖关系依赖（Dependency）关系是一种使用关系，它是对象之间耦合度最弱的一种关联方式，是临时性的关联。在代码中，某个类的方法通过局部变量、方法的参数或者对静态方法的调用来访问另一个类（被依赖类）中的某些方法来完成一些职责。 在 UML 类图中，依赖关系使用带箭头的虚线来表示，箭头从使用类指向被依赖的类。图所示是人与手机的关系图，人通过手机的语音传送方法打电话。 关联关系关联（Association）关系是对象之间的一种引用关系，用于表示一类对象与另一类对象之间的联系，如老师和学生、师傅和徒弟、丈夫和妻子等。关联关系是类与类之间最常用的一种关系，分为一般关联关系、聚合关系和组合关系。我们先介绍一般关联。 关联可以是双向的，也可以是单向的。在 UML 类图中，双向的关联可以用带两个箭头或者没有箭头的实线来表示，单向的关联用带一个箭头的实线来表示，箭头从使用类指向被关联的类。也可以在关联线的两端标注角色名，代表两种不同的角色。 在代码中通常将一个类的对象作为另一个类的成员变量来实现关联关系。图 5 所示是老师和学生的关系图，每个老师可以教多个学生，每个学生也可向多个老师学，他们是双向关联。 聚合关系聚合（Aggregation）关系是关联关系的一种，是强关联关系，是整体和部分之间的关系，是 has-a 的关系。 聚合关系也是通过成员对象来实现的，其中成员对象是整体对象的一部分，但是成员对象可以脱离整体对象而独立存在。例如，学校与老师的关系，学校包含老师，但如果学校停办了，老师依然存在。 在 UML 类图中，聚合关系可以用带空心菱形的实线来表示，菱形指向整体。图所示是大学和教师的关系图。 组合关系组合（Composition）关系也是关联关系的一种，也表示类之间的整体与部分的关系，但它是一种更强烈的聚合关系，是 contains-a 关系。 在组合关系中，整体对象可以控制部分对象的生命周期，一旦整体对象不存在，部分对象也将不存在，部分对象不能脱离整体对象而存在。例如，头和嘴的关系，没有了头，嘴也就不存在了。 在 UML 类图中，组合关系用带实心菱形的实线来表示，菱形指向整体。图所示是头和嘴的关系图。 泛化关系泛化（Generalization）关系是对象之间耦合度最大的一种关系，表示一般与特殊的关系，是父类与子类之间的关系，是一种继承关系，是 is-a 的关系。 在 UML 类图中，泛化关系用带空心三角箭头的实线来表示，箭头从子类指向父类。在代码实现时，使用面向对象的继承机制来实现泛化关系。例如，Student 类和 Teacher 类都是 Person 类的子类，其类图如图所示。 实现关系实现（Realization）关系是接口与实现类之间的关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的所有的抽象操作。 在 UML 类图中，实现关系使用带空心三角箭头的虚线来表示，箭头从实现类指向接口。例如，汽车和船实现了交通工具，其类图如图所示。 总结便于记忆，特此绘制一个表格记录类之间的关系。 类关系 说明 代码表现 箭头及指向 依赖关系 是一种使用的关系,尽量不使用双向的互相依赖 局部变量、方法的参数或者对静态方法的调用 带箭头的虚线，指向被使用者 关联关系 是一种拥有的关系,它使一个类知道另一个类的属性和方法 成员变量 带普通箭头的实心线，指向被拥有者 聚合关系 是整体与部分的关系 成员变量 带空心菱形的实心线，菱形指向整体 组合关系 是整体与部分的关系 成员变量 带实心菱形的实线，菱形指向整体 泛化关系 是一种继承关系,它指定了子类如何特化父类的所有特征和行为 —— 带三角箭头的实线，箭头指向父类 实现关系 一种类与接口的关系，表示类是接口所有特征和行为的实现 —— 带三角箭头的虚线，箭头指向接口 各种关系的强弱顺序： 泛化 = 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖 看完这些脑袋是不是嗡嗡的啊，少年，还有一个速记表格如下： 看以上表格可快速看懂类和类之间的关系图，学会了你也可以快速绘制UML类图了，分享到此结束！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"UML类图","slug":"UML类图","permalink":"http://www.devcheng.net/tags/UML类图/"},{"name":"类图","slug":"类图","permalink":"http://www.devcheng.net/tags/类图/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MySQL性能优化命令Explain使用介绍","slug":"MySQL性能优化命令Explain使用介绍","date":"2021-10-20T11:42:53.000Z","updated":"2021-10-20T12:15:56.732Z","comments":true,"path":"post/506c22fa.html","link":"","permalink":"http://www.devcheng.net/post/506c22fa.html","excerpt":"","text":"简介MySQL 提供了一个 EXPLAIN 命令, 它可以对 SELECT 语句进行分析, 并输出 SELECT 执行的详细信息, 以供开发人员针对性优化.EXPLAIN 命令用法十分简单, 在 SELECT 语句前加上 Explain 就可以了, 例如: 1EXPLAIN SELECT * from user_info WHERE id &lt; 300; 准备为了接下来方便演示 EXPLAIN 的使用, 首先我们需要建立两个测试用的表, 并添加相应的数据: 12345678910111213141516171819202122232425262728293031323334353637383940CREATE TABLE `user_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `name` VARCHAR(50) NOT NULL DEFAULT '', `age` INT(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `name_index` (`name`)) ENGINE = InnoDB DEFAULT CHARSET = utf8INSERT INTO user_info (name, age) VALUES ('xys', 20);INSERT INTO user_info (name, age) VALUES ('a', 21);INSERT INTO user_info (name, age) VALUES ('b', 23);INSERT INTO user_info (name, age) VALUES ('c', 50);INSERT INTO user_info (name, age) VALUES ('d', 15);INSERT INTO user_info (name, age) VALUES ('e', 20);INSERT INTO user_info (name, age) VALUES ('f', 21);INSERT INTO user_info (name, age) VALUES ('g', 23);INSERT INTO user_info (name, age) VALUES ('h', 50);INSERT INTO user_info (name, age) VALUES ('i', 15);CREATE TABLE `order_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `user_id` BIGINT(20) DEFAULT NULL, `product_name` VARCHAR(50) NOT NULL DEFAULT '', `productor` VARCHAR(30) DEFAULT NULL, PRIMARY KEY (`id`), KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`)) ENGINE = InnoDB DEFAULT CHARSET = utf8INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p2', 'WL');INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'DX');INSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p5', 'WL');INSERT INTO order_info (user_id, product_name, productor) VALUES (3, 'p3', 'MA');INSERT INTO order_info (user_id, product_name, productor) VALUES (4, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (6, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (9, 'p8', 'TE'); EXPLAIN 输出格式EXPLAIN 命令的输出内容大致如下: 123456789101112131415mysql&gt; explain select * from user_info where id = 2\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 各列的含义如下: id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引. ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息 接下来我们来重点看一下比较重要的几个字段. select_typeselect_type 表示了查询的类型, 它的常用取值有: SIMPLE, 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. 最常见的查询类别应该是 SIMPLE 了, 比如当我们的查询没有子查询, 也没有 UNION 查询时, 那么通常就是 SIMPLE 类型, 例如: 123456789101112131415mysql&gt; explain select * from user_info where id = 2\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 如果我们使用了 UNION 查询, 那么 EXPLAIN 输出 的结果类似如下: 1234567891011mysql&gt; EXPLAIN (SELECT * FROM user_info WHERE id IN (1, 2, 3)) -&gt; UNION -&gt; (SELECT * FROM user_info WHERE id IN (3, 4, 5));+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+| 1 | PRIMARY | user_info | NULL | range | PRIMARY | PRIMARY | 8 | NULL | 3 | 100.00 | Using where || 2 | UNION | user_info | NULL | range | PRIMARY | PRIMARY | 8 | NULL | 3 | 100.00 | Using where || NULL | UNION RESULT | &lt;union1,2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary |+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+3 rows in set, 1 warning (0.00 sec) table表示查询涉及的表或衍生表 typetype 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等. type 常用类型type 常用的取值有: system: 表中只有一条数据. 这个类型是特殊的 const 类型. const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.例如下面的这个查询, 它使用了主键索引, 因此 type 就是 const 类型的. 123456789101112131415mysql&gt; explain select * from user_info where id = 2\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高. 例如: 12345678910111213141516171819202122232425262728mysql&gt; EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: indexpossible_keys: user_product_detail_index key: user_product_detail_index key_len: 314 ref: NULL rows: 9 filtered: 100.00 Extra: Using where; Using index*************************** 2. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: eq_refpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: test.order_info.user_id rows: 1 filtered: 100.00 Extra: NULL2 rows in set, 1 warning (0.00 sec) ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询.例如下面这个例子中, 就使用到了 ref 类型的查询: 12345678910111213141516171819202122232425262728mysql&gt; EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL*************************** 2. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: refpossible_keys: user_product_detail_index key: user_product_detail_index key_len: 9 ref: const rows: 1 filtered: 100.00 Extra: Using index2 rows in set, 1 warning (0.01 sec) range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中.当 type 是 range 时, 那么 EXPLAIN 输出的 ref 字段为 NULL, 并且 key_len 字段是此次查询中使用到的索引的最长的那个. 例如下面的例子就是一个范围查询: 1234567891011121314151617mysql&gt; EXPLAIN SELECT * -&gt; FROM user_info -&gt; WHERE id BETWEEN 2 AND 8 \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: rangepossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: NULL rows: 7 filtered: 100.00 Extra: Using where1 row in set, 1 warning (0.00 sec) index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index. 例如: 123456789101112131415mysql&gt; EXPLAIN SELECT name FROM user_info \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: indexpossible_keys: NULL key: name_index key_len: 152 ref: NULL rows: 10 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) 上面的例子中, 我们查询的 name 字段恰好是一个索引, 因此我们直接从索引中获取数据就可以满足查询的需求了, 而不需要查询表中的数据. 因此这样的情况下, type 的值是 index, 并且 Extra 的值是 Using index. ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免.下面是一个全表扫描的例子, 可以看到, 在全表扫描时, possible_keys 和 key 字段都是 NULL, 表示没有使用到索引, 并且 rows 十分巨大, 因此整个查询效率是十分低下的. 123456789101112131415mysql&gt; EXPLAIN SELECT age FROM user_info WHERE age = 20 \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 10 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) type 类型的性能比较通常来说, 不同的 type 类型的性能关系如下:ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; systemALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.而 index 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了. possible_keyspossible_keys 表示 MySQL 在查询时, 能够使用到的索引. 注意, 即使有些索引在 possible_keys 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 key 字段决定. key此字段是 MySQL 在当前查询时所真正使用到的索引. key_len表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.key_len 的计算规则如下: 字符串 char(n): n 字节长度 varchar(n): 如果是 utf8 编码, 则是 3 n + 2字节; 如果是 utf8mb4 编码, 则是 4 n + 2 字节. 数值类型: TINYINT: 1字节 SMALLINT: 2字节 MEDIUMINT: 3字节 INT: 4字节 BIGINT: 8字节 时间类型 DATE: 3字节 TIMESTAMP: 4字节 DATETIME: 8字节 字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性. 我们来举两个简单的栗子: 123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id &lt; 3 AND product_name = &apos;p1&apos; AND productor = &apos;WHH&apos; \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: rangepossible_keys: user_product_detail_index key: user_product_detail_index key_len: 9 ref: NULL rows: 5 filtered: 11.11 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) 上面的例子是从表 order_info 中查询指定的内容, 而我们从此表的建表语句中可以知道, 表 order_info 有一个联合索引: 1KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`) 不过此查询语句 WHERE user_id &lt; 3 AND product_name = &#39;p1&#39; AND productor = &#39;WHH&#39; 中, 因为先进行 user_id 的范围查询, 而根据 最左前缀匹配 原则, 当遇到范围查询时, 就停止索引的匹配, 因此实际上我们使用到的索引的字段只有 user_id, 因此在 EXPLAIN 中, 显示的 key_len 为 9. 因为 user_id 字段是 BIGINT, 占用 8 字节, 而 NULL 属性占用一个字节, 因此总共是 9 个字节. 若我们将user_id 字段改为 BIGINT(20) NOT NULL DEFAULT &#39;0&#39;, 则 key_length 应该是8. 上面因为 最左前缀匹配 原则, 我们的查询仅仅使用到了联合索引的 user_id 字段, 因此效率不算高. 接下来我们来看一下下一个例子: 123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id = 1 AND product_name = 'p1' \\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: refpossible_keys: user_product_detail_index key: user_product_detail_index key_len: 161 ref: const,const rows: 2 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) 这次的查询中, 我们没有使用到范围查询, key_len 的值为 161. 为什么呢? 因为我们的查询条件 WHERE user_id = 1 AND product_name = &#39;p1&#39; 中, 仅仅使用到了联合索引中的前两个字段, 因此 keyLen(user_id) + keyLen(product_name) = 9 + 50 * 3 + 2 = 161 rowsrows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好. ExtraEXplain 中的很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容: Using filesort当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大. 例如下面的例子: 123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY product_name \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: indexpossible_keys: NULL key: user_product_detail_index key_len: 253 ref: NULL rows: 9 filtered: 100.00 Extra: Using index; Using filesort1 row in set, 1 warning (0.00 sec) 我们的索引是 1KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`) 但是上面的查询中根据 product_name 来排序, 因此不能使用索引进行优化, 进而会产生 Using filesort.如果我们将排序依据改为 ORDER BY user_id, product_name, 那么就不会出现 Using filesort 了. 例如: 123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY user_id, product_name \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: indexpossible_keys: NULL key: user_product_detail_index key_len: 253 ref: NULL rows: 9 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) Using index“覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using temporary查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"http://www.devcheng.net/tags/MySQL优化/"},{"name":"Explain","slug":"Explain","permalink":"http://www.devcheng.net/tags/Explain/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"来一波安利手绘流程图神器，亲测好用","slug":"来一波安利手绘流程图神器，亲测好用","date":"2021-10-17T08:31:24.000Z","updated":"2021-10-17T08:46:49.342Z","comments":true,"path":"post/70b4b9af.html","link":"","permalink":"http://www.devcheng.net/post/70b4b9af.html","excerpt":"","text":"写在前面前几天在gitee无意浏览其它小伙伴分享源码时，我惊奇的发现人家写的md文档里面的流程图（配图）和一般的不太一样，常规的线条都是规规矩矩，四四方方的。可能是看多了常规的流程图的原因，让我才如此惊奇， 常规的图如下： 不一样的风格流程图如下： 网上查询了一下，这不一样的风格流程图叫 手绘流程图。顾名思义就是类似徒手绘画出来的，继续查询了一番，终于在某乎上发现了一个不错的神器。 神器之draw.iodraw.io 是啥玩意百度了一番，才知道draw.io 是一款免费的在线图表编辑工具, 可以用来编辑工作流, BPM, org charts, UML, ER图, 网络拓朴图等. 如何使用draw.io 绘制手绘风格的图访问draw.io 之后就可以开始画图了，但是我拖了一个椭圆出来之后发现还是常规的圆，这和我期望的不一致啊，后来一顿操作摸索下来，需要在勾选 Sketch 。 接着就可以愉快的绘制你想要的手绘风格的各种图了。 欣赏几张我绘制的吧！ JDBC执行流程 TCP三次握手，四次挥手 以上分享到此结束！ draw.io地址： https://app.diagrams.net/ The end…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"手绘流程图","slug":"手绘流程图","permalink":"http://www.devcheng.net/tags/手绘流程图/"},{"name":"draw.io","slug":"draw-io","permalink":"http://www.devcheng.net/tags/draw-io/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"jenkins打包前端项目","slug":"jenkins打包前端项目","date":"2021-09-24T01:27:47.000Z","updated":"2021-09-24T01:37:05.614Z","comments":true,"path":"post/92a007c9.html","link":"","permalink":"http://www.devcheng.net/post/92a007c9.html","excerpt":"","text":"准备工作这里我的 Jenkins版本是：2.303.1 安装插件点击 左边菜单栏中 “Manage Jenkins” –&gt; “Manager Plugins”。 在输入框中输入 nodeJS,搜索安装即可（我这里是已经安装过了的截图） 全局工具配置 选择对应的版本，点击 保存 和 应用 按钮即可。 做到这，准备工作都已经作完了，接着就是创建一个任务。 新建任务输入名称，选择一个自由风格的项目。 配置General(我这里保持构建的最大个数写的是 10，大家可以按需配置) 配置 源码管理，填写对应的项目gitlab地址。 配置构建环境 配置构建 在构建中选择执行shell 对应的命令如下： 123456echo $PATH node -v npm -v npm install chromedriver --chromedriver_cdnurl=http://cdn.npm.taobao.org/dist/chromedrivernpm installnpm run build 执行成功后可以看到控制台输出 1234 DONE Build complete. The dist directory is ready to be deployed. INFO Check out deployment instructions at https://cli.vuejs.org/guide/deployment.html Finished: SUCCESS The end …","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"http://www.devcheng.net/tags/jenkins/"},{"name":"jenkins打包","slug":"jenkins打包","permalink":"http://www.devcheng.net/tags/jenkins打包/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"如何配置虚拟机互相免密ssh登录","slug":"如何配置虚拟机互相免密ssh登录","date":"2021-08-31T12:02:25.000Z","updated":"2021-08-31T12:07:27.254Z","comments":true,"path":"post/3ab16e7d.html","link":"","permalink":"http://www.devcheng.net/post/3ab16e7d.html","excerpt":"","text":"背景如何让多台虚拟机之间免密互相可登录，接下来我们实战演示一下。 实现准备2台服务器，各自的IP分别为 192.168.191.128 和 192.168.191.129 。 ① 查看ssh server状态123456789101112131415161718[root@jenkins ~]# systemctl status sshd● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) Active: active (running) since 二 2021-08-31 15:13:37 CST; 23min ago Docs: man:sshd(8) man:sshd_config(5) Main PID: 1082 (sshd) Tasks: 1 CGroup: /system.slice/sshd.service └─1082 /usr/sbin/sshd -D8月 31 15:13:37 jenkins systemd[1]: Starting OpenSSH server daemon...8月 31 15:13:37 jenkins sshd[1082]: Server listening on 0.0.0.0 port 22.8月 31 15:13:37 jenkins sshd[1082]: Server listening on :: port 22.8月 31 15:13:37 jenkins systemd[1]: Started OpenSSH server daemon.8月 31 15:14:48 jenkins sshd[3227]: Accepted password for root from 192.168.191.1 port 53268 ssh28月 31 15:33:28 jenkins sshd[27315]: Connection closed by 192.168.191.128 port 35046 [preauth]8月 31 15:33:28 jenkins sshd[27382]: Connection closed by 192.168.191.128 port 35048 [preauth] 由以上信息得知，这台服务器以及安装了对应ssh server 。 如果没有安装请点击 这个连接安装ssh-server传送门 ② 开始配置root用户ssh免密登录执行 ssh-keygen -t rsa 命令。123456789101112131415161718192021[root@jenkins ~]# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:mrzfLe+SUFFjuDmXsasdwX173L+j2fgqhI8jJagQ root@jenkinsThe key&apos;s randomart image is:+---[RSA 2048]----+| o+ || o. . || + . || E * o || . . S. *. . || .+ =. +...o =|| . O ..o+.B .*|| .. . o+oo.* =|| .. ... .B=o+=o|+----[SHA256]-----+ 接着继续执行 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.191.128 命令12345678910[root@jenkins ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.191.128/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.191.128&apos;s password: //输入对应的root密码Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh &apos;root@192.168.191.128&apos;&quot;and check to make sure that only the key(s) you wanted were added. 看到以上提示信息，就成功了。可以使用 ssh &#39;root@192.168.191.128‘ 免密登录对应服务器了。 123[root@jenkins ~]# ssh &apos;root@192.168.191.128&apos;Last login: Tue Aug 31 15:34:01 2021 from 192.168.191.1[root@gitlab ~]# 对应的原理再另外一台服务器也这么操作即可。 这样就实现了这2台服务器互相免密可ssh 登录了！ The end…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ssh免密登陆","slug":"ssh免密登陆","permalink":"http://www.devcheng.net/tags/ssh免密登陆/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"如何批量添加单引号(逗号)","slug":"如何批量添加单引号-逗号","date":"2021-08-17T12:56:24.000Z","updated":"2021-08-17T13:01:22.234Z","comments":true,"path":"post/79b571d7.html","link":"","permalink":"http://www.devcheng.net/post/79b571d7.html","excerpt":"","text":"背景在工作中可能会遇到这样的需求，客户（领导、同事）给你很多数据，你需要添加对应的单引号(or逗号)。数据量少的情况可以采用笨方法一个一个的处理，但是数据量大的时候那怎么办呢？ 借助一个神器，它就是 “Visual Studio Code”！ 准备工作 假如客户（领导、同事）给你的是这样的一个txt文件，这个文件里面有很多数据。 解决方法(vsCode方案)第一步这里我们借助 vsCode ,先打开 vsCode 。 接着双击编辑区，看下图： 第二步把准备工作中的txt文件里面的数据复制进去。 第三步鼠标放在文件最开始的地方，然后 ‘Alt + Shift’ 按住鼠标左键往下滑。然后你就可以输入你想要的符号了，例如我这里第一行我输入单引号，然后再最后一行我也输入一个单引号并且加了一个逗号。 如下图： 解决方法(notepad++方案)步骤和上述 vsCode 操作很类似，不一样的地方就是快捷键不一样了，在 notepad++ 里面 ‘Ctrl + Alt + Shift’ 按住鼠标左键往下滑。 以上两种解决方案，任君选择。 好风凭借力，扶摇上青云。 收藏小技巧，包你事倍功半! The end…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"批量添加单引号","slug":"批量添加单引号","permalink":"http://www.devcheng.net/tags/批量添加单引号/"},{"name":"vscode","slug":"vscode","permalink":"http://www.devcheng.net/tags/vscode/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Springboot2.x整合p6spy","slug":"Springboot2-x整合p6spy","date":"2021-08-06T05:27:03.000Z","updated":"2021-08-17T12:57:04.822Z","comments":true,"path":"post/b5cbfcc0.html","link":"","permalink":"http://www.devcheng.net/post/b5cbfcc0.html","excerpt":"","text":"介绍p6spyP6Spy 是针对数据库访问操作的动态监测框架，它使得数据库数据可无缝截取和操纵，而不必对现有应用程序的代码作任何修改。 P6Spy 分发包包括P6Log，它是一个可记录任何 Java 应用程序的所有JDBC事务的应用程序。其配置完成使用时，可以进行数据访问性能的监测。 P6Spy是一个开源项目，项目首页 www.p6spy.com [项目首页网站不可访问了！] 为何选择p6spy在很多项目中我们都会用mybatis打印必要的sql语句，但是对应的参数都是用 ？ 展示。而开发过程中如果我需要看完整的一条sql语句和具体参数值这就需要p6spy了。 12==&gt; Preparing: select order_id, order_code, org_remark, add_payment, activity_id, evaluate_score FROM tc_order WHERE 1=1 and category =? and order_status = ? and start_date &lt;=? and third_order_id = ? 2017-06-07 14:30:02,679 [executor-1] DEBUG com.xx.xx.dop2c.order.ext.TcOrderExtDao.queryForQueue - 47 - ==&gt; Parameters: 253(Long), 30(Integer), 2017-06-07 14:30:02(String), 0(String) 使用p6spy打印的sql如下： 122021-08-05 10:05:53.217 INFO 1064 --- [ main] p6spy : 2021-08-05 10:05:53|0|statement|connection 0|url jdbc:p6spy:h2:./data/test|insert into goods (name, price, create_time, update_time) values (&apos;bottole&apos;, 2500, now(), now())|insert into goods (name, price, create_time, update_time) values (&apos;bottole&apos;, 2500, now(), now()) Springboot2整合p6spyspring boot 版本：2.4.3 1.添加对应依赖12345&lt;dependency&gt; &lt;groupId&gt;p6spy&lt;/groupId&gt; &lt;artifactId&gt;p6spy&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt; 2.修改数据库连接URL中加入p6spy 3.配置spy.properties将spy.properties复制到项目的resources文件夹中。 12345678910111213141516171819202122232425#3.2.1以上使用modulelist=com.baomidou.mybatisplus.extension.p6spy.MybatisPlusLogFactory,com.p6spy.engine.outage.P6OutageFactory#modulelist=com.baomidou.mybatisplus.extension.p6spy.MybatisPlusLogFactory#3.2.1以下使用或者不配置#modulelist=com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory# 自定义日志打印logMessageFormat=com.baomidou.mybatisplus.extension.p6spy.P6SpyLogger#日志输出到控制台appender=com.baomidou.mybatisplus.extension.p6spy.StdoutLogger# 使用日志系统记录 sql#appender=com.p6spy.engine.spy.appender.Slf4JLogger# 设置 p6spy driver 代理deregisterdrivers=true# 取消JDBC URL前缀useprefix=true# 配置记录 Log 例外,可去掉的结果集有error,info,batch,debug,statement,commit,rollback,result,resultset.excludecategories=info,debug,result,commit,resultset# 日期格式dateformat=yyyy-MM-dd HH:mm:ss# 实际驱动可多个#driverlist=org.h2.Driver# 是否开启慢SQL记录outagedetection=true# 慢SQL记录标准 2 秒outagedetectioninterval=2 这样就大功告成了，我们在运行项目的时候就可以在控制台中看到具体的sql语句了。 12Consume Time：0 ms 2021-08-05 11:16:24Execute SQL：SELECT * FROM tb_data_info WHERE datasource_id = 74 The end…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"springboot2","slug":"springboot2","permalink":"http://www.devcheng.net/tags/springboot2/"},{"name":"p6spy","slug":"p6spy","permalink":"http://www.devcheng.net/tags/p6spy/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"微信小程序使用async提示regeneratorRuntime is not defined异常","slug":"微信小程序使用async提示regeneratorRuntime-is-not-defined异常","date":"2021-07-07T14:31:14.000Z","updated":"2021-07-07T14:34:49.053Z","comments":true,"path":"post/12b3c63e.html","link":"","permalink":"http://www.devcheng.net/post/12b3c63e.html","excerpt":"","text":"背景微信小程序使用async提示regeneratorRuntime is not defined异常。 解决方法新版本的小程序支持async / await。勾选下面选项后重新编译程序即可 点击 ‘详情’ – ‘本地设置’ – 勾选 ‘ES6转ES5’ 和 ‘增强编译’，然后重新编译即可。 完美解决问题！ 更新时间：2021-7-7 The end…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"http://www.devcheng.net/tags/微信小程序/"},{"name":"regeneratorRuntime is not defined","slug":"regeneratorRuntime-is-not-defined","permalink":"http://www.devcheng.net/tags/regeneratorRuntime-is-not-defined/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"springBoot启动提示If you want an embedded database (H2, HSQL or Derby), please put","slug":"springBoot启动提示If-you-want-an-embedded-database-H2-HSQL-or-Derby-please-put-i","date":"2021-05-26T11:47:56.000Z","updated":"2021-05-26T12:01:44.877Z","comments":true,"path":"post/7dd074b3.html","link":"","permalink":"http://www.devcheng.net/post/7dd074b3.html","excerpt":"","text":"异常Springboot启动时报错 If you want an embedded database (H2, HSQL or Derby), please put it on the classpath 说明对于这个异常的解决方案，网上绝大部分都是说：在启动的类中的@SpringBootApplication 改为如下：123456@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)//排除自动配置public class ErukaServerMain &#123; public static void main(String[] args) &#123; SpringApplication.run(ErukaServerMain.class,args); &#125;&#125; 这样改没有解决实际的问题。 产生这个错误的原因是Spring Boot的自动配置，如果你没有配置DataSource就会导致下图这个错误。 那如果你很确定，比如你就是要Spring Boot + Mybatis + MySQL 整合的代码，此时就应该去检查你的配置文件中是否正确配置了数据库连接。 举个栗子下面我们举个栗子复现这个问题，这里我使用Spring Boot + JPA + MySQL整合一个demo。 在数据库链接配置文件中，我们故意写错1234spring.datasource.mysql.jdbc-url=jdbc:mysql://127.0.0.1:3306/beauty_atlas_server?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai&amp;allowMultiQueries=truespring.datasource.mysql.driverClassName=com.mysql.cj.jdbc.Driverspring.datasource.mysql.username=rootspring.datasource.mysql.password=root tips: Spring Boot + JPA 配置连接数据库 可不是用 spring.datasource.mysql.jdbc-url 这个哦，以上的这块配置都是错的，这个时候你启动就会提示 那正确的解决方法如下： 123456# 数据库配置 spring boot + jpa 数据库配置前缀是下面这样的spring.datasource.url=jdbc:mysql://127.0.0.1:3306/beauty_atlas_server?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai&amp;allowMultiQueries=truespring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.username=rootspring.datasource.password=rootspring.datasource.type=com.alibaba.druid.pool.DruidDataSource 由上可见，Spirng Boot 和不同的持久层整合这些配置都是有所区别的，在整合的过程中一定要慎重。Spring Boot + JPA + MySQL 整合中还得配置DataSource，把它注入到Spring中接口，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142@ComponentScan@Configuration@ConfigurationProperties(prefix=&quot;spring.datasource&quot;)public class DbConfig &#123; private String url; private String username; private String password; @Bean public DataSource getDataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(url); dataSource.setUsername(username); dataSource.setPassword(password); return dataSource; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; 重新启动，项目无问题了。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"异常","slug":"异常","permalink":"http://www.devcheng.net/tags/异常/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.devcheng.net/tags/SpringBoot/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MySQL关键字大全","slug":"MySQL关键字大全","date":"2021-05-25T12:29:23.000Z","updated":"2021-05-25T12:45:48.401Z","comments":true,"path":"post/7024f457.html","link":"","permalink":"http://www.devcheng.net/post/7024f457.html","excerpt":"","text":"写在前面在创建表的时候一定使用到MYSQL的关键字，前几天我同事在对接别人的接口中就遇到了这个问题，别人的接口中返回了一个 ‘desc’,他毫不犹豫地创建表的时候也用了’desc’。 结果死活保存不了这条数据。后面排查代码才发现使用了MYSQL的关键子了。 以下都是整理出来所有的MySQL关键字，为了避免踩坑，建议收藏！！！ MySQL关键字ADDALLALTERANALYZEANDASASCASENSITIVEBEFOREBETWEENBIGINTBINARYBLOBBOTHBYCALLCASCADECASECHANGECHARCHARACTERCHECKCOLLATECOLUMNCONDITIONCONNECTIONCONSTRAINTCONTINUECONVERTCREATECROSSCURRENT_DATECURRENT_TIMECURRENT_TIMESTAMPCURRENT_USERCURSORDATABASEDATABASESDAY_HOURDAY_MICROSECONDDAY_MINUTEDAY_SECONDDECDECIMALDECLAREDEFAULTDELAYEDDELETEDESCDESCRIBEDETERMINISTICDISTINCTDISTINCTROWDIVDOUBLEDROPDUALEACHELSEELSEIFENCLOSEDESCAPEDEXISTSEXITEXPLAINFALSEFETCHFLOATFLOAT4FLOAT8FORFORCEFOREIGNFROMFULLTEXTGOTOGRANTGROUPHAVINGHIGH_PRIORITYHOUR_MICROSECONDHOUR_MINUTEHOUR_SECONDIFIGNOREININDEXINFILEINNERINOUTINSENSITIVEINSERTINTINT1INT2INT3INT4INT8INTEGERINTERVALINTOISITERATEJOINKEYKEYSKILLLABELLEADINGLEAVELEFTLIKELIMITLINEARLINESLOADLOCALTIMELOCALTIMESTAMPLOCKLONGLONGBLOBLONGTEXTLOOPLOW_PRIORITYMATCHMEDIUMBLOBMEDIUMINTMEDIUMTEXTMIDDLEINTMINUTE_MICROSECONDMINUTE_SECONDMODMODIFIESNATURALNOTNO_WRITE_TO_BINLOGNULLNUMERICONOPTIMIZEOPTIONOPTIONALLYORORDEROUTOUTEROUTFILEPRECISIONPRIMARYPROCEDUREPURGERAID0RANGEREADREADSREALREFERENCESREGEXPRELEASERENAMEREPEATREPLACEREQUIRERESTRICTRETURNREVOKERIGHTRLIKESCHEMASCHEMASSECOND_MICROSECONDSELECTSENSITIVESEPARATORSETSHOWSMALLINTSPATIALSPECIFICSQLSQLEXCEPTIONSQLSTATESQLWARNINGSQL_BIG_RESULTSQL_CALC_FOUND_ROWSSQL_SMALL_RESULTSSLSTARTINGSTRAIGHT_JOINTABLETERMINATEDTHENTINYBLOBTINYINTTINYTEXTTOTRAILINGTRIGGERTRUEUNDOUNIONUNIQUEUNLOCKUNSIGNEDUPDATEUSAGEUSEUSINGUTC_DATEUTC_TIMEUTC_TIMESTAMPVALUESVARBINARYVARCHARVARCHARACTERVARYINGWHENWHEREWHILEWITHWRITEX509XORYEAR_MONTHZEROFILL 记录一下备忘~ The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"mysql关键字","slug":"mysql关键字","permalink":"http://www.devcheng.net/tags/mysql关键字/"},{"name":"mysql","slug":"mysql","permalink":"http://www.devcheng.net/tags/mysql/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"启动nginx提示Job for nginx.service failed because the control process exited with error code","slug":"启动nginx提示Job-for-nginx-service-failed-because-the-control-process-exited-with-error-code","date":"2021-04-20T12:51:40.000Z","updated":"2021-04-20T13:03:55.574Z","comments":true,"path":"post/ceba3d83.html","link":"","permalink":"http://www.devcheng.net/post/ceba3d83.html","excerpt":"","text":"写在前面启动nginx的时候，提示异常信息如下： Job for nginx.service failed because the control process exited with error code. 查看状态信息,提示配置文件出错: “server” directive is not allowed here in /etc/nginx/nginx.conf:39 解决方法发现端口被占用，centos中查看端口被占用命令为 1netstat -lnp | grep 端口号 杀掉进程： ps -9 进程号 杀掉所有80端口的进程：lsof -i :80|grep -v “PID”|awk ‘{print “kill -9”,$2}’|sh The end…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://www.devcheng.net/tags/nginx/"},{"name":"nginx.service failed","slug":"nginx-service-failed","permalink":"http://www.devcheng.net/tags/nginx-service-failed/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"离职的时候不能说的十句话","slug":"离职的时候不能说的十句话","date":"2021-04-12T13:36:46.000Z","updated":"2021-04-12T13:44:49.082Z","comments":true,"path":"post/462294b4.html","link":"","permalink":"http://www.devcheng.net/post/462294b4.html","excerpt":"","text":"写在前面又是一年一季的跳槽季，也不知道此刻的你是不是正打算离职了，如果打算离职那你应该好好看看这篇文章。 10点不能说的1：老板很挫任何将你的离职与老板的性格或性情联系起来的评论都是无济于事的。他们可能是个食人魔，但如果传回你这么说的消息，他们在与未来的雇主交谈时，更有可能贬低你的态度或表现。 2：上级领导很挫不要说你要离开是因为你的老板不称职，即使这是真的。你的经理会更容易将任何失败归咎于你，并对你的工作做出负面评价。 3：你在的团队成员有问题不要把团队成员的表现或不良态度作为你离职的理由。雇主在调查你的背景时，往往会征求员工以及主管的意见。如果以前的下属或同事因为你的离职言论而受到侮辱，那么他们会更容易提到你作为经理或队友的缺点。 4：你的能力应该拿更多的收入没有必要鼓励管理层将你视为不满的员工，因为这种定性可能会传递给其他询问你在组织的任期的人。 5：公司的状况很糟糕如果你认为公司在某些方面陷入困境或成绩不佳，不要说出来。你的雇主会知道他们组织内部的任何问题。你向管理层传达他们被困在一个糟糕的组织中，而你却在向更好的事情发展，这对你没有任何好处。 6：公司的产品很糟糕不忠诚的员工通常是不受欢迎的。前主管更可能会断言，你成功的任何限制都是由于你的不足，而不是他们产品或服务的缺陷。未来的雇主会怀疑，当你继续前进时，你是否会说他们的坏话。 7：你没有被给到足够的通知突然离职可以用来证明你不是一个敬业或专业的员工的指控。在某些情况下，可以不经通知就辞职，但在大多数情况下，通常是提前两周通知。 8：你不愿意顺利的交接工作这是一个很好的主意，证明你是一个有责任感的员工，直到你的工作结束。为老板缓解过渡期的合作会被记住，并经常得到积极的推荐奖励。 9：新的工作机会实在是太6了不要向其他员工吹嘘你的新工作，因为这可能会引起他们的不满，特别是如果你暗示你比他们更好。感谢他人的支持，并提及你将如何想念与他们一起工作。 10：你对前公司有意见，而且还要写在邮件里不要把任何负面的东西写进去。保持你的辞职信是积极的，这样所有相关人员都会记住你是一个积极的人。学习如何写一封礼貌地说明你要离开的辞职信。 总结：保持积极的态度。现在不是贬低你的老板，队友，或者即将到来的前雇主的时候。 以正确的方式辞职。提供至少两周的书面通知 并感谢公司提供的机会。 从长计议。记住，大多数行业都比他们看起来要小。当你离开时要专业一点，以后你就可以要求推荐人推荐你。","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.devcheng.net/tags/职场/"},{"name":"离职","slug":"离职","permalink":"http://www.devcheng.net/tags/离职/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"工作中碰上那些给你挖坑或者带你踩坑的猪队友，你会怎么办？","slug":"工作中碰上那些给你挖坑或者带你踩坑的猪队友，你会怎么办？","date":"2021-04-10T01:43:25.000Z","updated":"2021-04-10T01:52:41.406Z","comments":true,"path":"post/d7b63f4f.html","link":"","permalink":"http://www.devcheng.net/post/d7b63f4f.html","excerpt":"","text":"写在前面如果你在工作中碰上那些给你挖坑或者带你踩坑的猪队友，你会怎么办？ 正文后台有个老铁就跟我说了这么一件事。 他是产品经理，上周刚加班搞定一个老板很重视的需求，熬了几个夜终于上线了。 这周陆续收到用户反馈，说其中一个功能的历史数据没有了，各种投诉就直接过来了。 在后台一查，原来是新版本完全覆盖了老版本的数据，没有做数据上新老版本兼容，导致更新了新版本的用户看不到之前的老数据。且后台上线后，老版本的用户也看不到之前的数据了。 这个问题最先被反馈到产品经理这，产品去问测试，测试说已经都测过没问题才发包的。产品去问研发，研发说新版代码里已经做了数据兼容的调整。 没办法，让研发老大带着下面的人去检查线上代码，发现提交上去的代码中果然没有完成数据兼容。可去发布前的测试代码中一看，这部分代码却存在。 原来，最后提交代码的程序员没有把这部分代码合并到主分支里面去。 因为表现层的功能测试都没问题了，且数据代码也写好了，所有人都以为万事俱备，没想到被一个代码提交给搞砸了。 幸亏数据有备份，经过恢复处理后这才回归了正常。 原本大家等着靠这个项目拿个季度奖，没想到被队友给坑了，而且是一个本该完全避免的失误。 所以，产品测试完没问题真不是最后一步。在有条件的团队，一定要做灰度上线，把出问题的概率控制在最低。 据我了解，微信团队每次更新产品都是逐步灰度放量，一旦遇到问题就立马回滚，非常灵活。 这些都属于产品技术的基本功，在快速跑需求的同时，也得时刻降低技术负债，多给自己留一些后路。","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.devcheng.net/tags/职场/"},{"name":"猪队友","slug":"猪队友","permalink":"http://www.devcheng.net/tags/猪队友/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"ETL入门系列 03","slug":"ETL入门系列-03","date":"2021-03-15T13:33:32.000Z","updated":"2021-03-16T12:52:46.467Z","comments":true,"path":"post/bb6a7fde.html","link":"","permalink":"http://www.devcheng.net/post/bb6a7fde.html","excerpt":"","text":"背景结合前面两篇博文，这篇博文进行一次实战案例，用于介绍如何使用Ckettle做数据集成。 实战需求：某公司新人试用期为3个月，现在需要对职称为P3的为转正的员工实施转正考核，需要从现有的一张员工信息表格中提取并筛选未转正的员工数据，然后转存到考核系统的数据库中，每个月的1号执行一次。 技术需求 源数据：Excel 目标数据：MySql 业务分析 试用期：3个月 职称：P3 转正状态:未转正 技术概要分析 识别源和目标数据库，数据存储表 操作概要分析 数据处理类型：定时调用 调度频率：每个一次 操作步骤数据抽取1.找到CKettle安装完成目录中的 ‘Spoon.bat’ 双击打开即可。 2.点击 ‘新建’，选择 ‘转换’ 选项。 3.点击 ‘输入’插件中，拖拽 ‘Excel输入’ 插件到右边。 4.选择存于你本地的excel文件，点击 ‘添加’按钮。 5.切换到 ‘工作表’选项，点击 ‘获选工作表名称’选择数据对应的sheet，完成后点击确定按钮。 6.继续切换到 ‘字段’选项，点击 ‘选择来自头部数据的字段’，如无需修改各个字段的类型点击确定按钮。 tips:到此第一步的数据抽取的工作就完成了。 数据转换1.接着需要筛选出职称为P3的员工，需要’过滤记录’插件。 2.按住shift键把两个插件用数据线连接在一块，然后进行数据过来的配置。 3.接着筛选出未转正的数据，在步骤2中同理操作一次即可。 tips：做好以上的步骤，我们可以试着点击’运行’按钮，查看一下流程是否有问题，如果配置都没问题的情况下我们可以查看到数据过滤后的结果。 4.添加一个常量用于比较出是否已经满了入职三个月的需求，这里需要一个 ‘增加常量’插件。 5.添加一个’计算器’ 插件，把入职时间加上刚刚设置的常量得到一个应该转正日期。 6.添加一个 ‘获取系统信息’ 插件，选择系统时间固定值。 7.由以上步骤，可以用当前时间和应该转正日期做比较从而筛选出符合条件的数据。 做到这一步，点击运行查看一下被筛选后的数据。 8.由上一步得知有重复数据，需要借助 ‘去除重复记录’ 插件。 数据转载1.添加 ‘插入/更新’ 插件，配置数据库连接信息。 设置好用来查询的关键字字段，这一步是用来当成数据查询的条件。更新字段这一项是获取数据之后需要更新哪一些字段。 配置完成之后可以点击运行按钮，接着查看数据库对应的表是否存放了符合条件的数据。 数据成功存入到对应数据库表中，到此数据抽取，转换，装载都完成了。但每个月1号需要执行一次这个涉及到定时调度，我们后续再出对应博文讲解！ 其它说明《ETL入门系列01》 《ETL入门系列02》 《ETL入门系列03》 ETL入门系列到此结束！ 本案例中涉及的execl文档和ktr文件有需要的可以加QQ群：816175200备注: ckettle The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ETL","slug":"ETL","permalink":"http://www.devcheng.net/tags/ETL/"},{"name":"数据集成","slug":"数据集成","permalink":"http://www.devcheng.net/tags/数据集成/"},{"name":"实战案例","slug":"实战案例","permalink":"http://www.devcheng.net/tags/实战案例/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"ETL入门系列 02","slug":"ETL入门系列-02","date":"2021-02-24T13:44:07.000Z","updated":"2021-02-24T13:48:31.124Z","comments":true,"path":"post/cc6d4f48.html","link":"","permalink":"http://www.devcheng.net/post/cc6d4f48.html","excerpt":"","text":"背景上一篇我们提到了有几款开源的ETL工具，接下来将学习CKettle。CKettle源于Kettle，在CKettle官网自我介绍中是这样描述自己的 “源于开源，强于开源”。主要提供专职、专业的技术支持和帮助，快速响应国内用户，他们致力于打造专业的ETL技术交流社区。 下载CKettle下载地址： https://ckettle.ccsaii.com.cn/ 下载稳定版即可！ 必要准备CKettle是基于Java开发的，所以确保你本地电脑配置了Java环境变量。 下载得到一个zip压缩包，解压缩出来之后，结构目录如下： windows下双击 Spoon.bat 启动。 在结构目录中我们经常使用到的有： Spoon.bat , Kitchen.bat , Pan.bat , Carte.bat 下面分别介绍 Spoon(设计器)提供了一个图形用户界面，用户创建(编辑)作业或转换；也可以用户执行(调试)作业或转换，它还提供了性能监控的功能。 Kitchen用于作业的命令行运行，可以通过Shell脚本来调用，常用于Linux环境中。 Pan用户转换的命令行运行，和Kitchen一样可以通过Shell脚本来调用。 Carte是一个轻量级的HTTP服务器，后台运行，监听HTTP请求来运行一个作业或转换,也可以用于分布式执行作业或转换，也就是CKettle的集群。 关于以上几个命令如何使用，后续我们结合例子再做详细说明。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ETL","slug":"ETL","permalink":"http://www.devcheng.net/tags/ETL/"},{"name":"ELT","slug":"ELT","permalink":"http://www.devcheng.net/tags/ELT/"},{"name":"数据集成","slug":"数据集成","permalink":"http://www.devcheng.net/tags/数据集成/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"ETL入门系列01","slug":"ETL入门系列01","date":"2021-02-21T07:12:47.000Z","updated":"2021-02-21T07:31:31.758Z","comments":true,"path":"post/53978f67.html","link":"","permalink":"http://www.devcheng.net/post/53978f67.html","excerpt":"","text":"背景DT时代，把数据转换为信息、知识，已成为企业提高核心竞争力的关键。目前，大多数企业和政府采用传统的数据库脚本方式来处理数据，但是脚本方式可读性差，过分依赖人，无论是程序的迁移还是系统维护，都极为不便，而ETL则成为主要的一个技术手段。 什么是ETL字面含义：ETL（Extact-Transform-Load，数据的抽取、转换、加载）是抽取、转换、加载的缩写。 简单定义：把数据从OLTP系统中转移到数据仓库中的一系列操作的集合。 抽取 一般抽取过程需要连接到不同的数据源，以便为随后的步骤提供数据。这一部分看上去简单而琐碎，实际上它是ETL解决方案成功实施的一个主要障碍。 转换 在抽取和加载之间，任何对数据的处理过程都是转换。这些处理过程通常包括（但不限于）下面一些操作。 移动数据 根据规则验证数据 数据内容和数据结构的修改 集成多个数据源的数据 根据处理后的数据计算派生值和聚集值 加载 将数据加载到目标系统的所有操作。 ETL解决方案演化过程第一代，使用手工编程、脚本的方式来完成。 第二代，依据设计好的ETL工作流来自动生成所需代码。 第三代，采用基于引擎的架构，可以执行所有的数据处理进程，还可以将所有的数据库连接和转换规则作为元数据存储起来。 第四代，基于MDA智能化ETL。 ETL工具 用途一，数据迁移。 二，数据同步。 数据集成的几种方式 ELT抽取、加载和转换的简称，同ETL在数据整合的方法上略微不同。在ELT的情况下，数据首先从源数据进行抽取、加载到目标数据库中，再转换为所需要的格式。所有大数据量处理全部放在目标数据库中进行。这种做法的好处在于，一般情况下，数据库系统更适合处理负荷在百万级以上的数据储存民。数据库系统也通常会对I/O(吞吐量)进行优化，用来提高数据处理速度。 EII除了物理数据集成方式，还有虚拟数据集成方式也可以满足用户访问数据的要求。这种虚拟数据集成试就是企业信息集成，也就是EII。如数据联邦和数据虚拟化，也都是描述同样的事情。 这种方法的主要优点就是数据永远都是最新的，不需要额外的存储层，没有冗余数据。缺点就是使用虚拟方法来管理大量的、清洗后的、时效性强的数据是一个非常具有挑战性的工作。 虚拟数据集成和物理数据集成的比较 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ETL","slug":"ETL","permalink":"http://www.devcheng.net/tags/ETL/"},{"name":"ELT","slug":"ELT","permalink":"http://www.devcheng.net/tags/ELT/"},{"name":"数据集成","slug":"数据集成","permalink":"http://www.devcheng.net/tags/数据集成/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于SpringBoot开发的招聘网站源码分享","slug":"基于SpringBoot开发的招聘网站源码分享","date":"2021-01-19T02:16:31.000Z","updated":"2021-01-19T03:36:51.187Z","comments":true,"path":"post/2093beaf.html","link":"","permalink":"http://www.devcheng.net/post/2093beaf.html","excerpt":"","text":"前言本项目是基于SpringBoot开发招聘网站，可以当作毕业设计、期末课程作业等，也使用刚刚入门SpringBoot的同学们！ 功能描述项目分为应聘方和招聘方两种角色，招聘方可以发布职位，应聘方创建简历通过投递简历应聘。 在项目中主要拥有的功能有：登录（密码登录，验证码登录），注册，创建简历，投递，查看职位详情，申请职位等。 开发环境（运行环境） 系统环境：Windows 10 开发工具：IntelliJ IDEA Java版本：JDK 1.8 项目技术栈 Spring Boot Mybatis Maven 3.X Bootstarp Druid Mysql Jsp 登录地址http://localhost:8081/ 账户和密码(密码登陆)： 18612345678 / 1234567 系统展示图 联系我们如有需要源码可以通过 QQ 搜索：792435323联系我！ 备注：招聘网站源码 项目演示视频链接: https://pan.baidu.com/s/1pIwQ3s8casozF02VzRVtxQ 提取码: dxnr 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的xxxApplication直接运行吧！ 其它说明白嫖怪请绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.devcheng.net/tags/SpringBoot/"},{"name":"招聘网站","slug":"招聘网站","permalink":"http://www.devcheng.net/tags/招聘网站/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"分享几个实用的Git技巧","slug":"分享几个实用的Git技巧","date":"2021-01-12T13:59:13.000Z","updated":"2021-01-12T14:08:38.013Z","comments":true,"path":"post/ddae8940.html","link":"","permalink":"http://www.devcheng.net/post/ddae8940.html","excerpt":"","text":"写在前面可以这么说,Git在一定程度上拯救了很多开发者的饭碗。只要你经常使用Git保存自己的工作，你就一直有机会可以将代码退回到之前的状态，因此就可以挽回那些你深夜里迷迷糊糊犯下的错误。 但是Git的命令行界面可是出了名的难掌握。接下来，就给大家介绍7个比较实用的小技巧，最大限度发挥Git的作用。 通常，大部分时间我们都只会用到add、commit、branch和push/pull这些命令。大部分人熟悉这套只往一个方向运转的工作流。你们有没有想过，如果自己往仓库中添加了错误的文件，或是将代码提交到了错误的分支，而且提交信息还写错了的话，自己怎样才能取消之前的操作？如果你也是按照上面漫画中所描绘的一样操作的，那么你就有必要了解下面这些Git使用技巧了。 Git技巧1.修改错误的提交信息（commit message）提交的信息在很长时间内会一直保留在你的代码库（code base）中，所以你肯定希望通过这个信息正确地了解代码修改情况。 下面这个命令可以让你编辑最近一次的提交信息，但是你必须确保没有对当前的代码库（working copy）做修改，否则这些修改也会随之一起提交。 1$ git commit --amend -m ”YOUR-NEW-COMMIT-MESSAGE” 假如你已经将代码提交（git commit）推送（git push）到了远程分支，那么你需要通过下面的命令强制推送这次的代码提交。 1$ git push &lt;remote&gt; &lt;branch&gt; --force 2.提交之前撤销 git add如果你往暂存区（staging area）中加入了一些错误的文件，但是还没有提交代码。你可以使用一条简单的命令就可以撤销。如果只需要移除一个文件，那么请输入： 1$ git reset &lt;文件名&gt; 或者如果你想从暂存区移除所有没有提交的修改： 1$ git reset 3.撤销最近一次代码提交有时候你可能会不小心提交了错误的文件或一开始就遗漏了某些东西。下面这三步操作可以帮助你解决这个问题。 1$ git reset --soft HEAD~1 对工作文件进行必要的更改 12$ git add -A .$ git commit -c ORIG_HEAD 你执行第一个命令时，Git会将HEAD指针后移到此前的一次提交，之后你才能移动文件或作必要的修改。 然后你就可以添加所有的修改，而且当你执行最后的命令时，Git会打开你的默认文本编辑器，其中会包含上一次提交时的信息。如果愿意的话，你可以修改提交信息，或者你也可以在最后的命令中使用-C而不是-c，来跳过这一步。 4.Git仓库撤销至前一次提交时的状态“撤销”（revert）在许多情况下是非常有必要的——尤其是你把代码搞的一团糟的情况下。最常见的情况是，你想回到之前代码版本，检查下那个时候的代码库，然后再回到现在状态。这可以通过下面的命令实现： 1$ git checkout &lt;SHA&gt; “”是你想查看的提交拥有的哈希值（Hash Code）中前8至10个字符。 这个命令会使指针脱离（detach），可以让你在不检出（check out）任何分支的情况下查看代码——脱离HEAD并不像听上去那么可怕。如果你想在这种情况下提交修改，你可以通过创建新的分支来实现：1$ git checkout -b &lt;SHA&gt; 要想回到当前的工作进度，只需要检出（check out）你之前所在的分支即可。 5.撤销合并（Merge）要想撤销合并，你可能必须要使用恢复命令（HARD RESET）回到上一次提交的状态。“合并”所做的工作基本上就是重置索引，更新working tree（工作树）中的不同文件，即当前提交（）代码中与HEAD游标所指向代码之间的不同文件；但是合并会保留索引与working tree之间的差异部分（例如那些没有被追踪的修改）。1$ git checkout -b &lt;SHA&gt; 当然，Git中总是有其他的实现办法，你可以查看看这篇文章继续了解。 6.从当前Git分支移除未追踪的本地文件假设你凑巧有一些未被追踪的文件（因为不再需要它们），不想每次使用git status命令时让它们显示出来。下面是解决这个问题的一些方法：12345$ git clean -f -n # 1$ git clean -f # 2$ git clean -fd # 3$ git clean -fX # 4$ git clean -fx # 5 (1): 选项-n将显示执行（2）时将会移除哪些文件。(2): 该命令会移除所有命令（1）中显示的文件。(3): 如果你还想移除文件件，请使用选项-d。(4): 如果你只想移除已被忽略的文件，请使用选项-X。(5): 如果你想移除已被忽略和未被忽略的文件，请使用选项-x。请注意最后两个命令中X的区别。 7.删除本地和远程Git分支删除本地分支：1$ git branch --delete --force &lt;branchName&gt; 或者使用选项-D作为简写：1$ git branch -D 删除远程分支：1$ git push origin --delete &lt;branchName&gt; 建议：要想更好地掌握Git的用法，还得仔细阅读Git官方文档！ The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://www.devcheng.net/tags/Git/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MySQL优化干货总结","slug":"MySQL优化干货总结","date":"2021-01-03T06:45:54.000Z","updated":"2021-01-03T07:12:02.349Z","comments":true,"path":"post/991a821e.html","link":"","permalink":"http://www.devcheng.net/post/991a821e.html","excerpt":"","text":"写在前面在面试中无论大厂还是到小公司，一直未变的一个重点就是对SQL优化经验的考察。一提到数据库，先“说一说你对SQL优化的见解吧？”。SQL优化已经成为衡量程序猿优秀与否的硬性指标，甚至在各大厂招聘岗位职能上都有明码标注，如果是你，在这个问题上能吊打面试官还是会被吊打呢？ 语法顺序SELECT语句 - 语法顺序123456789101. SELECT 2. DISTINCT &lt;select_list&gt;3. FROM &lt;left_table&gt;4. &lt;join_type&gt; JOIN &lt;right_table&gt;5. ON &lt;join_condition&gt;6. WHERE &lt;where_condition&gt;7. GROUP BY &lt;group_by_list&gt;8. HAVING &lt;having_condition&gt;9. ORDER BY &lt;order_by_condition&gt;10.LIMIT &lt;limit_number&gt; Tips:以下SQL优化策略适用于数据量较大的场景下，如果数据量较小，没必要以此为准。 SQL优化策略避免不走索引的场景 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描。 1SELECT * FROM student WHERE name LIKE &apos;%陈%&apos; 优化方式：尽量在字段后面使用模糊查询。如下： 1SELECT * FROM student WHERE name LIKE &apos;陈%&apos; 尽量避免使用in 和not in，会导致引擎走全表扫描 1SELECT * FROM student WHERE id IN (2,3) 优化方式：如果是连续数值，可以用between代替。如下： 1SELECT * FROM student WHERE id BETWEEN 2 AND 3 如果是子查询，可以用exists代替。如下： 1234-- 不走索引select * from A where A.id in (select id from B);-- 走索引select * from A where exists (select * from B where B.id = A.id); 尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描。1SELECT * FROM student WHERE id = 1 OR id = 3 优化方式：可以用union代替or。 123SELECT * FROM student WHERE id = 1UNIONSELECT * FROM student WHERE id = 3 4.尽量避免进行null值的判断，会导致数据库引擎放弃索引进行全表扫描1SELECT * FROM student WHERE score IS NUL 优化方式：可以给字段添加默认值0，对0值进行判断 1SELECT * FROM student WHERE score = 0 5.尽量避免在where条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描。可以将表达式、函数操作移动到等号右侧。1234-- 全表扫描SELECT * FROM T WHERE score/10 = 9-- 走索引SELECT * FROM T WHERE score = 10*9 当数据量大时，避免使用where 1=1的条件。通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描。1SELECT username, age, sex FROM T WHERE 1=1 优化方式：用代码拼装sql时进行判断，没 where 条件就去掉 where，有where条件就加 and。 查询条件不能用 &lt;&gt; 或者 != 使用索引列作为条件进行查询时，需要避免使用&lt;&gt;或者!=等判断条件。如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替。 where条件仅包含复合索引非前置列复合（联合）索引包含key_part1，key_part2，key_part3三列，但SQL语句没有包含索引前置列”key_part1”，按照MySQL联合索引的最左匹配原则，不会走联合索引。 1select col1 from table where key_part2=1 and key_part3=2 隐式类型转换造成不使用索引如下SQL语句由于索引对列类型为varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引。 1select col1 from table where col_varchar=123; order by 条件要与where中条件一致，否则order by不会利用索引进行排序 12345-- 不走age索引SELECT * FROM student order by age; -- 走age索引SELECT * FROM student where age &gt; 0 order by age; SELECT语句其他优化 避免出现select * 避免出现不确定结果的函数 多表关联查询时，小表在前，大表在后。 使用表的别名 用where字句替换HAVING字句 调整Where字句中的连接顺序 查询条件优化 对于复杂的查询，可以使用中间临时表 暂存数据 优化group by语句默认情况下，MySQL 会对GROUP BY分组的所有值进行排序，如 “GROUP BY col1，col2，….;” 查询的方法如同在查询中指定 “ORDER BY col1，col2，…;” 如果显式包括一个包含相同的列的 ORDER BY子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL禁止排序。例如：SELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ; 优化join语句MySQL中可以通过子查询来使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接(JOIN)..替代。例子：假设要将所有没有订单记录的用户取出来，可以用下面这个查询完成：SELECT col1 FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo )如果使用连接(JOIN).. 来完成这个查询工作，速度将会有所提升。尤其是当 salesinfo表中对 CustomerID 建有索引的话，性能将会更好，查询如下： 123SELECT col1 FROM customerinfo LEFT JOIN salesinfoON customerinfo.CustomerID=salesinfo.CustomerID WHERE salesinfo.CustomerID IS NULL 连接(JOIN).. 之所以更有效率一些，是因为 MySQL 不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。 优化union查询MySQL通过创建并填充临时表的方式来执行union查询。除非确实要消除重复的行，否则建议使用union all。原因在于如果没有all这个关键词，MySQL会给临时表加上distinct选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高。高效：12345SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION ALL SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= &apos;DEVCHENG&apos;; 低效：12345SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= &apos;DEVCHENG&apos;; 5.拆分复杂SQL为多个小SQL，避免大事务简单的SQL容易使用到MySQL的QUERY CACHE；减少锁表时间特别是使用MyISAM存储引擎的表；可以使用多核CPU。 6.使用truncate代替delete当删除全表中记录时，使用delete语句的操作会被记录到undo块中，删除记录也记录binlog，当确认需要删除全表时，会产生很大量的binlog并占用大量的undo数据块，此时既没有很好的效率也占用了大量的资源。使用truncate替代，不会记录可恢复的信息，数据不能被恢复。也因此使用truncate操作有其极少的资源占用与极快的时间。另外，使用truncate可以回收表的水位，使自增字段值归零。 建表优化1.在表中建立索引，优先考虑where、order by使用到的字段。 尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。 3.查询数据量大的表 会造成查询缓慢。 4.用varchar/nvarchar 代替 char/nchar尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 The end .","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"MySQL优化","slug":"MySQL优化","permalink":"http://www.devcheng.net/tags/MySQL优化/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"docker踩坑学习笔记","slug":"docker踩坑学习笔记","date":"2020-12-25T15:13:25.000Z","updated":"2020-12-25T15:24:19.909Z","comments":true,"path":"post/53539811.html","link":"","permalink":"http://www.devcheng.net/post/53539811.html","excerpt":"","text":"写在前面安装完成功docker后，如何在容器中安装JDK、TOMCAT。 方法一123docker search jdk docker install jdk_open... docker中如何挂载文件方法二上传压缩文件到服务器，这种方式需要将服务器上的文件挂载到docker 容器中。docker可以支持把一个宿主机上的目录挂载在docker容器中（镜像）。 tips:要把宿主机文件挂载在容器中，此时，身份是 宿主机中找到要被挂载文件的目录 通过-v参数，冒号前为宿主机目录，必须为绝对路径，冒号后为镜像内挂载的路径 执行 挂载成功 解压jdk 此时会遇到权限不够的问题 操作：1231.退出容器2. 执行 su -c &quot;setenforce 0&quot;3.dorcker run -i -t centos /bin/bash 重新解压即可！相关解决链接：http://www.cnblogs.com/adamas21/p/6280297.html 启动docker web服务时,虚拟机端口转发外部无法访问?可参考以下链接：http://blog.csdn.net/u014062332/article/details/52911405 jdk的配置123456vi /etc/profile添加以下配置export JAVA_HOME=/opt/jdk1.8.0_121export JRE_HOME=/usr/java/jdk1.8.0_121/jreexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.devcheng.net/tags/docker/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MySQL索引","slug":"MySQL索引","date":"2020-11-29T10:53:46.000Z","updated":"2020-11-29T11:02:03.328Z","comments":true,"path":"post/43a71ae4.html","link":"","permalink":"http://www.devcheng.net/post/43a71ae4.html","excerpt":"","text":"索引的优点最典型的例子就是查新华字典，通过查找目录快速定位到查找的字 大大减少了服务器需要扫描的数量 帮助服务器避免排序和临时表 将IO变成顺序IO 尽可能的降低磁盘的寻址时间，也就是局部性原理，就是很大一部分数据在未来的一段时间被连续访问 在复制1G压缩包 和 1G小文件，前者的速度会大于后者 减少IO的量，例如写SQL语句的时候，不要写 select * 减少IO的次数，一次IO能搞定的事，不使用3次IO 索引的用处 快速查找匹配where子句的行 从consideration中消除行，如果可以在多个索引之间进行选择，mysql通常会使用栈找到最少行的索引 如果表具有多列索引，则优化器可以使用索引的最左匹配前缀来查找 当有表连接的时候，从其他表检测行数据 查找特定索引列min或max值 如果排序或分组是，在可用索引的最左前缀上完成的，则对表进行排序和分组 在某些清空下，可以优化查询以检索值而无需查询数据行 索引的分类主键索引如果你在创建索引的时候，使用的是主键这个值，那么就是主键索引，primary key 我们建表的时候，例如下面这个建表语句 1234567891011CREATE TABLE `t_blog_sort` ( `uid` varchar(32) NOT NULL COMMENT '唯一uid', `sort_name` varchar(255) DEFAULT NULL COMMENT '分类内容', `content` varchar(255) DEFAULT NULL COMMENT '分类简介', `create_time` timestamp NOT NULL DEFAULT '0000-00-00 00:00:00' COMMENT '创建时间', `update_time` timestamp NOT NULL DEFAULT '0000-00-00 00:00:00' COMMENT '更新时间', `status` tinyint(1) unsigned NOT NULL DEFAULT '1' COMMENT '状态', `sort` int(11) DEFAULT '0' COMMENT '排序字段，越大越靠前', `click_count` int(11) DEFAULT '0' COMMENT '点击数', PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='博客分类表'; 这里面有使用到 PRIMARY KEY (uid)，这就是主键索引 唯一索引唯一索引 类似于普通索引，索引列的值必须唯一 唯一索引和主键索引的区别就是，唯一索引允许出现空值，而主键索引不能为空 1create unique index index_name on table(column) 或者创建表时指定 1unique index_name column 普通索引当我们需要建立索引的字段，既不是主键索引，也不是唯一索引 那么就可以创建一个普通索引 1create index index_name on table(column) 或者创建表时指定 1create table(..., index index_name column) 全文索引lunce、solr和ElasticSearch就是做全文检索的，里面涉及到了倒排索引的概念，mysql很少使用全文索引。 要用来查找文本中的关键字，不是直接与索引中的值相比较，像是一个搜索引擎，配合 match against 使用，现在只有char，varchar，text上可以创建索引，在数据量比较大时，先将数据放在一个没有全文索引的表里，然后在利用create index创建全文索引，比先生成全文索引在插入数据快很多。 组合索引目前，在业务不是特别复杂的时候，可能使用一个列作为索引，或者直接采用主键索引即可，但是如果业务变得复杂的时候，就需要用到组合索引，通过对多个列建立索引。 组合索引的用处，假设我现在表有个多个字段：id、name、age、gender，然后我经常使用以下的查询条件 1select * from user where name = 'xx' and age = xx 这个时候，我们就可以通过组合 name 和 age 来建立一个组合索引，加快查询效率，建立成组合索引后，我的索引将包含两个key值 在多个字段上创建索引，遵循最左匹配原则 1alter table t add index index_name(a,b,c); 索引的使用与否索引的使用MySQL每次只使用一个索引，与其说 数据库查询只能用一个索引，倒不如说，和全表扫描比起来，去分析两个索引 B+树更耗费时间，所以where A=a and B=b 这种查询使用（A，B）的组合索引最佳，B+树根据（A，B）来排序。 主键，unique字段 和其他表做连接的字段需要加索引 在where 里使用 &gt;, &gt;=, = , &lt;, &lt;=, is null 和 between等字段。 使用不以通配符开始的like，where A like ‘China%’ 聚合函数里面的 MIN()， MAX()的字段 order by 和 group by字段 何时不使用索引 表记录太少 数据重复且分布平均的字段（只有很少数据的列）； 经常插入、删除、修改的表要减少索引 text，image 等类型不应该建立索引，这些列的数据量大（加入text的前10个字符唯一，也可以对text前10个字符建立索引） MySQL能估计出全表扫描比使用索引更快的时候，不使用索引 索引何时失效 组合索引为使用最左前缀，例如组合索引（A，B），where B = b 不会使用索引 like未使用最左前缀，where A like “%China” 搜索一个索引而在另一个索引上做 order by， where A = a order by B，只会使用A上的索引，因为查询只使用一个索引。 or会使索引失效。如果查询字段相同，也可以使用索引。例如 where A = a1 or A = a2（生效），where A=a or B = b （失效） 在索引列上的操作，函数upper()等，or、！ = （&lt;&gt;）,not in 等 面试技术名词回表首先我们需要知道，我们建立几个索引，就会生成几棵B+Tree，但是带有原始数据行的B+Tree只有一棵，另外一棵树上的叶子节点带的是主键值。 例如，我们通过主键建立了主键索引，然后在叶子节点上存放的是我们的数据 当我们创建了两个索引时，一个是主键，一个是name，它还会在生成一棵B+Tree，这棵树的叶子节点存放的是主键，当我们通过name进行查找的时候，会得到一个主键，然后在通过主键再去上面的这个主键B+Tree中进行查找，我们称这个操作为 ==回表== 当我们的SQL语句使用的是下面这种的时候，它会查找第一颗树，直接返回我们的数据 1select * from tb where id = 1 当我们使用下面这种查询的时候，它会先查找第二棵树得到我们的主键，然后拿着主键再去查询第一棵树 1select * from tb where name = &apos;gang&apos; 回表就是通过普通列的索引进行检索，然后再去主键列进行检索，这个操作就是回表 ==但是我们在使用检索的时候，尽量避免回表，因为这会造成两次B+Tree的查询，假设一次B+Tree查询需要三次IO操作，那么查询两次B+Tree就需要六次IO操作。== 索引覆盖我们看下面的两个SQL语句，看看它们的查询过程是一样的么？ 12select * from tb where id = 1select name from tb where name = zhou 答案是不一样的，首先我们看第二个语句，就是要输出的列中，就是我们的主键，当我们通过name建立的B+Tree进行查询的时候 我们可以直接找到我们的数据，并得到主键，但是因为我们要返回的就是name，此时说明数据存在了，那么就直接把当前的name进行返回，而不需要通过主键再去主键B+Tree中进行查询。 这样一个不需要进行回表操作的过程，我们称为索引覆盖 最左匹配这里提到的 最左匹配 和 索引下推 都是针对于组合索引的。 例如，我们有这样一个索引 1name age：组合索引 必须要先匹配name，才能匹配到age。这个我们就被称为最左匹配 例如下面的几条SQL语句，那些语句不会使用组合索引 1234where name = ? and age = ?where name = ?where age = ?where age = ? and name = ? 根据最左匹配原则，我们的 3 不会使用组合索引的。 那为什么4的顺序不一样，也会使用组合索引呢？ 其实内部的优化器会进行调整，例如下面的一个连表操作 1select * from tb1 join tb2 on tb1.id = tb2.id 其实在加载表的时候，并不一定是先加载tb1，在加载tb2，而是可能根据表的大小决定的，小的表优先加载进内存中。 索引下推在说索引下推的时候，我们首先在举两个例子 1select * from tb1 where name = ? and age = ? 在mysq 5.6之前，会先根据name去存储引擎中拿到所有的数据，然后在server层对age进行数据过滤 在mysql5.6之后，根据name 和 age两个列的值去获取数据，直到把数据返回。 通过对比能够发现，第一个的效率低，第二个的效率高，因为整体的IO量少了，原来是把数据查询出来，在server层进行筛选，而现在在存储引擎层面进行筛选，然后返回结果。我们把这个过程就称为 索引下推 优化器CBO基于成本的优化 RBO基于规则的优化 索引匹配方式全值匹配全值匹配指的是和索引中所有的列进行匹配 1explain select * from staffs where name = 'July' and age = 23 and pos = 'dev' 而我们建立了一个 包含 name、age、pos的组合索引，使用上面的SQL语句，就会进行全值匹配 匹配最左前缀只匹配前面的几列 1explain select * from staffs where name = 'July' and age = 23 这个时候，只使匹配了前面两个列，而没有使用第三个列 现在我们使用下面的SQL语句进行验证，但我们输出值只包含ID的时候 1explain select id from staffs where id = 1 我们查看其任务计划，在某尾有 Extra字段，如果是Using index 表示是使用了覆盖索引 然后我们在查看下面这条SQL语句 1explain select * from staffs where id = 1 通过查看任务计划，发现extra字段是NULL，说明没有使用覆盖索引 匹配列前缀可以匹配某一列值的开头部分 12explain select * from staffs where name = 'J%'explain select * from staffs where name = '%y' 匹配范围值可以查找某个范围的数据 1explain select * from staffs where name &gt; 'Mary' 精确匹配某一列并范围匹配另外一列可以查询某一列的全部和第二列的部分 1explain select * from staffs where name = \"July\" and age &gt; 25 只访问索引的查询查询的时候值需要访问索引，不需要访问数据行，本质上就是索引覆盖 1explain select name,age,pos from staffs where name=\"July\" and age=25 and pos = \"dev\" 哈希索引概念基于哈希的实现，只有精确匹配索引所有的列的查询才有效，在mysql中，只有memory的存储引擎显式支持哈希索引，哈希索引自身只需存储对应的hash值，索引索引的结构十分紧凑，这让哈希索引查找的速度非常快。 哈希索引的限制 哈希索引值包含哈希值和行指针，而不存储字段值。索引不能使用索引中的值来避免读取行 哈希索引数据并不是按照索引值顺序存储的，所以无法进行排序 哈希索引不支持部分列匹配查找，哈希索引是使用索引列的全部内容来计算哈希值 哈希索引支持等值比较查询，也不支持任何范围查询 访问哈希索引的数据非常快，除非有很多哈希冲突，当出现哈希冲突的时候，存储引擎必须遍历链表中的所有行指针，逐行进行比较，知道找到所有符合条件的行 哈希冲突比较多的话，维护的代价也会很高 聚簇索引和非聚簇索引聚簇索引InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，聚簇索引就是按每张表的主键构造一棵B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚簇索引的叶子节点称为数据也，这个特性就决定了索引组织表中的数据也是索引的一部分。 ==一句话来说：将索引和数据放在一起的，就称为聚簇索引== 我们日常的工作中，根据实际情况自行添加的索引，都是辅助索引或者称为普通索引，辅助索引就是为了查找主键索引的二级索引，先找到主键索引然后再通过主键索引找数据，但是可能会存在回表的问题。 聚簇索引的优点 数据访问更快，因为聚簇索引将索引和数据保存在一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快 聚簇索引对主键的排序和范围查找速度非常快 聚簇索引的缺点 插入速度严重依赖于排序，按照主键的顺序插入是最快的方式，否者会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列作为主键 更新主键的代价很高，因为将会导致被更新的行移动，因此，对于InnoDB表，我们一般定义主键不可更新 二级索引访问需要两次索引查找，第一次找到主键值，第二次 根据主键值查找行数据，一般我们需要尽量避免出现索引的二次查找，这个时候，用到的就是索引的覆盖 非聚簇索引非聚簇索引也被称为辅助索引，辅助索引在我们访问数据的时候总是需要两次查找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到主键值，然后在通过主键值找到数据行的数据页，在通过数据页中的Page Directory找到数据行。 InnoDB辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，还包含了行数据的聚簇索引建。辅助索引的存在不影响数据在聚簇索引中的组织，所以一张表可以有多个辅助索引。在InnoDB中有时也称为辅助索引为二级索引 组合索引当包含多个列为索引，需要注意的是正确的顺序依赖于该索引的查询，同时需要考虑如何更好的满足排序和分组的需要 第4个不走索引，是因为不满足最左匹配原则 第5个，因为跨过了b，所以只走a的索引 优化细节 当使用索引列进行查询的时候，尽量不要使用表达式，把计算放到业务层而不是数据库层 12select actor_id from actor where actor_id = 4select actor_id from actor where actor_id+1 = 5 第一条语句走索引 而第二条语句没有走主键索引 尽量使用主键查询，而不是其它索引，因为主键查询不会触发回表操作 使用前缀索引 有时候需要索引很长的字符串，这会让索引变得大且满，通常情况下可以使用某个列开始的部分字符串，这样大大的节约了索引空间，从而提高索引效率，但这会降低索引的选择性，索引的选择性是指不重复的索引值和数据表记录总数的比值，范围从1/#T 到 1 之间，索引的选择性越高，则查询效率越高，因为选择性更高的索引可以让mysql在查找的时候过滤掉更多的行。 一般情况下，某个列前缀的选择性也是足够高的，足以满足查询的性能，但是对应BLOG，TEXT，VARCHAR类型的列，必须要使用前缀索引，因为mysql不允许索引这些列的完整长度，使用该方法的诀窍在于选择足够长的前缀以保证较高的选择性，通过又不能太长 。 使用索引扫描来进行排序 union、all、in、or都能使用索引，但是推荐使用in 1234567explain select * from actor where actor_id = 1 union all select * from actor where actor_id = 2explain select * from actor where actor_id in (1,2);explain select * from actor where actor_id = 1 or actor_id = 2;-- 关于or到底走不走索引，必须根据实际情况进行考虑 范围列可以使用到索引 例如 范围条件是：&lt;、&lt;=、&gt;、&gt;=、between 范围列可以用到索引，但是范围列后面的列无法用到索引，索引最多用于一个范围列，所以一般如果我们使用组合索引的时候，最好不要使用范围查找 如倒数第一个所示，因为中间b使用了范围查找，所以后面的c是无法使用索引的，只能是a和b才能使用索引 强制类型转换会让索引失效，进行全表查询 例如下面这样一个例子所示，我们对 phone字段进行了强制类型转换 12explain select * from user where phone = 13800001234 -- 不会触发索引（触发了字符串到整型转换）explain select * from user where phone = '13800001234' -- 触发索引 更新十分频繁，数据区分度不高的字段上不宜建立索引 更新会变更B+树，更新 频繁的字段建立索引会大大降低数据库性能 类似于性别这列的区分度不高的字段，建立索引是没有意义的，不能有效的过滤数据 一般区分度在百分80以上的时候，就可以建立索引，区分度可以使用 count(distinct(列名)) / count(*) 来进行计算 创建索引的列，不允许为null，可能会得到不符合预期的结果 当需要进行表连接的时候，最好不要超过三张表，因为需要join的字段，数据类型必须一致（阿里规约） 允许数据的冗余，从而加快查询的效率 目前是范式和反范式的混合使用 能使用limit的时候，尽量使用limit 单表索引建议控制在5个以内 单索引字段不允许超过5个（组合索引） 创建索引的时候应该尽量避免以下错误的概念 索引不是越多越好，不要在不了解系统的情况下进行优化","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"MySQL索引","slug":"MySQL索引","permalink":"http://www.devcheng.net/tags/MySQL索引/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"并发锁知识点","slug":"并发锁知识点","date":"2020-10-23T13:31:56.000Z","updated":"2020-10-23T13:41:01.549Z","comments":true,"path":"post/2a798f18.html","link":"","permalink":"http://www.devcheng.net/post/2a798f18.html","excerpt":"","text":"悲观锁：synchronizedSynchronized互斥锁属于悲观锁，它有一个明显的缺点，它不管数据存不存在竞争都加锁，随着并发量增加，且如果锁的时间比较长，其性能开销将会变得很大。 每个对象头中分为两部分：一部分是自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等。一部分是类型指针，即是对象指向它的类的元数据的指针。 而对象的锁(monitor)就在对象头中，MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。 而其他想要获取该锁只能阻塞，一个线程进行阻塞或唤起都需要操作系统的协助，这就需要从用户态切换到内核态来执行，这种切换代价十分昂贵，需要消耗很多处理器时间 特性：互斥锁、非公平锁、可重入、不可中断优点：实现简单缺点： 不管数据存不存在竞争都加锁，随着并发量增加，且如果锁的时间比较长，其性能开销将会变得很大 不可中断，在所有等待的线程中，synchronized无法帮你中断此任务 互斥锁在获取锁失败后将进入睡眠或阻塞状态 乐观锁：CAS( compare and swap,比较并交换)自旋锁悲观锁会把整个对象加锁占为自有后才去做操作，乐观锁不获取锁直接做操作，然后通过一定检测手段决定是否更新数据。 乐观锁的核心算法是CAS（Compare and Swap，比较并交换），它涉及到三个操作数：内存值、预期值、新值。当且仅当预期值和内存值相等时才将内存值修改为新值。 这样处理的逻辑是，首先检查某块内存的值是否跟之前我读取时的一样，如不一样则表示期间此内存值已经被别的线程更改过，舍弃本次操作，否则说明期间没有其他线程对此内存值操作，可以把新值设置给此块内存。 优点： 高并发性能，jdk中的并发包也大量使用基于CAS的乐观锁。 缺点： 乐观锁只能保证一个共享变量的原子操作 长时间自旋可能导致开销大 ABA问题。 CAS的核心思想是通过比对内存值与预期值是否一样而判断内存值是否被改过，但这个判断逻辑不严谨，假如内存值原来是A，后来被一条线程改为B，最后又被改成了A，则CAS认为此内存值并没有发生改变，但实际上是有被其他线程改过的，这种情况对依赖过程值的情景的运算结果影响很大。解决的思路是引入版本号，每次变量更新都把版本号加一。 同步器：AQS(AbstractQueuedSynchronizer)定义：它为不同场景提供了实现锁及同步机制的基本框架，为同步状态的原子性管理、线程的阻塞、线程的解除阻塞及排队管理提供了一种通用的机制。 原理：ASQ将线程封装到一个Node里面，并维护一个CHL Node FIFO队列，它是一个非阻塞的FIFO队列，也就是说在并发条件下往此队列做插入或移除操作不会阻塞，是通过自旋锁和CAS保证节点插入和移除的原子性，实现无锁快速插入。 state 独占模式state的值只能为0或1 共享模式的state是可以被出事换成任意整数，一般初始值表示提供一个同时n条线程通过的管道宽度，这样一来，多条线程通过tryAcquireShared尝试将state的值减去1，成功修改state后就返回新值，只有当新值大于等于0才表示获取锁成功，拥有往下执行的权利，进入管道。在执行完毕时线程将调用tryReleaseShared尝试修改state值使之增加1。 表示我已经执行完了并让出管道的通道供后面线程使用，需要说明的是与独占模式不同，由于可能存在多条线程并发释放锁，所以此处必须使用基于CAS算法的修改方法，修改成功后其他线程便可继续竞争锁。 独占式：只容许一个线程通过的管道，在这种模式下线程只能逐一通过管道，任意时刻管内只能存在一条线程，这便形成了互斥效果。 共享式：共享模式就是管道宽度大于1的管道，可以同时让n条管道通过，吞吐量增加但可能存在共享数据一致性问题。 阻塞唤醒三种方式： suspend与resume：存在无法解决的竟态问题而被Java废弃 wait与notify：这两个方法必须存在于synchronized中，存在竟态条件，wait必须在notify之前执行，假如一个线程先执行notify再执行wait将可能导致一个线程永远阻塞 await与singal: Condition类提供，而Condition对象由new ReentLock().newCondition()获得，与wait和notify相同，因为使用Lock锁后无法使用wait方法wait与await区别： wait与notify必须配合synchronized使用，因为调用之前必须持有锁，wait会立即释放锁，notify则是同步块执行完了才释放 因为Lock没有使用synchronized机制，故无法使用wait方法区操作多线程，所以使用了Condition的await来操作 park与unpark：由LockSupport类提供，底层调用的是Unsafe类的方法，由于park与unpark使用的是许可机制，许可最大为1，所以unpark与park操作不会累加，而且unpark可以在park之前执行，如unpark先执行，后面park将不阻塞。 Lock实现主要是基于AQS，而AQS实现则是基于LockSupport，所以说LockSupport更底层，所以不建议使用park和unpark去阻塞和唤醒线程 Java内部有两种锁机制:1.synchonized2.Lock区别：实现机制不同 synchonrized 分为两种 程序段的synchonized是通过monitor.enter monitor.exit来实现的，方法和类级别的则是通过设置实例或者类的锁字段来实现 Lock的实现方式则是通过AQS。AQS是一个线程的链表，负责维护线程的状态，以及线程的调度，AQS也是一个锁 保证同一时间获取AQS锁的线程只有一个，也就是下面的Nodestatus为runnning的只有一个(为什么不是同一时间运行的线程只有一个呢?线程在申请锁的时候先加入队列然后挂起，并且在公平竞争时所有的线程都会别唤醒 ) synchronized 同步锁原理：任何一个对象都一个Monitor与之关联，当且一个Monitor被持有后，它将处于锁定状态。Synchronized在JVM里的实现都是基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。 MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。 这时如果要将一个线程进行阻塞或唤起都需要操作系统的协助，这就需要从用户态切换到内核态来执行，这种切换代价十分昂贵，需要消耗很多处理器时间。如果可能，应该减少这样的切换，jvm一般会采取一些措施进行优化，例如在把线程进行阻塞操作之前先让线程自旋等待一段时间，可能在等待期间其他线程已经解锁，这时就无需再让线程执行阻塞操作，避免了用户态到内核态的切换。 Java中每一个对象都可以作为锁，这是synchronized实现同步的基础： 普通同步方法，锁是当前实例对象 静态同步方法，锁是当前类的class对象 同步方法块，锁是括号里面的对象 javap工具查看生成的class文件信息来分析Synchronize的实现 同步代码块： monitorenter指令插入到同步代码块的开始位置，monitorexit指令插入到同步代码块的结束位置，JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个monitor与之相关联，当且一个monitor被持有之后，他将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权，即尝试获取对象的锁； 同步方法：synchronized方法则会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。 Java对象头和monitor是实现synchronized的基础特性：互斥锁、非公平锁、可重入、不可中断、使用简单性能和建议：JDK6之后，在并发量不是特别大的情况下，性能中等且稳定。建议新手使用。Lock锁实现： ReentrantLock 重入锁使用：ReentrantLock是Lock接口的实现类。Lock接口的核心方法是lock()，unlock()，tryLock()。可用Condition来操作线程，await()和object.wait()类似，singal()和object.notify()类似，singalAll()和object.notifyAll()类似。 原理核心类AbstractQueuedSynchronizer，通过构造一个基于阻塞的CLH队列容纳所有的阻塞线程，而对该队列的操作均通过Lock-Free（CAS）操作，但对已经获得锁的线程而言，ReentrantLock实现了偏向锁的功能。 特性：公平锁, 定时锁, 有条件锁, 可轮询锁, 可中断锁. 可以有效避免死锁的问题性能和建议：性能中等，建议需要手动操作线程时使用。ReentrantReadWriteLock 读写锁使用它允许多个线程读某个资源，但每次只允许一个线程来写。ReadWriteLock接口的核心方法是readLock()，writeLock()。实现了并发读、互斥写。但读锁会阻塞写锁，是悲观锁的策略。 当多个线程读取有个变量时可以使用读锁rwl.readLock().lock();，如果需要去修改某个变量时则可以上写锁rwl.writeLock().lock();//上写锁，不允许其他线程读也不允许写 与重入锁比较，其实现原理一致，但是读写锁更适合读多写少的场景，因为读读共享，而重入锁全互斥 StampedLock 时间戳锁(jdk1.8改进的读写锁) 使用写锁的改进，它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写，在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写！ 时间戳锁与读写锁比较读锁不阻塞写锁，如果时间戳无效，则重新读取变量值。无ABA问题。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"并发锁","slug":"并发锁","permalink":"http://www.devcheng.net/tags/并发锁/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于SpringBoot开发图书管理系统源码分享","slug":"基于SpringBoot开发图书管理系统源码分享","date":"2020-10-06T13:32:33.000Z","updated":"2020-12-26T05:56:52.714Z","comments":true,"path":"post/931cd25c.html","link":"","permalink":"http://www.devcheng.net/post/931cd25c.html","excerpt":"","text":"前言本项目是基于SpringBoot开发图书管理系统，可以当作毕业设计、期末课程作业、课间小作业等，也使用刚刚入门SpringBoot的朋友！ 功能描述项目分为管理员和非管理员两种角色，其中非管理员包含：教师和学生。 在项目中管理员主要拥有的功能有：书籍管理（图书管理、借书审核、查看已借出书籍、查看换书），用户管理（学生管理、教师管理），部门管理（班级管理、学院管理），设置（修改密码、查看个人信息、操作日志、退出）。 在项目非管理员拥有的功能：借阅图书管理（借书、已借书及还书、正审核的图书），设置（修改密码、查看个人信息、退出）。 开发环境（运行环境） 系统环境：Windows 10 开发工具：IntelliJ IDEA Java版本：JDK 1.8 项目技术栈 Spring Boot 2.0.6.RELEASE SpringDataJpa Maven 3.X Bootstarp EasyUI Mysql thymeleaf 登录地址http://localhost:8080/ 管理员账户和密码： admin6 / admin6 学生账户和密码： guliduo / guliduo 系统展示图 联系我们如有需要源码可以通过 QQ 搜索：792435323联系我！ 备注：图书管理系统 项目演示视频链接: https://pan.baidu.com/s/1UDY8uH167xUUttXKrDMF3A 提取码: hjhi 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的xxxApplication直接运行吧！ 其它说明白嫖怪请绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"图书管理系统","slug":"图书管理系统","permalink":"http://www.devcheng.net/tags/图书管理系统/"},{"name":"在线图书管理系统","slug":"在线图书管理系统","permalink":"http://www.devcheng.net/tags/在线图书管理系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"Class org.springframework.util.ReflectionUtils can not access a member of class异常","slug":"Class-org-springframework-util-ReflectionUtils-can-not-access-a-member-of-class异常","date":"2020-09-28T09:34:25.000Z","updated":"2020-09-28T09:57:08.461Z","comments":true,"path":"post/50c55201.html","link":"","permalink":"http://www.devcheng.net/post/50c55201.html","excerpt":"","text":"背景最近，工作中多个地方用到了Java反射调用私有方法，但如果不小心很容易出错，下面看看异常信息 1234562020-09-25 14:02:03.393 ERROR 13920 --- [nio-8400-exec-3] c.s.b.d.support.utils.ExceptionUtils : Could not access method: Class org.springframework.util.ReflectionUtils can not access a member of class com.xxx.model.entity.XxxEntity with modifiers &quot;private&quot;; nested exception is java.lang.IllegalStateException: Could not access method: Class org.springframework.util.ReflectionUtils can not access a member of class com.xxx.Entity with modifiers &quot;private&quot; 举个栗子为了完整的说明这个异常，简单的看一下代码： Entity 类1234567891011121314151617181920212223242526272829303132333435363738package com.xxx.reflect;public class Student &#123; private void add()&#123; System.out.println(&quot;add method...&quot;); &#125; private int id; private String name; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Student(int id, String name) &#123; super(); this.id = id; this.name = name; &#125; public Student() &#123; &#125;&#125; Main类 12345678public static void main(String[] args) throws Exception &#123; Class c1=Student.class; Object obj=(Object)c1.newInstance(); Method method = c1.getDeclaredMethod(&quot;add&quot;); method.invoke((Student)obj); &#125; 直接运行 main 方法则会报这个异常 Class . can not access a member of class . with modifiers “private” 。 解决方法设置Field对象的Accessible的访问标志位为Ture，就可以通过反射获取私有变量的值，在访问时会忽略访问修饰符的检查。 所以只需要加上这行代码即可！ Main类 123456789public static void main(String[] args) throws Exception &#123; Class c1=Student.class; Object obj=(Object)c1.newInstance(); Method method = c1.getDeclaredMethod(&quot;add&quot;); method.setAccessible(true); // 加上这句即可解决问题！ method.invoke((Student)obj); &#125; The end","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"异常","slug":"异常","permalink":"http://www.devcheng.net/tags/异常/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"乐观锁与悲观锁","slug":"乐观锁与悲观锁","date":"2020-09-25T12:53:55.000Z","updated":"2020-09-25T13:03:42.557Z","comments":true,"path":"post/c72647c7.html","link":"","permalink":"http://www.devcheng.net/post/c72647c7.html","excerpt":"","text":"大白话之乐观锁和悲观锁用大白话解释什么是乐观锁好悲观锁如下： 乐观锁对应于生活中乐观的人总是想着事情会往好的方向发展。 悲观锁对应于生活中悲观的人总是想着事情会往坏的方向发展。 乐观锁 (Optimistic Locking)假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回给用户错误的信息，让用户决定如何去做。 乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。 悲观锁 (Pessimistic Lock)悲观其实是我们人类一种消极的情绪，对应到锁的悲观情绪，悲观锁认为被它保护的数据是极其不安全的，每时每刻都有可能变动，一个事务拿到悲观锁后（可以理解为一个用户），其他任何事务都不能对该数据进行修改，只能等待锁被释放才可以执行。 传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁以及 Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 使用场景从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。 但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以悲观锁一般多写的场景下用就比较合适。 乐观的两种实现方式 版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。 1.操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 50（100-$50 ）。 2.在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 20（100-$20 ）。 3.操作员 A 完成了修改工作，将数据版本号（ version=1 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本等于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 4.操作员 B 完成了操作，也将版本号（ version=1 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 1 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须等于当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。 这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。 CAS算法即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。 CAS算法涉及到三个操作数 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。 一般情况下是一个自旋操作，即不断的重试。 乐观锁的缺点ABA 问题是乐观锁一个常见的问题。 1 ABA 问题 如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。 这个问题被称为CAS操作的 “ABA”问题。 JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 CAS与synchronized的使用情景简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少）synchronized适用于写比较多的情况下（多写场景，冲突一般较多） 1.对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 2.对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 小结由上文的介绍，相信大家都有一定的认识了，在实际工作中如何选择得需要看对应的业务场景，但随着互联网三高架构(高并发、高性能、高可用)的提出，悲观锁已经越来越少的被应用到生产环境中了，尤其是并发量比较大的业务场景。 The end","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"乐观锁","slug":"乐观锁","permalink":"http://www.devcheng.net/tags/乐观锁/"},{"name":"悲观锁","slug":"悲观锁","permalink":"http://www.devcheng.net/tags/悲观锁/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"如果面试官问你“你有什么问题问我吗？”时，你该如何回答","slug":"如果面试官问你“你有什么问题问我吗？”时，你该如何回答","date":"2020-09-22T13:35:33.000Z","updated":"2020-09-22T14:05:06.212Z","comments":true,"path":"post/185dcb3e.html","link":"","permalink":"http://www.devcheng.net/post/185dcb3e.html","excerpt":"","text":"背景又是一年一度的“金九银十”跳槽季，我还记得当时我去参加面试的时候，几乎每一场面试，特别是HR面和高管面的时候，面试官总是会在结尾问我:“问了你这么多问题了，你有什么问题问我吗？”。 这个时候很多人内心就会陷入短暂的纠结中：我该问吗？不问的话面试官会不会对我影响不好？问什么问题？问这个问题会不会让面试官对我的影响不好啊？ 这个问题对最终面试结果的影响到底大不大?就技术面试而言，回答这个问题的时候，只要你不是触碰到你所面试的公司的雷区，那么我觉得这对你能不能拿到最终offer来说影响确实是不大的。 我说这些并不代表你就可以直接对面试官说：“我没问题了。”，个人当时面试的时候确实也说过挺多次“没问题要问了。”，最终也没有导致笔主被pass掉（可能是前面表现比较好，哈哈，自恋一下）。我现在回想起来，觉得自己当时做法其实挺不对的。 面试本身就是一个双向选择的过程，你对这个问题的回答也会侧面反映出你对这次面试的上心程度，你的问题是否有价值，也影响了你最终的选择与公司是否选择你。 面试官在技术面试中主要考察的还是你这样个人到底有没有胜任这个工作的能力以及你是否适合公司未来的发展需要，很多公司还需要你认同它的文化。 我觉得你只要不是太笨，应该不会栽在这里。除非你和另外一个人在能力上相同，但是只能在你们两个人中选一个，那么这个问题才对你能不能拿到offer至关重要。有准备总比没准备好，给面试官留一个好的影响总归是没错的。 但是，就非技术面试来说，我觉得好好回答这个问题对你最终的结果还是比较重要的。 总的来说不管是技术面试还是非技术面试，如果你想赢得公司的青睐和尊重，我觉得我们都应该重视这个问题。 真诚一点,不要问太 Low 的问题回答这个问题很重要的一点就是你没有必要放低自己的姿态问一些很虚或者故意讨好面试官的问题，也不要把自己从面经上学到的东西照搬下来使用。 面试官也不是傻子，特别是那种特别有经验的面试官，你是真心诚意的问问题，还是从别处照搬问题来讨好面试官，人家可能一听就听出来了。 总的来说，还是要真诚。 除此之外，不要问太 Low 的问题，会显得你整个人格局比较小或者说你根本没有准备（侧面反映你对这家公司不上心，既然你不上心，为什么要要你呢）。 举例几个比较 Low 的问题，大家看看自己有没有问过其中的问题： 贵公司的主要业务是什么？（面试之前自己不知道提前网上查一下吗？） 贵公司的男女比例如何？（考虑脱单？记住你是来工作的！） 贵公司一年搞几次外出旅游？（你是来工作的，这些娱乐活动先别放在心上！） …… 有哪些有价值的问题值得问?针对这个问题。笔主专门找了几个专门做HR工作的小哥哥小姐姐们询问并且查阅了挺多前辈们的回答，然后结合自己的实际经历，我概括了下面几个比较适合问的问题。 面对HR或者其他Level比较低的面试官时 1.能不能谈谈你作为一个公司老员工对公司的感受? (这个问题比较容易回答，不会让面试官陷入无话可说的尴尬境地。另外，从面试官的回答中你可以加深对这个公司的了解，让你更加清楚这个公司到底是不是你想的那样或者说你是否能适应这个公司的文化。除此之外，这样的问题在某种程度上还可以拉进你与面试官的距离。) 2.能不能问一下，你当时因为什么原因选择加入这家公司的呢或者说这家公司有哪些地方吸引你？有什么地方你觉得还不太好或者可以继续完善吗？ （类似第一个问题，都是问面试官个人对于公司的看法。） 3.我觉得我这次表现的不是太好，你有什么建议或者评价给我吗？(这个是我常问的。我觉得说自己表现不好只是这个语境需要这样来说，这样可以显的你比较谦虚好学上进。) 4.接下来我会有一段空档期，有什么值得注意或者建议学习的吗？ （体现出你对工作比较上心，自助学习意识比较强。） 5.这个岗位为什么还在招人？ (岗位真实性和价值咨询) 6.大概什么时候能给我回复呢？(终面的时候，如果面试官没有说的话，可以问一下) 7……. 面对部门领导 1.部门的主要人员分配以及对应的主要工作能简单介绍一下吗？ 2.未来如果我要加入这个团队，你对我的期望是什么？ （部门领导一般情况下是你的直属上级了，你以后和他打交道的机会应该是最多的。你问这个问题，会让他感觉你是一个对他的部门比较上心，比较有团体意识，并且愿意倾听的候选人。） 3.公司对新入职的员工的培养机制是什么样的呢？（正规的公司一般都有培养机制，提前问一下是对你自己的负责也会显的你比较上心） 4.以您来看，这个岗位未来在公司内部的发展如何？ (在我看来，问这个问题也是对你自己的负责吧，谁不想发展前景更好的岗位呢？) 5.团队现在面临的最大挑战是什么？ (这样的问题不会暴露你对公司的不了解，并且也能让你对未来工作的挑战或困难有一个提前的预期。) 面对Level比较高的(比如总裁,老板) 1.贵公司的发展目标和方向是什么？ （看下公司的发展是否满足自己的期望） 2.与同行业的竞争者相比，贵公司的核心竞争优势在什么地方？ （充分了解自己的优势和劣势） 3.公司现在面临的最大挑战是什么？ 总结薪酬待遇和相关福利问题一般在终面的时候（最好不要在前面几面的时候就问到这个问题），面试官会提出来或者在面试完之后以邮件的形式告知你。一般来说，如果面试官很愿意为你回答问题，对你的问题也比较上心的话，那他肯定是觉得你就是他们要招的人。 大家在面试的时候，可以根据自己对于公司或者岗位的了解程度，对上面提到的问题进行适当修饰或者修改。 上面提到的一些问题只是给没有经验的朋友一个参考，如果你还有其他比较好的问题的话，那当然也更好啦！ The End","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://www.devcheng.net/tags/面试/"},{"name":"面试经验","slug":"面试经验","permalink":"http://www.devcheng.net/tags/面试经验/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"你是否因为命名被diss过？","slug":"你是否因为命名被diss过？","date":"2020-09-18T10:56:03.000Z","updated":"2020-09-18T11:27:16.259Z","comments":true,"path":"post/18c03ab9.html","link":"","permalink":"http://www.devcheng.net/post/18c03ab9.html","excerpt":"","text":"背景在工作中，有太多太多让我们头疼的事情了，比如变量命名、类命名、维护其他人的代码、写测试、与其他人沟通交流等等。就连世界级软件大师 Martin Fowler 大神都说过 CS 领域有两大最难的事情，一是缓存失效，一是程序命名。 为什么需要重视命名好的命名即是注释，别人一看到你的命名就知道你的变量、方法或者类是做什么的！ 好的命名对于其他人（包括你自己）理解你的代码有着很大的帮助！ 简单举个例子说明一下命名的重要性。 《Clean Code》这本书明确指出： 好的代码本身就是注释，我们要尽量规范和美化自己的代码来减少不必要的注释。 若编程语言足够有表达力，就不需要注释，尽量通过代码来阐述。 举个栗子： 去掉下面复杂的注释，只需要创建一个与注释所言同一事物的函数即可。 12// check to see if the employee is eligible for full benefitsif ((employee.flags &amp; HOURLY_FLAG) &amp;&amp; (employee.age &gt; 65)) 应替换为 1if (employee.isEligibleForFullBenefits()) 常见命名规则以及适用场景这里只介绍 3 种最常见的命名规范。 驼峰命名法（CamelCase）驼峰命名法应该我们最常见的一个，这种命名方式使用大小写混合的格式来区别各个单词，并且单词之间不使用空格隔开或者连接字符连接的命名方式 大驼峰命名法（CamelCase） 类名需要使用大驼峰命名法（UpperCamelCase） 正例： 1ServiceDiscovery、ServiceInstance、LruCacheFactory 反例： 1serviceDiscovery、Serviceinstance、LRUCacheFactory 小驼峰命名法（lowerCamelCase） 方法名、参数名、成员变量、局部变量需要使用小驼峰命名法（lowerCamelCase） 正例： 12getUserInfo()、createCustomThreadPool()、setNameFormat(String nameFormat)Uservice userService; 反例：12GetUserInfo()、CreateCustomThreadPool()、setNameFormat(String NameFormat)Uservice user_service 蛇形命名法（snake_case） 测试方法名、常量、枚举名称需要使用蛇形命名法（snake_case） 在蛇形命名法中，各个单词之间通过下划线“_”连接，比如should_get_200_status_code_when_request_is_valid、CLIENT_CONNECT_SERVER_FAILURE。 蛇形命名法的优势是命名所需要的单词比较多的时候，比如我把上面的命名通过小驼峰命名法给大家看一下： “shouldGet200StatusCodoWhenRequestIsValid”。 感觉如何？ 相比于使用蛇形命名法（snake_case）来说是不是不那么易读？ 正例： 1234@Testvoid should_get_200_status_code_when_request_is_valid() &#123; ......&#125; 反例：1234@Testvoid shouldGet200StatusCodoWhenRequestIsValid() &#123; ......&#125; 串式命名法（kebab-case） 在串式命名法中，各个单词之间通过下划线“-”连接，比如dubbo-registry。 建议项目文件夹名称使用串式命名法（kebab-case），比如 dubbo 项目的各个模块的命名是下面这样的。 常见命名规范Java 语言基本命名规范1.类名需要使用大驼峰命名法（UpperCamelCase）风格。方法名、参数名、成员变量、局部变量需要使用小驼峰命名法（lowerCamelCase）。 2.测试方法名、常量、枚举名称需要使用蛇形命名法（snake_case），比如should_get_200_status_code_when_request_is_valid、CLIENT_CONNECT_SERVER_FAILURE。并且，测试方法名称要求全部小写，常量以及枚举名称需要全部大写。 3.项目文件夹名称使用串式命名法（kebab-case），比如dubbo-registry。 4.包名统一使用小写，尽量使用单个名词作为包名，各个单词通过 “.” 分隔符连接，并且各个单词必须为单数。 正例： org.apache.dubbo.common.threadlocal 反例： org.apache.dubbo.common.threadLocal 5.抽象类命名使用 Abstract 开头。1234//为远程传输部分抽象出来的一个抽象类（出处：Dubbo源码）public abstract class AbstractClient extends AbstractEndpoint implements Client &#123;&#125; 6.异常类命名使用 Exception 结尾。123456789101112//自定义的 NoSuchMethodException（出处：Dubbo源码）public class NoSuchMethodException extends RuntimeException &#123; private static final long serialVersionUID = -2725364246023268766L; public NoSuchMethodException() &#123; super(); &#125; public NoSuchMethodException(String msg) &#123; super(msg); &#125;&#125; 7.测试类命名以它要测试的类的名称开始，以 Test 结尾。1234//为 AnnotationUtils 类写的测试类（出处：Dubbo源码）public class AnnotationUtilsTest &#123; ......&#125; POJO 类中布尔类型的变量，都不要加 is 前缀，否则部分框架解析会引起序列化错误。 如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。 命名易读性规范1.为了能让命名更加易懂和易读，尽量不要缩写/简写单词，除非这些单词已经被公认可以被这样缩写/简写。比如 CustomThreadFactory 不可以被写成 CustomTF 。 2.命名不像函数一样要尽量追求短，可读性强的名字优先于简短的名字，虽然可读性强的名字会比较长一点。 这个对应我们上面说的第 1 点。 3.避免无意义的命名，你起的每一个名字都要能表明意思。 正例：UserService userService; int userCount; 反例: UserService service int count 4.避免命名过长（50 个字符以内最好），过长的命名难以阅读并且丑陋。 5.不要使用拼音，更不要使用中文。 注意：像 alibaba 、wuhan、taobao 这种国际通用名词可以当做英文来看待。 正例：discount 反例：dazhe Codelf:变量命名神器?这是一个由国人开发的网站，网上有很多人称其为变量命名神器，大家可以自行体验一下，然后再给出自己的判断。 Codelf 提供了在线网站版本，网址：https://unbug.github.io/codelf/ 具体使用情况如下： 我选择了 Java 编程语言，然后搜索了“序列化”这个关键词，然后它就返回了很多关于序列化的命名。 并且，Codelf 还提供了 VS code 插件，看这个评价，看来大家还是很喜欢这款命名工具的。 The End","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"变量命名","slug":"变量命名","permalink":"http://www.devcheng.net/tags/变量命名/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Spring Boot 注解大全，建议收藏","slug":"Spring-Boot-注解大全，建议收藏","date":"2020-09-09T13:15:54.000Z","updated":"2020-09-09T13:39:53.962Z","comments":true,"path":"post/2ad95350.html","link":"","permalink":"http://www.devcheng.net/post/2ad95350.html","excerpt":"","text":"背景在工作中，用到了各种各样的注解，一直没抽时间整理过，正好今天抽时间稍微整理了一波。整理的注解都是工作中常见的，如有纰漏请留言指出！ 一、注解 (annotations) 列表@SpringBootApplication： 包含了 @ComponentScan、@Configuration 和 @EnableAutoConfiguration 注解。 其中 @ComponentScan 让 spring Boot 扫描到 Configuration 类并把它加入到程序上下文。 @Configuration 等同于 spring 的 XML 配置文件；使用 Java 代码可以检查类型安全。 @EnableAutoConfiguration 自动配置。 @ComponentScan 组件扫描，可自动发现和装配一些 Bean。 @Component 可配合 CommandLineRunner 使用，在程序启动后执行一些基础任务。 @RestController 注解是 @Controller 和 @ResponseBody 的合集, 表示这是个控制器 bean, 并且是将函数的返回值直 接填入 HTTP 响应体中, 是 REST 风格的控制器。 @Autowired 自动导入。 @PathVariable 获取参数。 @JsonBackReference 解决嵌套外链问题。 @RepositoryRestResourcepublic 配合 spring-boot-starter-data-rest 使用。 二、注解 (annotations) 详解@SpringBootApplication：申明让 spring boot 自动给程序进行必要的配置，这个配置等同于：@Configuration ，@EnableAutoConfiguration 和 @ComponentScan 三个配置。 12345678910package com.example.myproject;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication // same as @Configuration @EnableAutoConfiguration @ComponentScanpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; @ResponseBody：表示该方法的返回结果直接写入 HTTP response body 中，一般在异步获取数据时使用，用于构建 RESTful 的 api。 在使用 @RequestMapping 后，返回值通常解析为跳转路径，加上 @responsebody 后返回结果不会被解析为跳转路径，而是直接写入 HTTP response body 中。 比如异步获取 json 数据，加上 @responsebody 后，会直接返回 json 数据。 该注解一般会配合 @RequestMapping 一起使用。示例代码：12345@RequestMapping(“/test”)@ResponseBodypublic String test()&#123; return”ok”;&#125; @Controller：用于定义控制器类，在 spring 项目中由控制器负责将用户发来的 URL 请求转发到对应的服务接口（service 层） 关注顶级架构师公众号回复“架构整洁”，送你一份惊喜礼包。 一般这个注解在类中，通常方法需要配合注解 @RequestMapping。 示例代码：1234567891011121314@Controller@RequestMapping(“/demoInfo”)publicclass DemoController &#123; @Autowired private DemoInfoService demoInfoService; @RequestMapping(&quot;/hello&quot;) public String hello(Map map)&#123; System.out.println(&quot;DemoController.hello()&quot;); map.put(&quot;hello&quot;,&quot;from TemplateController.helloHtml&quot;); //会使用hello.html或者hello.ftl模板进行渲染显示. return&quot;/hello&quot;; &#125;&#125; @RestController：用于标注控制层组件 (如 struts 中的 action)，@ResponseBody 和 @Controller 的合集。 示例代码：1234567891011121314package com.kfit.demo.web;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(“/demoInfo2”)publicclass DemoController2 &#123; @RequestMapping(&quot;/test&quot;) public String test()&#123; return&quot;ok&quot;; &#125;&#125; @RequestMapping：提供路由信息，负责 URL 到 Controller 中的具体函数的映射。 @EnableAutoConfiguration：Spring Boot 自动配置（auto-configuration）：尝试根据你添加的 jar 依赖自动配置你的 Spring 应用。 例如，如果你的 classpath 下存在 HSQLDB，并且你没有手动配置任何数据库连接 beans，那么我们将自动配置一个内存型（in-memory）数据库”。 你可以将 @EnableAutoConfiguration 或者 @SpringBootApplication 注解添加到一个 @Configuration 类上来选择自动配置。 如果发现应用了你不想要的特定自动配置类，你可以使用 @EnableAutoConfiguration 注解的排除属性来禁用它们。 @ComponentScan：表示将该类自动发现扫描组件。 个人理解相当于，如果扫描到有 @Component、@Controller、@Service 等这些注解的类，并注册为 Bean，可以自动收集所有的 Spring 组件，包括 @Configuration 类。 我们经常使用 @ComponentScan 注解搜索 beans，并结合 @Autowired 注解导入。可以自动收集所有的 Spring 组件，包括 @Configuration 类。 如果没有配置的话，Spring Boot 会扫描启动类所在包下以及子包下的使用了 @Service,@Repository 等注解的类。 @Configuration：相当于传统的 xml 配置文件，如果有些第三方库需要用到 xml 文件，建议仍然通过 @Configuration 类作为项目的配置主类——可以使用 @ImportResource 注解加载 xml 配置文件。 @Import：用来导入其他配置类。 @ImportResource：用来加载 xml 配置文件。 @Autowired：自动导入依赖的 bean @Service：一般用于修饰 service 层的组件 @Repository：使用 @Repository 注解可以确保 DAO 或者 repositories 提供异常转译，这个注解修饰的 DAO 或者 repositories 类会被 ComponetScan 发现并配置，同时也不需要为它们提供 XML 配置项。 @Bean：用 @Bean 标注方法等价于 XML 中配置的 bean。 @Value：注入 Spring boot application.properties 配置的属性的值。示例代码： 12@Value(value = “#&#123;message&#125;”)private String message; @Inject：等价于默认的 @Autowired，只是没有 required 属性； @Component：泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 @Bean：相当于 XML 中的, 放在方法的上面，而不是类，意思是产生一个 bean, 并交给 spring 管理。 @AutoWired：自动导入依赖的 bean。byType 方式。把配置好的 Bean 拿来用，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。当加上（required=false）时，就算找不到 bean 也不报错。 @Qualifier：当有多个同一类型的 Bean 时，可以用 @Qualifier(“name”) 来指定。与 @Autowired 配合使用。@Qualifier 限定描述符除了能根据名字进行注入，但能进行更细粒度的控制如何选择候选者，具体使用方式如下： 123@Autowired@Qualifier(value = “demoInfoService”)private DemoInfoService demoInfoService; @Resource(name=”name”,type=”type”)：没有括号内内容的话，默认 byName。与 @Autowired 干类似的事。 三、JPA 注解@Entity：@Table(name=”“)：表明这是一个实体类。一般用于 jpa 这两个注解一般一块使用，但是如果表名和实体类名相同的话，@Table 可以省略 @MappedSuperClass: 用在确定是父类的 entity 上。父类的属性子类可以继承。 @NoRepositoryBean: 一般用作父类的 repository，有这个注解，spring 不会去实例化该 repository。 @Column：如果字段名与列名相同，则可以省略。 @Id：表示该属性为主键。 @GeneratedValue(strategy=GenerationType.SEQUENCE,generator= “repair_seq”)：表示主键生成策略是 sequence（可以为 Auto、IDENTITY、native 等，Auto 表示可在多个数据库间切换），指定 sequence 的名字是 repair_seq。 @SequenceGeneretor(name = “repair_seq”, sequenceName = “seq_repair”, allocationSize = 1)：name 为 sequence 的名称，以便使用，sequenceName 为数据库的 sequence 名称，两个名称可以一致。 @Transient：表示该属性并非一个到数据库表的字段的映射, ORM 框架将忽略该属性。 如果一个属性并非数据库表的字段映射, 就务必将其标示为 @Transient, 否则, ORM 框架默认其注解为 @Basic。@Basic(fetch=FetchType.LAZY)：标记可以指定实体属性的加载方式 @JsonIgnore：作用是 json 序列化时将 Java bean 中的一些属性忽略掉, 序列化和反序列化都受影响。 @JoinColumn（name=”loginId”）: 一对一：本表中指向另一个表的外键。一对多：另一个表指向本表的外键。 @OneToOne、@OneToMany、@ManyToOne：对应 hibernate 配置文件中的一对一，一对多，多对一。 四、springMVC 相关注解@RequestMapping：@RequestMapping(“/path”)表示该控制器处理所有 “/path” 的 UR L 请求。 RequestMapping 是一个用来处理请求地址映射的注解，可用于类或方法上。 用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。该注解有六个属性： params: 指定 request 中必须包含某些参数值是，才让该方法处理。 headers: 指定 request 中必须包含某些指定的 header 值，才能让该方法处理请求。 value: 指定请求的实际地址，指定的地址可以是 URI Template 模式 method: 指定请求的 method 类型， GET、POST、PUT、DELETE 等 consumes: 指定处理请求的提交内容类型（Content-Type），如 application/json,text/html; produces: 指定返回的内容类型，仅当 request 请求头中的 (Accept) 类型中包含该指定类型才返回 @RequestParam：用在方法的参数前面。@RequestParamString a =request.getParameter(“a”)。 @PathVariable: 路径变量。如 1234RequestMapping(“user/get/mac/&#123;macAddress&#125;”)public String getByMacAddress(@PathVariable String macAddress)&#123; //do something;&#125; 参数与大括号里的名字一样要相同。 五、全局异常处理@ControllerAdvice：包含 @Component。可以被扫描到。统一处理异常。 @ExceptionHandler（Exception.class）：用在方法上面表示遇到这个异常就执行以下方法。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"注解","slug":"注解","permalink":"http://www.devcheng.net/tags/注解/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Redis知识点汇总整理","slug":"Redis知识点汇总整理","date":"2020-08-17T12:41:47.000Z","updated":"2020-08-17T12:49:51.967Z","comments":true,"path":"post/72b87000.html","link":"","permalink":"http://www.devcheng.net/post/72b87000.html","excerpt":"","text":"背景最近，利用业余时间把Redis的知识点从基础到面试常问的点，全面系统的画了一个脑图。 这里先给大家安利一个在线画图processon，先看一下Redis知识点汇总整理好的一览图。 . 由于绘制的脑图很大，以上仅是图的一部分。 涉及知识点 基础知识点 数据持久化 过期策略 内存淘汰策略 常见问题 Redis事务 主从复制 Redis集群 应用场景 对应面试题 … 如有其它你觉得可以加进去的知识点，欢迎留言。后续会继续修改优化脑图！ 脑图地址: https://www.processon.com/view/link/5f34b188e0b34d0806735914 阅读密码：yicheng The end","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.devcheng.net/tags/Redis/"},{"name":"Redis知识点","slug":"Redis知识点","permalink":"http://www.devcheng.net/tags/Redis知识点/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"16个Redis面试题，你能回答出来几个？","slug":"16个Redis面试题，你能回答出来几个？","date":"2020-08-09T13:05:00.000Z","updated":"2020-08-09T13:19:24.674Z","comments":true,"path":"post/60b1ff4c.html","link":"","permalink":"http://www.devcheng.net/post/60b1ff4c.html","excerpt":"","text":"背景从网上整理一些在面试过程中常问的Redis相关的面试题，建议各位看官收藏！ 1.什么是redis?Redis 是一个基于内存的高性能key-value数据库。 2.Redis的特点Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。 因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。 Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据。 因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。 另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 3.使用redis有哪些好处？速度快：因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 支持丰富数据类型：支持string，list，set，sorted set，hash 支持事务：操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 4.redis相比memcached有哪些优势？memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 redis的速度比memcached快很多 redis可以持久化其数据 5.Memcache与Redis的区别都有哪些？存储方式：Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，这样能保证数据的持久性。 数据支持类型：Memcache对数据类型支持相对简单。Redis有复杂的数据类型。 使用底层模型不同：它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 6.redis常见性能问题和解决方案：1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。 Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化，如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 4).Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 7.mySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略（回收策略）。redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 8.请用Redis和任意语言实现一段恶意登录保护的代码，限制1小时内每用户Id最多只能登录5次。具体登录函数或功能用空函数即可，不用详细写出。 用列表实现：列表中每个元素代表登陆时间，只要最后的第5次登陆时间和现在时间差不超过1小时就禁止登陆。用Python写的代码如下： 1234567891011121314151617#!/usr/bin/env python3import redis import sys import time r = redis.StrictRedis(host=’127.0.0.1′, port=6379, db=0) try: id = sys.argv[1]except: print(‘input argument error’) sys.exit(0) if r.llen(id) &gt;= 5 and time.time() – float(r.lindex(id, 4)) &lt;= 3600: print(“you are forbidden logining”)else: print(‘you are allowed to login’) r.lpush(id, time.time()) # login_func() 9.为什么redis需要把所有数据放到内存中?Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。 如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 10.Redis是单进程单线程的redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销。 11.redis的并发竞争问题如何解决?Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。 Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是 由于客户端连接混乱造成。对此有2种解决方法： 客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。 服务器角度，利用setnx实现锁。 注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。 12.redis事物的了解CAS(check-and-set 操作实现乐观锁 )?和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。 相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出Redis中事务的实现特征： 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。 和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。 我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为”BEGIN TRANSACTION”语句。 在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。 然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。 然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。 此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。 13.WATCH命令和基于CAS的乐观锁：在Redis的事务中，WATCH命令可用于提供CAS(check-and-set)功能。 假设我们通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Null multi-bulk应答以通知调用者事务执行失败。 例如，我们再次假设Redis中并未提供incr命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：123val = GET mykeyval = val + 1SET mykey $val 以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景–竞态争用(race condition)。 比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。 为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：123456WATCH mykey val = GET mykey val = val + 1MULTI SET mykey $valEXEC 和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前 如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。 14.redis持久化的几种方式1、快照（snapshots） 缺省情况情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump。rdb。你可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE。 工作原理 Redis forks。子进程开始将数据写到临时RDB文件中。当子进程完成写RDB文件，用新文件替换老文件。这种方式可以使Redis使用copy-on-write技术。 2、AOF 快照模式并不十分健壮，当系统停止，或者无意中Redis被kill掉，最后写入Redis的数据就会丢失。这对某些应用也许不是大问题，但对于要求高可靠性的应用来说，Redis就不是一个合适的选择。 Append-only文件模式是另一种选择。你可以在配置文件中打开AOF模式。 3、虚拟内存方式 当你的key很小而value很大时，使用VM的效果会比较好。因为这样节约的内存比较大。当你的key不小时，可以考虑使用一些非常方法将很大的key变成很大的value，比如你可以考虑将key，value组合成一个新的value。 vm-max-threads这个参数，可以设置访问swap文件的线程数，设置最好不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的。可能会造成比较长时间的延迟，但是对数据完整性有很好的保证。 自己测试的时候发现用虚拟内存性能也不错。如果数据量很大，可以考虑分布式或者其他数据库 15.redis的缓存失效策略和主键失效机制作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略。 在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0），它可能会被删除。 1、影响生存时间的一些操作 生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。 比如说，对一个 key 执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用RENAME对一个 key 进行改名，那么改名后的 key的生存时间和改名前一样。 RENAME命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key 因此，新的 another_key 的生存时间也和原本的 key 一样。使用PERSIST命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个persistent key 。 2、如何更新生存时间 可以对一个已经带有生存时间的 key 执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1），EXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。 最大缓存配置 在 redis 中，允许用户设置最大使用内存大小，server。maxmemory默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。 redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。使用策略规则： 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random三种数据淘汰策略： ttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰。 16.redis 最适合的场景Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别 那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached，何时使用Redis呢? 如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点： Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 （1）会话缓存（Session Cache） 最常用的一种使用Redis的情景是会话缓存（session cache）。 用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 （2）全页缓存（FPC） 除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 （3）队列 Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 （4）排行榜/计数器 Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。 所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”。 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORESAgora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。 （5）发布/订阅 最后是Redis的发布/订阅功能。 发布/订阅的使用场景确实非常多，我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！ Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如此多功能。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Redis面试题","slug":"Redis面试题","permalink":"http://www.devcheng.net/tags/Redis面试题/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Spring Boot自定义注解获取当前登录用户信息","slug":"Spring-Boot自定义注解获取当前登录用户信息","date":"2020-07-24T13:16:41.000Z","updated":"2020-07-24T13:20:33.519Z","comments":true,"path":"post/c0d388e.html","link":"","permalink":"http://www.devcheng.net/post/c0d388e.html","excerpt":"","text":"背景在项目开发过程中，难免都要获取当前登录用户的信息。通常的做法，都是开发一个获取用户信息的接口。 如果在本项目中，多处都需要获取登录用户的信息，难不成还要调用自己写的接口吗？显然不用！ 以往的项目经验里，都是使用用户对应的Service获取，今天使用自定义注解对其进行数据绑定，从而获取登录用户信息。 步骤一：编写自定义注解先自定义一个用于绑定登录用户信息的注解，且运行时有效。 代码如下：123456789/** * 当前登录用户信息注解 */@Target(&#123;ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CurrentUser&#123; &#125; 步骤二：自定义UserResolverSpring boot封装了SpringMVC中的HandlerMethodArgumentResolver接口，自定义UserResolver要实现对应的2个接口。 代码如下：123456789101112131415161718192021/** * 当前登录用户Resolver */public class CurrentUserMethodArgumentResolver implements HandlerMethodArgumentResolver &#123; @Autowired private UserService userService; @Override public boolean supportsParameter(MethodParameter methodParameter) &#123; //判断方法参数是否带有@CurrentUser注解且参数类型为User或其子类 return methodParameter.hasParameterAnnotation(CurrentUser.class) &amp;&amp; User.class.isAssignableFrom(methodParameter.getParameterType()); &#125; @Override public Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory) throws Exception &#123; //获取当前登录用户 return userService.getCurrent(); &#125;&#125; 步骤三：WebMvcConfig配置自定义解析器新建一个webconfig 实现 WebMvcConfigurer 接口， 需要重写 addArgumentResolvers 这个方法，初始化我们创建的操作类。 代码如下：12345678910111213141516/** * 配置自定义解析器 */@Configurationpublic class MvcConfig implements WebMvcConfigurer&#123; @Bean public CurrentUserMethodArgumentResolver currentUserMethodArgumentResolver() &#123; return new CurrentUserMethodArgumentResolver(); &#125; @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers) &#123; argumentResolvers.add(currentUserMethodArgumentResolver()); &#125;&#125; 步骤四：编写代码测试1234@RequestMapping(value = \"/getUser\", method = RequestMethod.GET)public Map&lt;String, Object&gt; queryUser( @CurrentUser UserInfoVO userInfo) &#123; System.out.println(userInfo);&#125; 小结之所以能够自定义注解获取当前登录用户信息，就是借助于HandlerMethodArgumentResolver来扩展自己的参数解析器。 在resolveArgument接口中编写对应获取登录用户信息的逻辑代码。举个栗子，有的系统是从数据库中获取数据，有的则把对应数据放在redis中。所以在这里从不同地方获取即可。 The end.","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"HandlerMethodArgumentResolver","slug":"HandlerMethodArgumentResolver","permalink":"http://www.devcheng.net/tags/HandlerMethodArgumentResolver/"},{"name":"自定义注解","slug":"自定义注解","permalink":"http://www.devcheng.net/tags/自定义注解/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"重装系统如何继续恢复Hexo博客","slug":"重装系统如何继续恢复Hexo博客","date":"2020-07-12T09:42:58.000Z","updated":"2020-07-13T13:38:52.159Z","comments":true,"path":"post/7fee676.html","link":"","permalink":"http://www.devcheng.net/post/7fee676.html","excerpt":"","text":"背景由于电脑系统使用的时间久了之后，渐渐的感觉在使用电脑的时候有卡顿以及响应时间逐渐变长。开始还以为是系统垃圾的缘故，但是清理系统垃圾之后还是有卡顿的现象，干脆从新装一个系统得了。 在重装系统之前，事先把原来Hexo的文件夹都备份一下。同时，我还备份了对应的id_rsa和id_rsa.pub文件。 如果要重装系统，务必要备份对应的文件！ 备份好对应的文件之后，开始重装系统！ 安装Node.js和Git1.安装Node.js 2.安装Git 具体细节就不展开细说了，可自行为度娘！安装成功node.js和git之后，查看一下确保无问题。 配置SSH key在最上面，已经提及到了 SSH key 对应的2个文件，找到路径 C:\\Users\\用户名.ssh 有无.ssh文件夹，没有则创建。 执行命令，如下：12cd ~/. sshssh-keygen -t rsa -C &quot;邮件地址&quot; 因为重装系统之前已经备份id_rsa和id_rsa.pub文件,所以把这2个文件复制到.ssh文件夹内即可。 使用命令，测试是否成功。1ssh -T git@e.coding.net 配置Git用户名和邮箱12git config --global user.name &quot;devcheng&quot; // 你的coding或github用户名，并非昵称git config --global user.email &quot;xxx@qq.com&quot;// 你的coding或github的注册邮箱 复制备份的文件夹文件夹删除node_modules public .git .deploy_git 和远程项目关联12git initgit remote add origin 你的hexo博客git地址 安装hexo开始执行命令： 1npm install -g hexo 并没有成功的安装好hexo,于是从新换一个命令，如下： 1npm install hexo --save 依然还是提示有对应的依赖没有找到，于是我把最开始备份的整个文件夹，全部都复制到了现在这个目录。 强势启动1hexo s 突然发现，居然可以启动起来。 小结以上步骤，仅供参考，步骤不是惟一定死的，各位务必根据自己的操作情况而定。这篇博客就是从重装系统之后写的第一篇博文！如有不妥之处，请留言！ The end","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"恢复Hexo","slug":"恢复Hexo","permalink":"http://www.devcheng.net/tags/恢复Hexo/"},{"name":"重装系统","slug":"重装系统","permalink":"http://www.devcheng.net/tags/重装系统/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MySQL中按字段查询重复数据","slug":"MySQL中按字段查询重复数据","date":"2020-07-09T13:37:57.000Z","updated":"2020-07-09T13:48:17.605Z","comments":true,"path":"post/4dfd5416.html","link":"","permalink":"http://www.devcheng.net/post/4dfd5416.html","excerpt":"","text":"背景在项目开发中，难免会遇到xx表有重复数据(脏数据)，导致的原因有很多，可能是测试人员一直在添加同一条数据，也可能是编写的功能本身就存在bug(没有对数据做重复数据校验)等。 既然是难免的情况，那如何处理呢？ 根据一个字段查询重复数据举个栗子，有个用户表测试小姐姐拼命的创建同一条数据插入到用户表。那么在用户表中就会存在相同用户名的多条数据，根据 用户名 查询重复数据的SQL如下： 1SELECT userName from tb_user GROUP BY userName HAVING count(*) &gt; 1; 如果查询出来重复数据只需要保留一条，那就得把多余的数据删除即可，对应SQL如下： 1DELETE FROM tb_user WHERE userId NOT IN ( SELECT MAX( userId ) AS maxid FROM tb_user GROUP BY userName); 这里是根据 用户名分组保留用户ID最大的那条数据，其它的都删掉！具体保留哪条数据，各位小伙伴可自行决定~ 根据多个字段查询重复数据在举个栗子，在这个用户表中 用户名和用户类型 都重复的需要查询出来，对应的SQL如下： 1SELECT * FROM tb_user GROUP BY userName,userType HAVING count(*) &gt; 1; 根据多个字段查询，保留一条数据，删除多余数据SQL如下： 方法一：1DELETE FROM tb_user WHERE userId NOT IN ( SELECT MAX( userId ) AS maxid FROM tb_user GROUP BY userName,userType); 方法二：1SELECT nameAndType from (SELECT CONCAT(userName,userType) as nameAndType from tb_user) tt GROUP BY nameAndType HAVING count(nameAndType) &gt; 1; 方法三：1DELETE FROM tb_user WHERE userId NOT IN (SELECT maxid from (SELECT MAX(userId) as maxid, CONCAT(userName,userType) as nameAndType from tb_user GROUP BY nameAndType) t); 方法一中删除多余重复数据和上面文章中的思路是一致的，方法二和方法三的思路是利用CONCAT函数。 以上，如果你开发过程中遇到同样问题，可以使用上面的SQL尝试一下！ The end…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.devcheng.net/tags/MySQL/"},{"name":"重复数据","slug":"重复数据","permalink":"http://www.devcheng.net/tags/重复数据/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Java8中列表的排序(升序、降序)","slug":"Java8中列表的排序-升序、降序","date":"2020-07-02T13:34:11.000Z","updated":"2020-07-02T13:45:39.000Z","comments":true,"path":"post/835182f7.html","link":"","permalink":"http://www.devcheng.net/post/835182f7.html","excerpt":"","text":"写在前面还记得几年前，那时候查询数据基本都是在数据库中把查询的数据做好排序。举个栗子，在查询User表的时候按照创建时间升序查询出来。 时过境迁，现在的项目中采用了Spring Data JPa,当然也支持排序。但本文中的主角可不是它，在很多情况下我们查询出来的List数据没有排序好或是需要二次按照某字段排序，这个时候，我们就可以使用Java8对其排序。 首先，看个基础语法，如下： 单个字段排序123456789101112List&lt;类&gt; list; 代表某集合 //返回 对象集合以类属性一升序排序list.stream().sorted(Comparator.comparing(类::属性一)); /*** 返回 对象集合以类属性一降序排序 注意两种写法**//先以属性一升序,结果进行属性一降序list.stream().sorted(Comparator.comparing(类::属性一).reversed());//以属性一降序 list.stream().sorted(Comparator.comparing(类::属性一,Comparator.reverseOrder())); 多个字段排序12345678910111213141516171819202122232425262728// 返回 对象集合以类属性一升序 属性二升序list.stream().sorted(Comparator.comparing(类::属性一).thenComparing(类::属性二)); //先以属性一升序,升序结果进行属性一降序,再进行属性二升序 list.stream().sorted(Comparator.comparing(类::属性一).reversed().thenComparing(类::属性二)); //先以属性一降序,再进行属性二升序list.stream().sorted(Comparator.comparing(类::属性一,Comparator.reverseOrder()).thenComparing(类::属性二)); /*** 返回 对象集合以类属性一降序 属性二降序 注意两种写法**/ //先以属性一升序,升序结果进行属性一降序,再进行属性二降序list.stream().sorted(Comparator.comparing(类::属性一).reversed().thenComparing(类::属性二,Comparator.reverseOrder()));//先以属性一降序,再进行属性二降序list.stream().sorted(Comparator.comparing(类::属性一,Comparator.reverseOrder()).thenComparing(类::属性二,Comparator.reverseOrder())); /*** 返回 对象集合以类属性一升序 属性二降序 注意两种写法**/ //先以属性一升序,升序结果进行属性一降序,再进行属性二升序,结果进行属性一降序属性二降序 list.stream().sorted(Comparator.comparing(类::属性一).reversed().thenComparing(类::属性二).reversed()); //先以属性一升序,再进行属性二降序 list.stream().sorted(Comparator.comparing(类::属性一).thenComparing(类::属性二,Comparator.reverseOrder())); 实例代码12345//根据User对象的id字段降序排序userList.sort(Comparator.comparing(User::getId).reversed());//根据User对象的id字段降序排序userList.sort(User::getId,Comparator.reverseOrder()); 小结通过以实例代码我们可以发现 写法一： Comparator.comparing(类::属性一).reversed(); 写法二： Comparator.comparing(类::属性一,Comparator.reverseOrder()); 两种排序是完全不一样的,一定要区分开来。 写法一是得到排序结果后再排序； 写法二是直接进行排序,很多人会混淆导致理解出错,但写法二更好理解,建议使用写法二。 完整例子demo最后贴一个完整的例子，供大家参考1234567891011121314151617181920212223242526public static void main(String[] args) &#123; User user1 = new User(22,\"张X\"); User user2 = new User(27,\"李X\"); User user3 = new User(21,\"王X\"); User user4 = new User(18,\"赵X\"); List&lt;User&gt; list = new ArrayList&lt;User&gt;(); list.add(user1); list.add(user2); list.add(user3); list.add(user4); for(User u :list)&#123; System.out.println(u); &#125; List&lt;User&gt; newList = list.stream().sorted(Comparator.comparing(User::getAge)) .collect(Collectors.toList()); for(User u :newList)&#123; System.out.println(u); &#125;&#125;@Dataclass User &#123; private int age; private String name;&#125;","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://www.devcheng.net/tags/Java8/"},{"name":"排序","slug":"排序","permalink":"http://www.devcheng.net/tags/排序/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Java中三大构建工具的发展历程（Ant、Maven和Gradle）","slug":"Java中三大构建工具的发展历程（Ant、Maven和Gradle）","date":"2020-06-21T07:47:09.000Z","updated":"2020-06-21T07:49:21.042Z","comments":true,"path":"post/e200ec64.html","link":"","permalink":"http://www.devcheng.net/post/e200ec64.html","excerpt":"","text":"背景我们要写一个Java程序，一般的步骤是编译，测试，打包。 这个构建的过程，如果文件比较少，我们可以手动使用java, javac,jar命令去做这些事情。但当工程越来越大，文件越来越多，这个事情就不是那么地令人开心了。 因为这些命令往往都是很机械的操作。所以我们可以把这些机械的操作交给机器去做。 而在linux中，有一个工具叫make。我们可以通过编写Makefile来执行工程的构建，在windows上相应的工具是nmake。 那既然有现成的工具，为什么当时没有选择Makefile呢？说道这里那就不得不提一下Ant了。 Ant说起Ant，就不得不说另一个Apache开源项目Tomcat。Tomcat作为轻量级Web容器，早已声名鹊起。最开始的时候，Ant是Tomcat的一部分，Ant的唯一目的就是build Tomcat。 不久，很多Java开源项目意识到Ant的简洁适用，更重要的是弥补Makefiles的不足。自从Jakarta以及Apache项目开始采用Ant以来,作为构建工具的Ant很快发展在各种各样的项目中。 在2000年1月，Ant脱离了Tomcat，成为独立的Apache开源项目，由独立的CVS模块维护，正式更名为Apache Ant。 第一个Ant版本是Tomcat 3.1于2000年4月19日发行的版本。此版本后来称为Ant 0.3.1。 到目前Ant最新的版本是 2020年5月13日 版本号：1.10.8 具体的版本发行历程可点击链接查看 http://ant.apache.org/faq.html Ant示例12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;project name=\"HelloWorld\" default=\"run\" basedir=\".\"&gt; &lt;property name=\"src\" value=\"src\"/&gt; &lt;property name=\"dest\" value=\"classes\"/&gt; &lt;property name=\"jarfile\" value=\"hello.jar\"/&gt; &lt;target name=\"init\"&gt; &lt;mkdir dir=\"$&#123;dest&#125;\"/&gt; &lt;/target&gt; &lt;target name=\"compile\" depends=\"init\"&gt; &lt;javac srcdir=\"$&#123;src&#125;\" destdir=\"$&#123;dest&#125;\"/&gt; &lt;/target&gt; &lt;target name=\"build\" depends=\"compile\"&gt; &lt;jar jarfile=\"$&#123;jarfile&#125;\" basedir=\"$&#123;dest&#125;\"/&gt; &lt;/target&gt; &lt;target name=\"test\" depends=\"build\"&gt; &lt;java classname=\"test.ant.HelloWorld\" classpath=\"$&#123;hello_jar&#125;\"/&gt; &lt;/target&gt; &lt;target name=\"clean\"&gt; &lt;delete dir=\"$&#123;dest&#125;\" /&gt; &lt;delete file=\"$&#123;hello_jar&#125;\" /&gt; &lt;/target&gt; &lt;/project&gt; 由示例，得知Ant定义了五个任务，init, compile, build, test,clean。 每个任务做什么都定义清楚了。在打包之前要先编译，所以通过depends来指定依赖的路径。 如果在命令行里执行ant build，那就会先执行compile，而compile又依赖于init，所以就会先执行init。 执行命令：1ant test 通过命令就可以执行编程，打包，测试。为开发者带来了很大的便利，提供了工作效率。 但是Ant有一个很致命的缺陷，那就是没办法管理依赖。 我们一个工程，要使用很多第三方工具，不同的工具，不同的版本。 每次打包都要自己手动去把正确的版本拷到lib下面去，不用说，这个工作既枯燥还特别容易出错。为了解决这个问题，Maven如约而至。 MavenMaven之前我们经常使用Ant来进行Java项目的构建，然后Ant仅是一个构建工具，它并未对项目的中的工程依赖以及项目本身进行管理，并且Ant作为构建工具未能消除软件构建的重复性，因为不同的项目需要编写对应的Ant任务。 Maven作为后来者，继承了Ant的项目构建功能，并且提供了依赖关系，项目管理的功能，因此它是一个项目管理和综合工具， 其核心的依赖管理， 项目信息管理， 中央仓库，约定大于配置的核心功能使得Maven成为当前Java项目构建和管理工具的标准选择。 Maven 发展历程： Maven –&gt; Maven2 –&gt; Maven3 到目前Maven最新的版本是 2019-11-25 版本号：3.6.3 Maven示例1234567891011121314&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;project ...xmlns...&gt; &lt;groupId&gt;net.devcheng.demo&lt;/groupId&gt; &lt;artifactId&gt;Example&lt;/artifactId&gt; &lt;version&gt;0.1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 由示例得知，包的坐标是net.devcheng.demo:Example:0.1.0-SNAPSHOT，而工程中要依赖junit:junit:4.10。 那么Maven就会自动去帮我把junit打包进来。如果本地没有junit，maven还会帮自动去网上下载。我们还通过Maven安装目录下的settings.xml文件可以配置本地仓库的路径，以及采用的远程仓库的地址。 相对于上文中的Ant来说，Maven抛弃了Ant中通过target定义任务的做法，对于依赖引入了生命周期。 最后在说说 Gradle。 GradleGradle是一个基于Apache Ant和ApacheMaven概念的项目自动化构建开源工具。它使用一种基于Groovy的特定领域语言(DSL)来声明项目设置，目前也增加了基于Kotlin语言的kotlin-based DSL，抛弃了基于XML的各种繁琐配置。 由以上定义得知，Gradle已经抛弃了Ant,Maven中Xml配置的形式。Gradle继承了Maven中仓库，坐标，依赖这些核心概念。文件的布局也和Maven相同。但同时，又继承了Ant中target的概念，我们又可以重新定义自己的任务(在Gradle中叫做task)。 Gradle示例1234567891011apply plugin: &apos;java&apos;repositories &#123; jcenter()&#125;dependencies &#123; compile &apos;org.slf4j:slf4j-api:1.7.21&apos; your tests. testCompile &apos;junit:junit:4.12&apos;&#125; 由示例可看出内容很简单，引入了java插件，指定仓库，指定依赖。可以看到依赖的设定相比起xml的写法，变得大大简化了。 到目前Gradle最新的版本是 2020年6月2日 版本号：v6.5 Gradle vs Maven关于Gradle和Maven的区别，简单比较如下： Maven和Gradle对依赖项的scope有所不同。在Maven世界中，一个依赖项有6种scope，分别是complie(默认)、provided、runtime、test、system、import。而grade将其简化为了4种，compile、runtime、testCompile、testRuntime。 Gradle支持动态的版本依赖。在版本号后面使用+号的方式可以实现动态的版本管理。 解决依赖冲突方面Gradle的实现机制更加明确。使用Maven和Gradle进行依赖管理时都采用的是传递性依赖；而如果多个依赖项指向同一个依赖项的不同版本时就会引起依赖冲突。而Maven处理这种依赖关系往往是噩梦一般的存在。而Gradle在解决依赖冲突方面相对来说比较明确。 Maven引用依赖方面采用的xml，而Gradle不是。 The End","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Ant","slug":"Ant","permalink":"http://www.devcheng.net/tags/Ant/"},{"name":"Maven","slug":"Maven","permalink":"http://www.devcheng.net/tags/Maven/"},{"name":"Gradle","slug":"Gradle","permalink":"http://www.devcheng.net/tags/Gradle/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"java通过反射获取注解@Column中的信息","slug":"java通过反射获取注解-Column中的信息","date":"2020-06-20T02:44:08.000Z","updated":"2020-06-20T02:49:43.679Z","comments":true,"path":"post/74b831b2.html","link":"","permalink":"http://www.devcheng.net/post/74b831b2.html","excerpt":"","text":"背景在工作中需要从实体类的@Column注解中获取对应的信息，先一个实体类的上代码，如下：123456789101112131415161718192021222324252627282930313233343536373839404142package com.devcheng.demo.restful.data.service.model.entity;import com.fasterxml.jackson.databind.annotation.JsonDeserialize;import com.fasterxml.jackson.databind.annotation.JsonSerialize;import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer;import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer;import lombok.Data;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.Id;import javax.persistence.Table;import java.time.LocalDateTime;@Data@Entity@Table(name = \"DEV_CHENG_FILE_DEMO\")public class DiscloseFileEntity&#123; @Id @Column(name = \"ID\",columnDefinition = \"ID\") private String id; @Column(name = \"APPLY_NO\",columnDefinition = \"申请号\") private String applyNo; @Column(name = \"FILE_NAME\",columnDefinition = \"文件名称\") private String fileName; @Column(name = \"FILE_SIZE\",columnDefinition = \"文件大小\") private String fileSize; @Column(name = \"TITLE\",columnDefinition = \"标题\") private String title; @Column(name = \"IS_VALID\",columnDefinition = \"是否有效\") private String isValid; @Column(name = \"SAVE_DATE\",columnDefinition = \"保存日期\") private LocalDateTime saveDate; &#125; 由上得知，需要从 @Column 注解中获取 name和columnDefinition 中的信息，那如何可以获取到对应的信息？ 在获取 @Column 注解中的信息之前，先看看 columnDefinition是啥意思? columnDefinitioncolumnDefinition属性表示创建表时，该字段创建的SQL语句，一般用于通过Entity生成表定义时使用，如果数据库中表已经建好，该属性没有必要使用。 值得注意的一点是：在编程语言中字符串一般都用String表示，但是数据库中varcahr数值类型有长度限制，一旦需要大文本，则需要text数值类型。但是String类型默认映射的数值类型是varchar，columnDefinition可以进行额外指定。 获取注解@Column中的信息实现思路：通过类路径利用反射获取到对应的注解信息，从而获取到对应@Column中的信息代码如下： 1234567891011121314151617181920212223242526public static List&lt;TableColumnsVO&gt; getFiledAndAnnotateInfo(String entityPath) &#123; List&lt;TableColumnsVO&gt; tableColumnsLists = new ArrayList&lt;&gt;(); try &#123; Class&lt;?&gt; aClass = Class.forName(entityPath); Field[] fields = aClass.getDeclaredFields(); Column presentColumn; for (Field field:fields) &#123; field.setAccessible(true); if(field.isAnnotationPresent(Column.class)) &#123; presentColumn = field.getDeclaredAnnotation(Column.class); TableColumnsVO tableData = new TableColumnsVO(); tableData.setColumnName(presentColumn.name()); tableData.setColumnDefinationInfo(presentColumn.columnDefinition()); tableColumnsLists.add(tableData); &#125; &#125; &#125; catch (ClassNotFoundException e) &#123; log.info(String.format(\"获取字段和注释异常：%s\", entityPath)); &#125; return tableColumnsLists; &#125; 对应的 TableColumnsVO代码如下:123456789import lombok.Data;@Datapublic class TableColumnsVO&#123; //列名 private String columnName; //ColumnDefinationInfo信息 private String columnDefinationInfo;&#125;","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"java反射","slug":"java反射","permalink":"http://www.devcheng.net/tags/java反射/"},{"name":"Column注解","slug":"Column注解","permalink":"http://www.devcheng.net/tags/Column注解/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"墙裂推荐一款redis客户端可视化工具之RedisPlus","slug":"墙裂推荐一款redis客户端可视化工具之RedisPlus","date":"2020-06-07T07:15:43.000Z","updated":"2020-06-07T07:23:36.448Z","comments":true,"path":"post/64102a3b.html","link":"","permalink":"http://www.devcheng.net/post/64102a3b.html","excerpt":"","text":"背景在实际工作中，项目中使用redis的项目肯定很多，因此大家或多或少都会接触过一些redis客户端可视化工具。比如：Redis Desktop Manager，RedisView ，RedisClient 等工具。 今天墙裂推荐一款redis客户端可视化工具：RedisPlus RedisPlus官方描述RedisPlus是为Redis可视化管理开发的一款开源免费的桌面客户端软件，支持Windows 、Linux、Mac三大系统平台，RedisPlus提供更加高效、方便、快捷的使用体验，有着更加现代化的用户界面风格。该软件支持单机、集群模式连接，同时还支持SSH（单机、集群）通道连接。 项目地址： https://gitee.com/MaxBill/RedisPlus 运行截图： RedisPlus目前最新版本为：3.2.0。项目介绍中得知，RedisPlus将不再更新迭代，包括V4.0的electron和jfx11版本都将停止开发和更新。 下载地址百度下载：链接: https://pan.baidu.com/s/1GjNFwbmksA1JhguHgcAcSQ 提取码: 3pcm 最后说一句在网上不乏有很多redis客户端工具，但是真正能支持集群的没几个工具，同时也找到了一款国外的工具，名字叫FastoRedis。下载地址：https://fastoredis.com/anonim_users_downloads FastoRedis 的官方介绍Download FastoRedis - cross-platform client for Redis, supported main Redis database features like: modules, cluster, sentinel, ssh tunneling. 但是这款工具是收费的，土豪请无视这句话！ 最后有需要RedisPlus的又觉得从百度网盘下载麻烦的，可以加一下我的QQ群：816175200 免费获取。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"RedisPlus","slug":"RedisPlus","permalink":"http://www.devcheng.net/tags/RedisPlus/"},{"name":"redis客户端","slug":"redis客户端","permalink":"http://www.devcheng.net/tags/redis客户端/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"JDK各个版本新特性小结","slug":"JDK各个版本新特性小结","date":"2020-05-30T07:07:22.000Z","updated":"2020-05-30T07:08:50.691Z","comments":true,"path":"post/5ae138f6.html","link":"","permalink":"http://www.devcheng.net/post/5ae138f6.html","excerpt":"","text":"截止到今天(2020-5-30)JDK已经发布到了 JDK14。 在2017年8月，JCP执行委员会提出将Java的发布频率改为每六个月一次，新的发布周期严格遵循时间点，将在每年的3月份和9月份发布。 JDK 14已经于2020年3月17日如期发布。下面介绍各个版本的新特性，后续随着JDK新版本的更新迭代，本文会持续更新。 JDK从1.5版本开始，在官方的正式文档与宣传资料中已经不再使用类似JDK1.5的名称，只有程序员内部 使用的开发版本号(DeveloperVersion，例如java-version的输出)才继续沿用1.5、1.6、1.7和1.8的版本号， 而公开版本号(Product Version)则改为JDK5、JDK6、JDK7和JDK8的命名方式。 JDK 5 新特性1.自动装箱、拆箱 2.静态导入(static import) 3.增强for循环（for-each） 4.可变参数 5.枚举（enmu） 6.泛型 7.元数据 8.线程并发库（JUC） JDK 6 新特性1.AWT中新增的两个类Desktop和SystemTray 2.使用JAXB2来实现对象与XML之间的映射 新增处理DOM和SAX之外又一种处理XML文档的API：STAX 使用Compiler API动态编译java源文件 轻量级Http Server API 插入式注解处理API（用于处理Annotations） 用Console开发控制台程序 对ruby、groovy、javascript等脚本语言的支持 Common Annotations JDK 7 新特性 对Java集合（Collections）的增强支持 在switch中可用String 数值可加下划线（eg:int one_million=123_1） 支持二进制文字（int binary=0b1001_1001） 简化可变参数方法的调用 自动资源管理 类型推断 catch 多个类型异常 JDK 8 新特性 Stream函数式操作流元素集合 Lambda表达式 新的日期时间 API(Java Date/time API) 新增接口：默认方法与静态方法 Nashorm(Rhino的接替者，轻量级高性能的javascript运行环境) Accumlators多线程lock 方法引用，与Lambda表达式联合使用 引入重复注解和类型注解 类型注解 新增base64加解密API 数组并行（parallel）操作 JVM的permGen空间移除，被Metaspace元空间取代 JDK 9 新特性 目录结构 模块化系统 jshell 多版本兼容JAR 接口的私有方法 改进try-with-resourcs 改进砖石操作符 限制使用单独下划线标识符 String存储结构变更 快速创建只读结合 增强Stream API 改进Optional 类 多分辨率图像 API 全新 HTTP客服端API 智能JAVA 编译工具 统一JVM 日志系统 javadoc 的 HTML5 支持 java 动态编译 JDK 10 新特性 局部变量类型推断 将JDK多存储库合并为单储存库 垃圾回收接口 并行Full GC 的G1 应用数据共享 线程局部管控 移除Native-Header Generation Tool （javah） Unicode 标签扩展 备用内存设备上分配堆内存 基于实验JAVA 的JIT 编译器 Root 证书 基于时间的版本控制 JDK 11 新特性 字符串加强 HttClient Api 用于 Lambda 参数的局部变量语法 ZGC (并发回收的策略) JDK 12 新特性 Switch Expressions Shenandoah GC (GC 算法) JDK 13 新特性 switch优化更新 文本块升级 重新实现旧版套接字API 核心库/java.util中：I18N 增加ZGC以将未使用的堆内存返回给操作系统 JDK 14 新特性 switch优化变更为最终版 垃圾回收相 删除cms垃圾收集器 弃用 ParallelScavenge + SerialOld GC 的垃圾回收算法组合 将 zgc 垃圾回收器移植到 macOS 和 windows 平台 instanceof的模式匹配（预览版） 删除了安全库java.security.acl API 货币格式（优化） 友好的空指针异常 外部存储器API（孵化） … 本文会持续更新…","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"新特性","slug":"新特性","permalink":"http://www.devcheng.net/tags/新特性/"},{"name":"JDK","slug":"JDK","permalink":"http://www.devcheng.net/tags/JDK/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"15个超实用的IDEA快捷键","slug":"15个超实用的IDEA快捷键","date":"2020-05-23T04:28:19.000Z","updated":"2020-05-23T04:47:57.551Z","comments":true,"path":"post/ea3f1216.html","link":"","permalink":"http://www.devcheng.net/post/ea3f1216.html","excerpt":"","text":"叨叨叨相信很多开发的小伙伴，或多或少都知道一些IDEA中的快捷键，我们常说的CV大法(Ctrl+C,Ctrl+V)也是常用的快捷键之一。掌握必要的一些快捷键，可以提高工作效率，但是IDEA中的快捷键可不是一个两个。为此博主特意整理里15个高频超级实用的IDEA快捷键。 快捷键Ctrl + Alt + O : 移除未使用的包 tip:可能会和QQ 屏幕识图快捷键冲突，解决方法可重新自定义QQ快捷键。 Ctrl + Alt + M :重构函数:将选中代码提取为函数 Ctrl + Alt + L :代码格式化 tip:可能会和QQ 中的快捷键冲突，解决方法可重新自定义QQ快捷键。 Ctrl + Alt + T:可以把代码包在一个块内，例如：try/catch Ctrl + Alt + B:定位至选中类或者方法的具体实现 Ctrl + Shift + F:全局查找快捷键 Ctrl + Shift + R:全局替换 Ctrl + Shift + U:大小写切换 Ctrl + Shift + /:使用 /**/ 注释 Ctrl + /:使用 // 注释 Ctrl + X（Ctrl + Y）:删除行 Ctrl + D:复制行 Ctrl+Shift+Alt+J:批量修改变量快捷键 F2 或 Shift+F2:快速定位高亮错误或警告 Shift+Click:可以关闭文件","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"IDEA快捷键","slug":"IDEA快捷键","permalink":"http://www.devcheng.net/tags/IDEA快捷键/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于Spring Boot开发的毕业论文管理系统(包含毕业论文)","slug":"基于Spring-Boot开发的毕业论文管理系统","date":"2020-05-08T12:22:47.000Z","updated":"2021-03-12T14:29:50.300Z","comments":true,"path":"post/1129f657.html","link":"","permalink":"http://www.devcheng.net/post/1129f657.html","excerpt":"","text":"前言本项目是基于Spring Boot开发的毕业论文管理系统，系统用户角色分为三个类型，分别是：学生，教师，管理员。不同角色拥有不同的菜单功能，管理员是系统中权限最大的一个角色，即可以管理系统的各个配置以及数据操作。 开发环境（运行环境）-系统环境：Windows 10-开发工具：IntelliJ IDEA 2019.3-Java版本：JDK 1.8 项目技术栈 Spring Boot Mybatis Maven Thymeleaf Echarts 文件服务器centos7 … 项目页面预览 系统登录页 系统首页 个人信息页 数据分析页 选题情况页 菜单开关页 学生管理页 修改密码页 下载任务书 上传论文页 选定学生页 注意事项使用IDEA(eclipse)前导入本项目前，请确保你本地环境是已经配置好了Java环境变量，本地安装好了虚拟机且是centos7。文件服务器搭建可以参考 点击 文件服务器搭建 传送门 联系我们如有需要源码可以通过 QQ 搜索：792435323联系我！ 温馨提示本项目可以当做毕业设计，内含毕业论文。 其它说明白嫖党绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"毕业论文管理系统","slug":"毕业论文管理系统","permalink":"http://www.devcheng.net/tags/毕业论文管理系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"centos7.x搭建ftp服务及创建用户","slug":"centos7-x搭建ftp服务及创建用户","date":"2020-04-18T13:23:05.000Z","updated":"2020-04-18T13:45:26.301Z","comments":true,"path":"post/c668f449.html","link":"","permalink":"http://www.devcheng.net/post/c668f449.html","excerpt":"","text":"FTP是什么东东？FTP是 File Transfer Protocol 文件传输协议的英文名称,用于在Internet上控制文件的双向传输. 同时它也是一个应用程序.一般的Linux系统默认带有ftp软件或者是vsftpd。 为何搭建？目的是从window系统中上传文件到linux系统的服务器里。 ##安装步骤提前使用终端工具连接上对应的服务器，这里我们以Xshell 为例 步骤一 登录到服务器后，先切换为 root 用户切换到 home 文件夹下（可以换任意一个你喜欢的文件夹下，这里以home文件夹为例）1cd /home 步骤二 接着，输入以下命令1wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 步骤三 1rpm -ivh epel-release-6-8.noarch.rpm 步骤四 1yum install vsftpd 注意： 安装完成后，找到 /etc/vsftpd/vsftpd.conf 文件，是vsftp的配置文件。 步骤五 修改selinux1getsebool -a | grep ftp 执行上面命令，从返回的结果看到 ftpd_full_access 和 tftp_home_dir两行都是off，说明没有开启外网的访问。 步骤六 开启外网的访问 12[root@bogon ~]# setsebool -P ftpd_full_access on[root@bogon ~]# setsebool -P tftp_home_dir on 步骤七 关闭匿名访问修改 /etc/vsftpd/vsftpd.conf文件：找到 anonymous_enable=NO #将YES改为NO 到此基本配置都完成了，使用以下命令重启 ftp 服务1systemctl restart vsftpd.service 另外设置一下 开机启动 ftp 服务使用以下命令即可1systemctl enable vsftpd.service 通过以上的几个步骤，ftp 服务就已经搭建完毕，接着我们还需要创建用户并指定对应的目录 创建目录以及用户在/var 目录下创建一个 www 文件夹,www文件夹中创建一个site文件夹一个da文件夹12345cd /varmkdir wwwcd wwwmkdir sitemkdir da 创建用户da并指定用户目录为/var/www/da12useradd -d /var/www/da dapasswd da 修改xiao用户的用户目录为/var/www/site1usermod -d /var/www/site xiao 查看新创建的用户的信息1tail /etc/passwd 修改/etc/vsftpd/vsftpd.conf文件1vi vsftpd.conf 找到 userlist_enable=YES 在这句后面换行追加以下内容12userlist_deny=NO userlist_file=/etc/vsftpd/user_list 完成 vsftpd.conf 文件修改之后保存退出。 编辑 user_list 文件1vi user_list 把上面的两个用户 一行一个用户名,输入 da 和xiao按下esc键退出输入模式进入命令模式输入:wq 保存并退出 配置文件夹权限切换到 /var/www 目录1cd /var/www 更改www里面两个文件夹的权限输入以下命令12chown da:da dachown xiao:xiao site 修改da用户的所属用户组,并修改site文件夹的权限1usermod -g xiao da 修改site文件夹的权限,允许同一个用户组的用户拥有rwx权限1chmod 775 site 到此搭建ftp和创建目录和创建对应用户都全部完成！接下来在代码中验证一下 使用springboot的配置文件application.yml 配置对应信息，如下123456ftp: host: 192.168.43.41 #你服务器的ip port: 21 #端口 userName: da #以上创建的ftp用户名 password: da #以上创建的ftp密码 basePath: /var/www/da #文件存放目录 上传文件 代码段 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public static boolean uploadFile(String host, int port, String username, String password, String basePath, String filePath, String filename, InputStream input) &#123; boolean result = false; FTPClient ftp = new FTPClient(); try &#123; int reply; ftp.connect(host, port);// 连接FTP服务器 // 如果采用默认端口，可以使用ftp.connect(host)的方式直接连接FTP服务器 ftp.login(username, password);// 登录 reply = ftp.getReplyCode(); if (!FTPReply.isPositiveCompletion(reply)) &#123; ftp.disconnect(); return result; &#125; //切换到上传目录 if (!ftp.changeWorkingDirectory(basePath + filePath)) &#123; //如果目录不存在创建目录 String[] dirs = filePath.split(\"/\"); String tempPath = basePath; for (String dir : dirs) &#123; if (null == dir || \"\".equals(dir)) continue; tempPath += \"/\" + dir; if (!ftp.changeWorkingDirectory(tempPath)) &#123; if (!ftp.makeDirectory(tempPath)) &#123; return result; &#125; else &#123; ftp.changeWorkingDirectory(tempPath); &#125; &#125; &#125; &#125; //设置上传文件的类型为二进制类型 ftp.setFileType(FTP.BINARY_FILE_TYPE); //上传文件 if (!ftp.storeFile(filename, input)) &#123; return result; &#125; input.close(); ftp.logout(); result = true; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (ftp.isConnected()) &#123; try &#123; ftp.disconnect(); &#125; catch (IOException ioe) &#123; &#125; &#125; &#125; return result;&#125; 看到这里说明以上的配置都没问题，到此本文告一段落了！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"centos7","slug":"centos7","permalink":"http://www.devcheng.net/tags/centos7/"},{"name":"搭建ftp服务","slug":"搭建ftp服务","permalink":"http://www.devcheng.net/tags/搭建ftp服务/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"win10怎么把两张图片合并为一张","slug":"win10怎么把两张图片合并为一张","date":"2020-04-07T05:37:28.000Z","updated":"2020-04-08T01:56:18.463Z","comments":true,"path":"post/87dbd908.html","link":"","permalink":"http://www.devcheng.net/post/87dbd908.html","excerpt":"","text":"背景在工作中往往有这样的情况，同事发了多张图片给你，如果利用系统的图片查看软件需要一张一张的打开。来回的切换查看图片，很是不方便。 不管你的操作系统是win7还是win10都自带了一个 画图 软件，利用自带的画图软件就可以轻易合成图片了。 准备工作准备两种图片待合成的图片，例如我这里 图片合成步骤 第一步：点击任意一张图片，选择打开方式 – 选择 画图。 第二步：将图片的长和宽做对应的变化，拉伸出更多空白地方用于展示其他图片。 第三步：点击 主页 – 点击粘贴 – 选择 粘贴来源 第四步：选择需要合成的图片，点击打开。 第五步：把两张图片做好对应的位置变化，保存即可。 这样两张图片就轻易合成为一张图片了，如果是多张图需要合并为一张图，重复操作步骤三即可。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"win10","slug":"win10","permalink":"http://www.devcheng.net/tags/win10/"},{"name":"图片合成","slug":"图片合成","permalink":"http://www.devcheng.net/tags/图片合成/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Redis常问面试题整理","slug":"Redis常问面试题整理","date":"2020-03-29T05:40:39.000Z","updated":"2020-03-29T06:16:33.235Z","comments":true,"path":"post/3ffff771.html","link":"","permalink":"http://www.devcheng.net/post/3ffff771.html","excerpt":"","text":"介绍Redis 是一个开源的使用 ANSI C 语言编写、遵守 BSD 协议、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API的非关系型数据库。传统数据库遵循 ACID 规则。而 Nosql（Not Only SQL 的缩写，是对不同于传统的关系型数据库的数据库管理系统的统称） 一般为分布式而分布式一般遵循 CAP 定理 1.Redis支持哪几种数据类型？1.string：最基本的数据类型，二进制安全的字符串，最大512M。2.list：按照添加顺序保持顺序的字符串列表。3.set：无序的字符串集合，不存在重复的元素。4.sorted set：已排序的字符串集合。5.hash：key-value对的一种集合。 另外还有四种特殊的 数据类型1.BloomFilter2.HyperLogLog3.BitMap4.Geo 这几种数据类型的具体介绍。立即了解redis其他的数据类型 : https://developer.51cto.com/art/201911/605731.htm 注意 关于数据类型多说两句： redis里存的都是二进制数据，其实就是字节数组（byte[]），这些字节数据是没有数据类型的，只有把它们按照合理的格式解码后，可以变成一个字符串，整数或对象，此时才具有数据类型。 这一点必须要记住。 所以任何东西只要能转化成字节数组（byte[]）的，都可以存到redis里。管你是字符串、数字、对象、图片、声音、视频、还是文件，只要变成byte数组。 关键字（Keys）是用于标识一段数据的一个字符串 值（Values）是一段任意的字节序列，Redis不会关注它们实质上是什么 关于key key不要太长，尽量不要超过1024字节，这不仅消耗内存，而且会降低查找的效率 key也不要太短，太短的话，key的可读性会降低 在一个项目中，key最好使用统一的命名模式，例如 user:10000:passwd 2.Redis是单进程单线程的吗？Redis是单进程单线程的，Redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销。 3.Redis为什么是单线程的？多线程处理会涉及到锁，而且多线程处理会涉及到线程切换而消耗CPU。因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者网络带宽。单线程无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来解决。 补充额外知识点 ：其它开源软件采用的模型Nginx：多进程单线程模型Memcached：单进程多线程模型 4.Memcache与Redis的区别都有哪些？ Memcache （MC） 看看 MC 的特点：MC 处理请求时使用多线程异步 IO 的方式，可以合理利用 CPU 多核的优势，性能非常优秀；MC 功能简单，使用内存存储数据；MC 的内存结构以及钙化问题我就不细说了，大家可以查看官网了解下；MC 对缓存的数据可以设置失效期，过期后的数据会被清除；失效的策略采用延迟失效，就是当再次使用数据时检查是否失效；当容量存满时，会对缓存中的数据进行剔除，剔除时除了会对过期 key 进行清理，还会按 LRU 策略对数据进行剔除。 另外，使用 MC 有一些限制，这些限制在现在的互联网场景下很致命，成为大家选择Redis、MongoDB的重要原因：key 不能超过 250 个字节；value 不能超过 1M 字节；key 的最大失效时间是 30 天；只支持 K-V 结构，不提供持久化和主从同步功能。 Redis 先简单说一下 Redis 的特点，方便和 MC 比较。 与 MC 不同的是，Redis 采用单线程模式处理请求。这样做的原因有 2 个：一个是因为采用了非阻塞的异步事件处理机制；另一个是缓存数据都是内存操作 IO 时间不会太长，单线程可以避免线程上下文切换产生的代价。 Redis 支持持久化，所以 Redis 不仅仅可以用作缓存，也可以用作 NoSQL 数据库。 相比 MC，Redis 还有一个非常大的优势，就是除了 K-V 之外，还支持多种数据格式，例如 list、set、sorted set、hash 等。 Redis 提供主从同步机制，以及 Cluster 集群部署能力，能够提供高可用服务。 5.什么是Redis数据持久？方式都有哪些，各自的优缺点是什么？1.redis持久化就是把内存的数据写到磁盘中去，防止服务器宕机了内存数据丢失。2.数据持久化的方式有2种： RDB(默认) 和 AOF 。 RDB （redis database） 核心函数rdbSave(生成RDB文件)和rdbLoad（从文件加载内存）两个函数 AOF （append-only file）每当执行服务器(定时)任务或者函数时flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作AOF 写入保存。 存储的内容是 redis通讯协议格式命令的命令文本存储。点击立即了解 —&gt; https://www.cnblogs.com/nele/p/8908298.html WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。 区别：1、AOF 文件比 RDB 更新频率高，优先使用 AOF 还原数据。2、AOF 比 RDB 更安全也更大3、RDB 性能比 AOF 好4、如果两个都配了优先加载AOF 6.说说 Redis 的淘汰策略？Redis提供了6中淘汰策略。 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 使用策略规则：1、如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru2、如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random 7. 什么是缓存穿透，缓存击穿，缓存雪崩？ 缓存穿透描述： 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。 解决方案： 接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截；从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 缓存击穿 描述：缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方案： 设置热点数据永远不过期。加互斥锁，互斥锁参考代码如下： 说明： 1）缓存中有数据，直接走上述代码13行后就返回结果了 2）缓存中没有数据，第1个进入的线程，获取锁并从数据库去取数据，没释放锁之前，其他并行进入的线程会等待100ms，再重新去缓存取数据。这样就防止都去数据库重复取数据，重复往缓存中更新数据情况出现。 3）当然这是简化处理，理论上如果能根据key值加锁就更好了，就是线程A从数据库取key1的数据并不妨碍线程B取key2的数据，上面代码明显做不到这点。 缓存雪崩 描述： 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案： 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。设置热点数据永远不过期。 8. Redis 架构模式有哪些？讲讲各自的特点？ 9. redis 集群方案都有哪些？1.twemproxy，大概概念是，它类似于一个代理方式， 使用时在本需要连接 redis 的地方改为连接 twemproxy， 它会以一个代理的身份接收请求并使用一致性 hash 算法，将请求转接到具体 redis，将结果再返回 twemproxy。缺点： twemproxy 自身单端口实例的压力，使用一致性 hash 后，对 redis 节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。 2.codis，目前用的最多的集群方案，基本和 twemproxy 一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新 hash 节点 3.redis cluster3.0 自带的集群，特点在于他的分布式算法不是一致性 hash，而是 hash 槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。 10. 在Redis中如何保证只存20W的热点数据？先计算出20W数据需要占用数据的空间，然后设置数据淘汰策略为 allkey-lru 回收最少使用策略。 11.Redis支持的Java客户端都有哪些？官方推荐使用哪个？Redisson、Jedis、lettuce等等，官方推荐使用Redisson。 12.Redis和Redisson有什么关系？Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。 13.Jedis与Redisson对比有什么优缺点？Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持； Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。 14.Redis支持事务吗？支持 , 表现为多条命令，要么都执行，要么都不执行。 redis的事务可以分为两步，定义事务和执行事务。使用multi命令开启一个事务，然后把要执行的所有命令都依次排上去。这就定义好了一个事务。此时使用exec命令来执行这个事务，或使用discard命令来放弃这个事务。你可能希望在你的事务开始前，你关心的key不想被别人操作，那么可以使用watch命令来监视这些key，如果开始执行前这些key被其它命令操作了则会取消事务的。也可以使用unwatch命令来取消对这些key的监视。 redis事务具有以下特点：1、如果开始执行事务前出错，则所有命令都不执行2、一旦开始，则保证所有命令一次性按顺序执行完而不被打断3、如果执行过程中遇到错误，会继续执行下去，不会停止的4、对于执行过程中遇到错误，是不会进行回滚的 很显然，这并不是我们通常认为的事务，因为它连原子性都保证不了。保证不了原子性是因为redis不支持回滚，不过它也给出了不支持的理由。 不支持回滚的理由：1、redis认为，失败都是由命令使用不当造成2、redis这样做，是为了保持内部实现简单快速3、redis还认为，回滚并不能解决所有问题因此 , 使用redis事务的不太多 15. Redis分布式锁如何续期？https://zhuanlan.zhihu.com/p/71185118 16.Redis分布式锁如何防止死锁 方法1 ， 编写2个方法一个加锁，一个解锁 12345678910111213141516171819private static final String LOCK_SUCCESS = \"OK\"; private static final String SET_IF_NOT_EXIST = \"NX\"; private static final String SET_WITH_EXPIRE_TIME = \"PX\"; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125; 可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参： 第一个为key，我们使用key来当锁，因为key是唯一的。 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 第五个为time，与第四个参数相呼应，代表key的过期时间。 总的来说，执行上面的set()方法就只会导致两种结果： 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。 已有锁存在，不做任何操作。 解锁代码 12345678910111213141516private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125; 可以看到，我们解锁只需要两行代码就搞定了！第一行代码，我们写了一个简单的Lua脚本代码，没想到这次居然用上了。第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行 Redis常用命令及介绍 字符串：setnx(key,value) 只在键 key 不存在的情况下， 将键 key 的值设置为 value 。key存在,不做任何操作。setex(key,seconds,value) 将key设置及生存时间seconds秒,原值存在覆盖。psetex(key,milliseconds,value) 与setex同样,只是单位是毫秒。getset(key,value) 设置新值并返回旧值,不存在返回nilsetrange(key,offset,value) 从偏移量开始offset开始mset 同时给多个key复制 哈希表(map)：hset(hash field value) 将哈希表 hash 中域 field 的值设置为 valuehmset key field value [field value …] 同时将多个 field-value (域-值)对设置到哈希表 key 中。hget hash field 返回哈希表中给定域的值。hgetall key 返回哈希表 key 中，所有的域和值。 队列(queue):lpush key value [value …] 将一个或多个值 value 插入到列表 key 的表头lpop key 移除并返回列表 key 的头元素,不存在返回nillset key index value 将列表 key 下标为 index 的元素的值设置为 value 。brpop key [key …] timeout 在超时时间内移除列表尾元素，阻塞的。 集合：sadd key member [member …] 将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略sismember key member 如果 member 元素是集合的成员，返回 1 。 如果 member 元素不是集合的成员，或 key 不存在，返回 0 。spop key 移除集合key的随机元素smembers key 返回集合 key 中的所有成员。sdiff key [key …] 返回给定多个集合之间的差集。 有序集合：zadd key score member [[score member] [score member] …] 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。zscore key member 返回有序集 key 中，成员 member 的 score 值。zcount key min max score 值在 min 和 max 之间的成员的数量。zrange key start stop [withscores] 返回有序集 key 中，指定区间内的成员(从小到大)。zrank key member 返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。zrem key member [member …] 移除有序集 key 中的一个或多个成员，不存在的成员将被忽略。 时效性：expire(key,seconds) 为给定 key 设置生存时间，当 key 过期时(生存时间为 0 )，它会被自动删除。expireat( key,timestamp) 设置过期时间戳,expireatcache1355292000# 这个 key 将在 2012.12.12 过期ttl(key) 返回剩余时间persist key 移除key有效期，转换成永久的 数据指令：keys pattern 符合给定模式的 key 列表。阻塞的scan 异步的 有重复","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://www.devcheng.net/tags/redis/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于Spring Boot开发的动漫商城系统源码分享","slug":"基于Spring-Boot开发的动漫商城系统源码分享","date":"2020-03-15T09:24:25.000Z","updated":"2020-09-20T07:10:55.889Z","comments":true,"path":"post/536e3846.html","link":"","permalink":"http://www.devcheng.net/post/536e3846.html","excerpt":"","text":"前言动漫商城项目包括商城前台系统和商城后台管理系统，基于 Spring Boot 2.X 及相关技术栈开发。前台商城系统包含首页门户、商品分类、新品上线、首页轮播、商品推荐、商品搜索、商品展示、购物车、订单结算、支付流程、订单流程(微信支付/支付宝沙箱支付)、个人订单管理、会员中心、帮助中心、公告管理等模块。后台管理系统包含数据面板、轮播图管理、商品管理、订单管理、会员管理、分类管理、系统设置等模块。 开发环境（运行环境）-系统环境：Windows 10-开发工具：IntelliJ IDEA-Java版本：JDK 1.8 项目技术栈 Spring Boot Mybatis Maven 3.X Thymeleaf 前台页面预览 动漫商城首页 商品详情页面 购物车页面 登录页面 后台管理页面预览 轮播图配置 商品管理 会员管理 订单管理 公告管理 联系我们如有需要欢迎私聊我哦！QQ 搜索：792435323联系我！ 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的xxxApplication直接运行吧！ 其它说明白嫖党绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"源代码","slug":"源代码","permalink":"http://www.devcheng.net/tags/源代码/"},{"name":"动漫商城系统","slug":"动漫商城系统","permalink":"http://www.devcheng.net/tags/动漫商城系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"基于Spring Boot+MyBatis+Maven论坛内容管理系统源码(包含毕业论文)","slug":"基于Spring Boot + MyBatis + Maven论坛内容管理系统源码","date":"2020-03-02T15:24:39.000Z","updated":"2021-04-11T06:46:47.492Z","comments":true,"path":"post/be40dded.html","link":"","permalink":"http://www.devcheng.net/post/be40dded.html","excerpt":"","text":"毕设描述xxxForum是一个基于Spring Boot + MyBatis + Maven开发的一个论坛内容管理系统，主要实现了的功能有： 前台页面展示数据、广告展示 内容模块：发帖、评论、帖子分类、分页、回帖统计、访问统计、表单验证 用户模块：权限、资料、头像、邮箱验证 管理：后台管理、统计图表、帖子/分类管理 开发环境（运行环境）windows 7 , jdk 1.8 项目采用技术后端 Spring Boot 1.5.5 Spring Security 4 Mybatis(mybatis-spring-boot-starter 1.3.1) Maven 3.X 前端 Thymeleaf Bootstrap jQuery Chart.js bootstrap-select daterangepicker 数据库文件在项目文件里面 项目截图 登录地址http://localhost:8080/ 登录用户名和密码 admin / admin 项目演示视频链接: https://pan.baidu.com/s/1ZvwWdYYGlByPbbRuhacLAQ 提取码: b3wv 联系我们如有需要源码可以通过 QQ 搜索：792435323联系我！ 注意事项 头像如何配置？在电脑选一个盘，新建一个文件夹 例如：在C盘新建一个avatar文件夹，里面存放你的头像图片。找到 application.properties 配置文件1234# ==============================# avator location# ==============================resource.staticResourceLocation=C:/avatar/ 写好配置，找到 StaticResourceConfig 类12345@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; //这里也要和之前的对应起来 registry.addResourceHandler(&quot;/avatar/**&quot;).addResourceLocations(&quot;file:C:/avatar/&quot;);&#125; 数据库里面和这对应就可以了！ 其它说明白嫖党绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"论坛内容管理系统","slug":"论坛内容管理系统","permalink":"http://www.devcheng.net/tags/论坛内容管理系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"Java8日期和时间段的计算","slug":"Java8日期和时间段的计算","date":"2020-02-25T05:53:57.000Z","updated":"2020-03-29T05:42:08.674Z","comments":true,"path":"post/55e45d5a.html","link":"","permalink":"http://www.devcheng.net/post/55e45d5a.html","excerpt":"","text":"前言在Java8之前，计算日期相差多少天一般的做法都是借助SimpleDateFormat对两个日期格式化之后在进行比较。在编写代码的过程中，计算一个方法具体耗时多少分钟，执行了多少秒等需求，一般也是借助System.currentTimeMillis()。 12345678long start = System.currentTimeMillis();//业务逻辑//...long end = System.currentTimeMillis();System.out.println(\"此处消耗了：\"+(end-start)); 下面看看在Java8中如何计算日期差以及时间差。 Java8中计算日期差比如日期A是1992-08-01 到 今天（2020-02-25）一共相差多少天： 代码1 如下： 12345678910111213public class Demo &#123; public static void main(String[] args) &#123; LocalDate startDate = LocalDate.of(1992, Month.AUGUST, 1); System.out.println(\"日期A : \" + startDate); LocalDate endDate = LocalDate.of(2020, Month.FEBRUARY, 25); System.out.println(\"日期B : \" + endDate); long daysDiff = ChronoUnit.DAYS.between(startDate, endDate); System.out.println(\"两个日期之间的差在天数 : \" + daysDiff); &#125;&#125; 输出的结果： 1234日期A : 1992-08-01日期B : 2020-02-25两个日期之间的差在天数 : 10069 代码2 如下： 1234567public class Demo &#123; public static void main(String[] args) &#123; Period period = Period.between(LocalDate.of(1992, 8, 1), LocalDate.of(2020, 2, 25)); System.out.println(\"两个日期之间的差 : \" + period.getYears()+\"年，\"+period.getMonths()+\"月，\"+period.getDays()+\"天\"); &#125;&#125; 输出的结果： 1两个日期之间的差 : 27年，6月，24天 ChronoUnit 类可用于在单个时间单位内测量一段时间，例如天数或秒。 Period类 主要用方法getYears()，getMonths()和getDays()来计算。 Java8中计算时间差列如文中说的计算某个方法运行耗时了多长，具体代码如下： 123456789101112131415public class Demo &#123; public static void main(String[] args) &#123; Instant start = Instant.now(); // 假设是业务逻辑部分代码 for (int i = 0; i &lt;100000 ; i++) &#123; System.out.println(\"---\"+i); &#125; Instant end = Instant.now(); System.out.println(\"此处消耗了（s）: \" + Duration.between(start, end).getSeconds()); &#125;&#125; 输出的结果： 12345678--- ...---99994---99995---99996---99997---99998---99999此处消耗了（s）: 1 Duration 类提供了使用基于时间的值（如秒，纳秒）测量时间量的方法。 关于三个类更多的说明，可自行参考官方API。 https://docs.oracle.com/javase/8/docs/api/index.html (官方API) http://www.matools.com/api/java8 (中文版API)","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://www.devcheng.net/tags/Java8/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"org.springframework.amqp.support.converter.MessageConversionExcep异常","slug":"org-springframework-amqp-support-converter-MessageConversionExcep异常","date":"2020-02-22T07:18:35.000Z","updated":"2020-02-22T07:20:32.395Z","comments":true,"path":"post/128dfa7.html","link":"","permalink":"http://www.devcheng.net/post/128dfa7.html","excerpt":"","text":"背景最近，在用Spring Boot+rabbitMQ整合的过程中，测试生产者发送单条字符串消息到消费者消费这个过程没出现任何问题。 可是在实际应用中，往往在生产中不可能只生产字符串的，更多时候需要生产一个对象发送到队列，消费者从队列里面获取一个对象进行消费。 准备工作先定义一个对象12345678910111213141516171819202122232425public class Order implements Serializable &#123; private String id; private String name; public Order() &#123; &#125; public Order(String id, String name) &#123; super(); this.id = id; this.name = name; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 从代码中，可以发现定义对象的时候已经做了序列化了。 生产者代码:12345678//发送消息方法调用: 构建自定义对象消息public void sendOrder(Order order) throws Exception &#123; rabbitTemplate.setConfirmCallback(confirmCallback); rabbitTemplate.setReturnCallback(returnCallback); //id + 时间戳 全局唯一 CorrelationData correlationData = new CorrelationData(\"0987654321\"); rabbitTemplate.convertAndSend(\"exchange-2\", \"springboot.def\", order, correlationData);&#125; 测试生产者发送代码：1234567@Testpublic void testSender2() throws Exception &#123; Order order = new Order(\"001\", \"第一个订单\"); rabbitSender.sendOrder(order); //防止资源提前关闭，ConfirmCallback异步回调失败 Thread.sleep(2000);&#125; 消费者代码:1234567891011121314151617181920RabbitListener(bindings = @QueueBinding( value = @Queue(value = \"$&#123;spring.rabbitmq.listener.order.queue.name&#125;\", durable=\"$&#123;spring.rabbitmq.listener.order.queue.durable&#125;\"), exchange = @Exchange(value = \"$&#123;spring.rabbitmq.listener.order.exchange.name&#125;\", durable=\"$&#123;spring.rabbitmq.listener.order.exchange.durable&#125;\", type= \"$&#123;spring.rabbitmq.listener.order.exchange.type&#125;\", ignoreDeclarationExceptions = \"$&#123;spring.rabbitmq.listener.order.exchange.ignoreDeclarationExceptions&#125;\"), key = \"$&#123;spring.rabbitmq.listener.order.key&#125;\" ) ) @RabbitHandler public void onOrderMessage(@Payload Order order, Channel channel, @Headers Map&lt;String, Object&gt; headers) throws Exception &#123; System.err.println(\"--------------------------------------\"); System.err.println(\"消费端order: \" + order.getId()); Long deliveryTag = (Long)headers.get(AmqpHeaders.DELIVERY_TAG); //手工ACK channel.basicAck(deliveryTag, false); &#125; 当生产者有数据发送到队列的时候，消费者这端代码报了一个异常。1234567891011121314151617181920212223org.springframework.amqp.rabbit.listener.exception.ListenerExecutionFailedException: Listener method could not be invoked with the incoming messageEndpoint handler details:Method [public void com.rabbit.producer.RabbitProducer.receiver.OrderRecevier.onOrderMessage(com.rabbit.producer.RabbitProducer.entity.Order,com.rabbitmq.client.Channel,java.util.Map&lt;java.lang.String, java.lang.Object&gt;) throws java.lang.Exception]Bean [com.rabbit.producer.RabbitProducer.receiver.OrderRecevier@600b7b3d] at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:185) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:120) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1414) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1337) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1324) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1303) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:817) [spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:801) [spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$700(SimpleMessageListenerContainer.java:77) [spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1042) [spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.rabbit.Springboot4RabbitMQ.entity.Order] to [com.rabbit.producer.RabbitProducer.entity.Order] for GenericMessage [payload=Order [id=RabbitMQTestId0002, name=HelloWorld, messageId=1538919928275$0836e0e7-4976-457e-92fb-44b937255855], headers=&#123;amqp_receivedDeliveryMode=PERSISTENT, amqp_receivedRoutingKey=order.ABC, amqp_receivedExchange=order-exchange, amqp_deliveryTag=1, amqp_consumerQueue=order-queue, amqp_redelivered=false, id=0ffe4dcd-048f-f274-bca9-5550f9ecebb1, amqp_consumerTag=amq.ctag-82Oo3kl1I138E2pvVRsczA, contentType=application/x-java-serialized-object, timestamp=1538919929083&#125;] at org.springframework.messaging.handler.annotation.support.PayloadArgumentResolver.resolveArgument(PayloadArgumentResolver.java:144) ~[spring-messaging-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:116) ~[spring-messaging-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:137) ~[spring-messaging-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:109) ~[spring-messaging-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:51) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:182) ~[spring-rabbit-2.0.5.RELEASE.jar:2.0.5.RELEASE] ... 10 common frames omitted 从异常信息中可以看到是消费者对消息反序列化的时候失败了。虽然两个项目中的Order类是完全一样的，但在进行反序列化的时候还是失败了! 于是找了一番解决方案·· 第一种：消费者引用生产者项目中的消息体即Order.java 在消费者项目上【右键】-&gt;【Bulid Path】-&gt;【Configure Build Path】-&gt;【Projects】-&gt;【Add】 选择生产者项目，然后消费者项目就可以引用生产者项目中类，这样完全保证了两个项目中JavaBean是一致的，所以能解决反序列失败的问题。 第二种：生产者在发送消息前将消息体转换为JSONObject，消费者以JSONObject接收消息，再转换为对应的实体类。 生产者的代码12345678//发送消息方法调用: 构建自定义对象消息public void sendOrder(Order order) throws Exception &#123; rabbitTemplate.setConfirmCallback(confirmCallback); rabbitTemplate.setReturnCallback(returnCallback); //id + 时间戳 全局唯一 CorrelationData correlationData = new CorrelationData(\"0987654321\"); rabbitTemplate.convertAndSend(\"exchange-2\", \"springboot.def\", FastJsonConvertUtil.toJsonObject(order), correlationData);&#125; 消费者的代码1234567891011@RabbitListener(bindings = @QueueBinding(value = @Queue(value = \"$&#123;spring.rabbitmq.listener.order.queue.name&#125;\", durable = \"$&#123;spring.rabbitmq.listener.order.queue.durable&#125;\"), exchange = @Exchange(value = \"$&#123;spring.rabbitmq.listener.order.exchange.name&#125;\", durable = \"$&#123;spring.rabbitmq.listener.order.exchange.durable&#125;\", type = \"$&#123;spring.rabbitmq.listener.order.exchange.type&#125;\", ignoreDeclarationExceptions = \"$&#123;spring.rabbitmq.listener.order.exchange.ignoreDeclarationeExceptions&#125;\"), key = \"$&#123;spring.rabbitmq.listener.order.key&#125;\")) public void onOrderMessage(@Payload JSONObject object, Channel channel, @Headers Map&lt;String, Object&gt; headers) throws Exception &#123; System.err.println(\"----------------------------------\"); Order order = JsonConvertUtils.convertJSONToObject(object); System.err.println(\"消费端Order: \" + order.toString()); Long deliveryTag = (Long)headers.get(AmqpHeaders.DELIVERY_TAG); channel.basicAck(deliveryTag, false); &#125;","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"http://www.devcheng.net/tags/rabbitMQ/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于Spring Boot后台管理系统","slug":"基于Spring-Boot后台管理系统","date":"2020-02-15T10:43:04.000Z","updated":"2020-09-20T07:11:45.607Z","comments":true,"path":"post/fb5a8cfd.html","link":"","permalink":"http://www.devcheng.net/post/fb5a8cfd.html","excerpt":"","text":"叨叨叨spring boot 后台管理系统，可以让你接触到的技术栈有以下： spring boot shiro druid maven … 数据库用的是 mysql，前端使用的是 thymeleaf模板引擎。开发工具：IntelliJ IDEA ，JDK 1.8 现在已经实现的功能点有： 登录 / 退出 用户管理 角色管理 权限管理 基本上学习用户角色权限，作为入门就足够了哦！如果有其他的想法，你可以下载这个代码根据自己的需求加上你自己的需求即可。 接着看一下项目截图： 登录页面 功能1 功能2 联系我们如有需要源码可以通过 QQ 搜索：792435323联系我！ 如何获取方式一：将本博客网址 www.devcheng.net 发送到任意2个技术群，截图发我即可获取源码。 方式二：通过本文打赏也可获取源码。 其它说明白嫖党绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://www.devcheng.net/tags/spring-boot/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"基于Spring Boot开发学生成绩管理系统","slug":"基于Spring Boot开发学生成绩管理系统","date":"2020-01-06T09:09:12.000Z","updated":"2020-09-20T07:12:51.339Z","comments":true,"path":"post/d01dd317.html","link":"","permalink":"http://www.devcheng.net/post/d01dd317.html","excerpt":"","text":"前言本项目为学生成绩管理系统，可以当作毕业设计，也可以成为Spirng Boot初学者的学习代码！ 系统描述学生成绩管理系统提供了三种角色：学生，老师，网站管理员。主要实现的功能如下： 登录 &amp; 安全退出 学生信息管理 班级信息管理 教师信息管理 课程信息管理 选课信息管理 考勤信息管理 请假信息管理 成绩信息管理 系统管理 开发环境（运行环境）-系统环境：Windows 10-开发工具：IntelliJ IDEA-Java版本：JDK 1.8 项目技术栈 Spring Boot 2.0.2 Mybatis(mybatis-spring-boot-starter 1.1.1) Maven 3.X Apache poi EasyUI Thymeleaf 数据库文件 db_studentmanager.sql 登录地址http://localhost:8888/ 不同角色的账号详细参考数据库学生，老师，管理员的密码均为：123456 项目截图 项目运行截图以下截图仅仅展示部分功能，上文罗列的功能均已实现！ 联系我们如有需要源码可以通过 QQ 搜索：792435323联系我！ 注意事项获取代码之后，使用IDEA导入本项目前，请确保你本地环境是已经含有代码所需要运行环境的条件了。 接着找到对应的sql文件，将其导入到你本地的数据库即可。 最后修改项目中配置文件中的数据库对应的信息，确认修改完毕，找到对应的xxxApplication直接运行吧！ 其它说明白嫖党绕道！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.devcheng.net/tags/SpringBoot/"},{"name":"源代码","slug":"源代码","permalink":"http://www.devcheng.net/tags/源代码/"},{"name":"学生成绩管理系统","slug":"学生成绩管理系统","permalink":"http://www.devcheng.net/tags/学生成绩管理系统/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"adb 无线连接小米手机(免ROOT)","slug":"adb-无线连接小米手机-免ROOT","date":"2019-12-28T11:43:54.000Z","updated":"2020-01-04T03:56:11.522Z","comments":true,"path":"post/9e1d1814.html","link":"","permalink":"http://www.devcheng.net/post/9e1d1814.html","excerpt":"","text":"前言adb本身提供了网络调试的功能，即使不用USB数据线连上Android手机的情况下，也可以使用WiFi连接add进行调试。详细的作法如下： 解决方法 开启USB调试 1.打开手机设置，点击“我的设备”，选择“全部参数” 2.连续点击MIUI版本几次，返回到设置主界面，点击“更多设置” 3.点击“开发者选项”，打开“开启开发者选项”和“USB调试” 开启USB调试之后，确保电脑和手机都是使用的是同一个网络，接着查看手机的IP地址。在手机屏幕上找到设置的图标，然后在打开的小米手机设置页面，点击WLAN菜单项,接着在打开的网络设置页面中，点击当前连接网络右侧的更多按钮,然后在打开的网络详情页面中，我们可以看到当前手机的IP地址了。 adb无线连接手机第一步：使用命令 adb tcpip 5555 1adb tcpip 5555 成功后,把数据线拔掉，然后重新连接USB数据线。 第二步： 使用命令 adb connect ip (这里的ip就是刚刚查看的手机IP地址) 1adb connect 192.168.1.166 配置完成！ 说明其他手机可以借鉴这个方法，不同手机可能会有不同的解决方法，如果更好的解决方法，请留言告知！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"adb","slug":"adb","permalink":"http://www.devcheng.net/tags/adb/"},{"name":"无线连接小米手机","slug":"无线连接小米手机","permalink":"http://www.devcheng.net/tags/无线连接小米手机/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Java+adb命令实现自动刷视频脚本","slug":"Java-adb命令实现自动刷视频脚本","date":"2019-12-15T11:34:42.000Z","updated":"2020-01-04T04:00:33.945Z","comments":true,"path":"post/58251880.html","link":"","permalink":"http://www.devcheng.net/post/58251880.html","excerpt":"","text":"前言最近，看身边的朋友很喜欢看某手视频，某音视频。边看还能赚点点零花钱，最开始的时候也遇到过很多类似的APP，比如有一些看新闻奖励金币，然后金币变成人民币到达多少金额之后可以提现，一般人都是喜欢自己去手把手的去刷，今天我们就用java加adb写一个程序出来实现自动刷视频。 准备工作在电脑上下载安装adb，手机开启开发者模式，记得把 USB调试 也打开。 点击 ADB的安装与使用 传送门 adb安装完成之后，打开cmd 窗口输入命令 1adb version 接着，用数据线把手机连接上电脑即可。输入命令 1adb devices 如果一切正常这里会显示你的devices的设备号。 如果你按照以上的步骤还没折腾出来你的devices的设备号，请参考以下链接 ⬇⬇⬇ 点击 adb devices找不到设备？设备VID缺失解决方案 传送门 接着在手机上安装一个APP，在这里我就下载了一个 某手极速版。 编写程序编写程序之前，我们到底要怎么去实现呢？实现原理：利用adb截图上传到电脑，得到截图使用adb自带的命令模拟现实中观看视频的滑动。 截图代码 1234567891011121314151617181920private static boolean screenshot() &#123; try &#123; Runtime.getRuntime() .exec(\"adb shell /system/bin/screencap -p /sdcard/screenshot.png\"); Thread.sleep(1000); // 上传手机截图到电脑 Runtime.getRuntime() .exec(\"adb pull /sdcard/screenshot.png C:/Users/Administrator/Downloads/screenshot.png\"); System.out.println(\"=============== Get screenshot success ===============\"); &#125; catch (IOException e) &#123; e.printStackTrace(); return false; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); return false; &#125; return true; &#125; 模拟向上滑动代码 1234567891011private static void wipeUp()&#123; try &#123; Runtime.getRuntime() .exec(\"adb shell input swipe 540 480 540 100 \"); int i = (int)(15000+Math.random()*(30000-10000)); Thread.sleep(i); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 核心代码都已经贴出来了，在模拟向上滑动代码中，需要注意一点 12int i = (int)(15000+Math.random()*(30000-10000));Thread.sleep(i); 这里为什么要做成随机数的原因就是为了防止被检测。这个地方的睡眠时间大家可以根据不同的应用更改！ 接着就写一个main方法就完成了！ 以上的代码适用于各种刷视频得金币的APP，万变不离其宗！ 加入我们群如果有需要，欢迎可以加入我们的QQ群！（QQ搜索 816175200，加入我们的QQ群吧！）有任何问题，也可以加入我们的QQ群，欢迎交（che）流（dan）！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ADB","slug":"ADB","permalink":"http://www.devcheng.net/tags/ADB/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"centos7下安装fastDFS","slug":"centos7下安装fastDFS","date":"2019-10-27T08:16:09.000Z","updated":"2020-01-04T03:59:11.140Z","comments":true,"path":"post/8720f09e.html","link":"","permalink":"http://www.devcheng.net/post/8720f09e.html","excerpt":"","text":"准备工作环境 ： centos7 下载fastDFS123wget https://github.com/happyfish100/libfastcommon/archive/V1.0.7.tar.gzwget http://jaist.dl.sourceforge.net/project/fastdfs/FastDFS%20Nginx%20Module%20Source%20Code/fastdfs-nginx-module_v1.16.tar.gzwget https://github.com/happyfish100/fastdfs/archive/V5.05.tar.gz 下载完成之后可以更改tar包的名字，更改完成之后如下 下载nginx1http://nginx.org/en/download.html 安装安装libevent1yum -y install libevent 接着 找到 fastDFS 目录下的 libfastcomm-1.0.7.tar.gz 对其解压1tar -zxvf libfastcommon-1.0.7.tar.gz 解压完成之后,进入解压后的文件1cd libfastcommon-1.0.7/ 查看一下里面有什么文件 接着 运行make.sh 进行编译1./make.sh 等待编译完成，然后对其安装，执行如下命令1./make.sh install 安装完成之后，切换到 usr/lib64 目录1cd /usr/lib64/ 执行如下命令 1ll libfast* 找到lbfastcommon.so 这个文件，需要将它复制到 usr/lib 目录下执行命令1cp libfastcommon.so /usr/lib/ 安装 tracker切换到 fastdfs-5.05.tar.gz 所在的目录 解压 fastdfs-5.05.tar.gz1tar -zxvf fastdfs-5.05.tar.gz 解压完成之后，切换到目录里面进行编译执行命令1./make.sh 等编译完成之后，执行安装命令1./make.sh install 安装完成之后，有一部分的配置文件会在 /usr/bin/ 目录下，接着切换到 /usr/bin/ 目录进行查看还有一部分配置文件存在于 /etc/fdfs/接着切换到 fastdfs-5.05/conf/ 目录1cd /home/tar/fastDFS/fastdfs-5.05/conf/ 需要把里面的配置文件复制到/etc/fdfs/ 目录切换到 /etc/fdfs/ 进行查看 修改配置文件 tracker.conf1vim tracker.conf 修改了 base_path,然后退出保存。 退出之后，在根目录下创建刚刚修改的base_path 里面定义的目录，命令如下1mkdir /fastdfs/tracker -p 查看是否创建成功在 fastdfs 下继续创建两个文件夹，后续会使用到的12mkdir storagemkdir client 做完这一步操作之后，回到 /usr/bin/ 目录 在这里找到fdfs_trackerd文件，而这个文件就是用来启动tracker的文件。执行启动命令1fdfs_trackerd /etc/fdfs/tracker.conf 假如你的tracker.conf 配置文件发生了变化，那么至需要在这个命令后面加一个restart 即可1fdfs_trackerd /etc/fdfs/tracker.conf restart 到此为止，fastDFS中的 tracker服务 已经OK了。 安装storage切换目录到 /etc/fdfs/ 上面我们已经修改了tracker.conf,接着找到storage.conf文件 1234group_name=group1 // 组织名，改成你想要的即可store_path0=/home/yuqing/fastdfs//图片存储路径tracker_server=192.168.209.121:22122//IP配置为你当前的服务器ip，端口是默认的可不做修改base_path=/fastdfs/storage // 这个目录路径在前面已经创建过的，在这里就直接写这个即可 这个文件就需要该这几个配置项，改为就直接保存退出。切换到 /usr/bin/目录可以用来启动 storage 服务 找到 fdfs_storaged执行命令1fdfs_storaged /etc/fdfs/storage.conf 如果storage.conf 有改动，可以重启storage服务就直接在上面的命令后面加一个 restart1fdfs_storaged /etc/fdfs/storage.conf restart 启动完成之后可以查看一下1ps aux | grep storage 到此为止，fastDFS中的 storage服务也已经OK了。 以上 storage服务和tracker服务都启动了，接着做个小测试。在做这测之前，还需要几件事 配置client首先切换到 /etc/fdfs/ 目录 修改 client.conf 配置文件12base_path=/fastdfs/client //这个目录也是之前已经创建好了的tracker_server=192.168.1.10:22122 // IP修改为你的服务器IP 端口默认的可不做修改 修改完成之后，退出保存 测试下面就可以做测试了。 首先还是要切换目录到 /usr/bin/ 找到 fdfs_test 这个服务就可以做相应的测试，记得事先准备一张测试图片。我这里事先准备了一张图片在根目录下切换到 home 目录查看 执行命令1/usr/bin/fdfs_test /etc/fdfs/client.conf upload zhu.png 看见如下就代表上传成功了 说明：上图可以看见我们曾配置的 组织名 group_name还有文件名，以及访问图片的URL。 到这一步虽然有了这个图片的url 但是我们还是访问不到这个图片的，因为我们并没有配置对应的web服务器，接下来会配置nginx 。 思考一个问题，由上面的图片已经上传成功了，那这图片到底存储在哪里了呢？这个取决于你的配置文件里面的配置，我这里是在这个路径下1/fastdfs/storage/data/00/00 异常情况如果上传失败一般都是你的配置文件修改的有误，这里附上一个常见的错误场景 解决方法，参考这个链接https://blog.csdn.net/egbertasd/article/details/90762478 修改完配置文件，记得重启对应的服务！ 配置nginx切换到目录 /home/tar/fastDFS/找到对应的 fastdfs-nginx-module_v1.16.tar.gz对其解压1tar -zxvf fastdfs-nginx-module_v1.16.tar.gz 解压完成之后 进入到 fastdfs-nginx-module在进入到 里面的 src修改 config 文件 删掉标红的三个 local ，因为和我们配置的路径不一致。 修改完成之后，保存退出。操作完以上步骤之后，切换目录到 nginx 的tar包下 在安装nginx 之前要先安装必要的一些库12341. yum install gcc-c++2. yum install pcre prce-devel3. yum install zlib zili-devel4. yum install openssl openssl-devel 接着解压 nginx1tar -zxvf nginx-1.12.2.tar.gz 进入 nginx 接下来需要运行一段配置文件12345678910111213./configure \\--prefix=/usr/local/nginx \\--pid-path=/var/run/nginx/nginx.pid \\--lock-path=/var/lock/nginx.lock \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--with-http_gzip_static_module \\--http-client-body-temp-path=/var/temp/nginx/client \\--http-proxy-temp-path=/var/temp/nginx/proxy \\--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\--http-scgi-temp-path=/var/temp/nginx/scgi \\--add-module=(这里填写你的fastdfs-ngix-module的路径) 复制在 nginx 下回车就可以运行 接着make 编译一下1make 编译完成之后，执行安装命令1make install 安装完成之后，在 /usr/local/ 目录下就会存在一个nginx文件夹 做到这一步，还需要一个fast和nginx的 “桥梁配置文件” 切换目录到1cd /home/tar/fastDFS/fastdfs-nginx-module/src 找到 mod_fastdfs.conf 文件把它复制到 /etc/fdfs/1cp mod_fastdfs.conf /etc/fdfs/ 进入 /etc/fdfs/ 目录进行查看并且使用 vim 修改这个文件12# the base path to store log filesbase_path=/fastdfs/tmp 修改完成保存，然后在 fastdfs 下面创建 tmp 文件夹 在此 进入到 /etc/fdfs/ 目录继续修改 mod_fastdfs.conf 文件123tracker_server=192.168.1.10:22122 //配置你的服务器ipgroup_name=yicheng // 和之前配置的组织名要一致url_have_group_name = true // 默认为关闭的 这里修改为true 修改完成之后保存退出。 接着到 /usr/local/nginx/conf 目录修改nginx.conf文件添加以下内容在 nginx.conf 文件123456789server&#123; listen 88; server_name 192.168.1.10; location /yicheng/M00 &#123; ngx_fastdfs_module; &#125; &#125; 接着可以进入sbin目录进行nginx的启动了执行命令先检查一下1./nginx -t 在这里提示 /var/temp/nginx/ 目录不存在执行以下命令1mkdir /var/temp/nginx -p 再次执行 ./nginx -t 发现没问题了，就可以直接启动nginx 了，执行命令1./nginx 打开浏览器输入IP访问试试说明 nginx 已经成功启动了！！！ 接着找一下开始上传成功的那个图片路径，复制到浏览器中访问一下。突然发现还是访问不了这张图片，因为现在我们使用的是nginx 的服务器，上文中有一个fastDFS和nginx 的桥梁配置文件，里面没有配置存放路径。进入 /etc/fdfs/ 目录，找到 mod_fastdfs.conf 文件，修改它1store_path0=/fastdfs/storage 保存退出。 接着重启 tracker ， storage重启 nginx 在浏览器刷新刚刚的url 进行查看！ 到此，全文结束！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"centos7","slug":"centos7","permalink":"http://www.devcheng.net/tags/centos7/"},{"name":"fastDFS","slug":"fastDFS","permalink":"http://www.devcheng.net/tags/fastDFS/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"如何在 Spring boot中使用 @Value注入map、List，yaml格式","slug":"如何在-Spring-boot中使用-Value注入map、List，yaml格式","date":"2019-09-03T13:24:50.000Z","updated":"2020-01-04T04:04:32.452Z","comments":true,"path":"post/dc31a844.html","link":"","permalink":"http://www.devcheng.net/post/dc31a844.html","excerpt":"","text":"前言最近项目开发中，需要做到项目的主备切换，所以就会有多个ip加端口,在配置文件里面可以配置成这样。 12ip1=172.168.34.161:2001ip2=172.168.34.171:3001 那怎么把这2行配置成一个map呢? @value注入map1maps: &quot;&#123;ip1: &apos;172.168.34.161:2001&apos;, ip2: &apos;172.168.34.171:3001&apos;&#125;&quot; 然后在你的service里面就可以用12@Value(&quot;#&#123;$&#123;maps&#125;&#125;&quot;) private Map&lt;String,String&gt; maps; 但是有一点需要注意的是：在上面map中，一定要用””把map所对应的value包起来，要不然解析会失败，导致不能转成 Map&lt;String,String&gt;。 @value注入list还有一个问题在配置文件中，很少有人使用配置文件配置一个list，如以下：1list: ip1,ip2,ip3 对应在service里面则可以这样写12@Value(&quot;#&#123;&apos;$&#123;list&#125;&apos;.split(&apos;,&apos;)&#125;&quot;)private List&lt;String&gt; list; 备忘，特此记录！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Spring boot","slug":"Spring-boot","permalink":"http://www.devcheng.net/tags/Spring-boot/"},{"name":"value","slug":"value","permalink":"http://www.devcheng.net/tags/value/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"浅谈ByteBuffer和ByteBuf的区别","slug":"浅谈ByteBuffer和ByteBuf的区别","date":"2019-07-27T08:35:46.000Z","updated":"2020-01-04T04:03:56.456Z","comments":true,"path":"post/b3bd5165.html","link":"","permalink":"http://www.devcheng.net/post/b3bd5165.html","excerpt":"","text":"写在前面最近这段时间接触到了netty,在做消息的编解码的过程中认识了bytebuf初次见面尚未深入认识，看见bytebuf的第一眼让我一下就联想到了bytebuffer这‘家伙’。 进过一段时间的使用，今天写一篇博客总结总结！ ByteBufferbytebuffer 是Java NIO里面提供的字节容器。有一个指针用于处理读写操作，每次读写的时候都需要调用flip()或是clear()方法，不然将会报异常。 部分源码：123456789101112131415161718192021222324252627282930* * * @author Mark Reinhold * @author JSR-51 Expert Group * @since 1.4 */public abstract class ByteBuffer extends Buffer implements Comparable&lt;ByteBuffer&gt;&#123; // These fields are declared here rather than in Heap-X-Buffer in order to // reduce the number of virtual method invocations needed to access these // values, which is especially costly when coding small buffers. // final byte[] hb; // Non-null only for heap buffers final int offset; boolean isReadOnly; // Valid only for heap buffers // Creates a new buffer with the given mark, position, limit, capacity, // backing array, and array offset // ByteBuffer(int mark, int pos, int lim, int cap, // package-private byte[] hb, int offset) &#123; super(mark, pos, lim, cap); this.hb = hb; this.offset = offset; &#125; 1234567891011121314public abstract class Buffer &#123; /** * The characteristics of Spliterators that traverse and split elements * maintained in Buffers. */ static final int SPLITERATOR_CHARACTERISTICS = Spliterator.SIZED | Spliterator.SUBSIZED | Spliterator.ORDERED; // Invariants: mark &lt;= position &lt;= limit &lt;= capacity private int mark = -1; private int position = 0; private int limit; private int capacity; 属性 描述 mark 调用mark()方法的话，mark值将存储当前position的值，等下次调用reset()方法时，会设定position的值为之前的标记值 position 用来表示bytes的容量，那么可以想像capacity就等于bytes.size()，此值在初始化bytes后，是不可变的 limit 用来表示bytes实际装了多少数据，可以容易想像得到limit &lt;= capacity，此值是可灵活变动的 capacity 用来表示在哪个位置开始往bytes写数据或是读数据，此值是可灵活变动的 他们之间的关系：mark &lt;= position &lt;= limit &lt;= capacity 创建一个bytebufferByteBuffer bf = ByteBuffer.allocate(10); position,limit和capacity图解如下： tips:创建一个bytebuffer有两个方法12public static ByteBuffer allocate(int capacity) public static ByteBuffer allocateDirect(int capacity) allocate和allocateDirect的区别，可以参考以下博文 https://blog.51cto.com/xingej/1967948https://www.jianshu.com/p/03054776bc60 写入数据到bytebufferbf.put((byte)’H’).put((byte)’e’).put((byte)’l’).put((byte)’l’).put((byte)’o’) 在操作bytebuffer的时候，每次往里面写入一个byte,position则会后移一位。 使用flip() 刷新缓冲区为 读模式bf.flip() bytebuffer有两种模式，分别是写模式和读模式，这两种模式通过使用flip方法进行模式。 如上将缓冲区切换为读模式，则position变成了初值位置0，而limit变成了写模式下position位置。 读取数据bf.get() 调用get()获取缓冲区中的一个byte。 清除缓冲区bf.clear() tips: 这个方法简单理解就是复位（Reset） 但不会清除数据（position=0, limit=capacity） ByteBufbytebuf 是Netty里的封装的数据缓存区，区别于bytebuffer里需要position、limit、capacity等属性来操作bytebuffer数据读写，而 bytebuf 里面则是通过 两个指针协助缓存区的读写操作，分别为 readIndex 和 writerIndex 。 在创建bytebuf 的时候，readIndex 和 writerIndex 的值都是0，但随着有数据被写入 writerIndex会增加，读取数据的时候 readIndex也会增加， 但是readIndex 不会超过 writerIndex。 创建一个bytebuf ByteBuf bf= Unpooled.buffer(10,100) write：写入N个字节之后ByteBuf read：读取M个字节后(M&lt;N) ByteBuffer和ByteBuf的区别 Netty的ByteBuf采用了读写索引分离的策略（readerIndex与writerIndex），一个初始化（里面尚未有任何数据）的ByteBuf的readerIndex与writerIndex值都为0 当读索引与写索引处于同一个位置时，如果继续读取，那么就会抛出IndexOutOfBoundsException。 ByteBuffer只有一个标识位置的指针，读写的时候需要手动的调用flip()和rewind()等，否则很容易导致程序处理失败。而ByteBuf有两个标识位置的指针，一个写writerIndex，一个读readerIndex,读写的时候不需要调用额外的方法。 ByteBuffer必须自己长度固定，一旦分配完成，它的容量不能动态扩展和收缩；ByteBuf默认容器大小为256，支持动态扩容，在允许的最大扩容范围内（Integer.MAX_VALUE）。 NIO的SocketChannel进行网络读写时，操作的对象是JDK标准的java.nio.byteBuffer。由于Netty使用统一的ByteBuf替代JDK原生的java.nio.ByteBuffer，所以ByteBuf中定义了ByteBuffer nioBuffer()方法将ByteBuf转换成ByteBuffer。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ByteBuffer","slug":"ByteBuffer","permalink":"http://www.devcheng.net/tags/ByteBuffer/"},{"name":"ByteBuf","slug":"ByteBuf","permalink":"http://www.devcheng.net/tags/ByteBuf/"},{"name":"Java NIO","slug":"Java-NIO","permalink":"http://www.devcheng.net/tags/Java-NIO/"},{"name":"Netty","slug":"Netty","permalink":"http://www.devcheng.net/tags/Netty/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"认识Java RandomAccessFile类","slug":"认识Java-RandomAccessFile类","date":"2019-07-26T12:31:19.000Z","updated":"2020-01-04T04:04:15.200Z","comments":true,"path":"post/ab99a0bd.html","link":"","permalink":"http://www.devcheng.net/post/ab99a0bd.html","excerpt":"","text":"介绍RandomAccessFile既可以读取文件内容，也可以向文件输出数据。同时，RandomAccessFile支持“随机访问”的方式，程序快可以直接跳转到文件的任意地方来读写数据。 由于RandomAccessFile可以自由访问文件的任意位置，所以如果需要访问文件的部分内容，而不是把文件从头读到尾，使用RandomAccessFile将是更好的选择。 与OutputStream、Writer等输出流不同的是，RandomAccessFile允许自由定义文件记录指针，RandomAccessFile可以不从开始的地方开始输出，因此RandomAccessFile可以向已存在的文件后追加内容。如果程序需要向已存在的文件后追加内容，则应该使用RandomAccessFile。 一个构造函数RandomAccessFile类有两个构造函数，其实这两个构造函数基本相同，只不过是指定文件的形式不同 一个需要使用String参数来指定文件名 一个使用File参数来指定文件本身 同时还需要指定一个mode参数，该参数指定RandomAccessFile的访问模式，一共有4种模式。 具体如下： 模式 | 说明|:—:|:—r | 以只读方式打开。调用结果对象的任何 write 方法都将导致抛出 IOExceptionrw | 打开以便读取和写入rws | 打开以便读取和写入。相对于 “rw”，”rws” 还要求对“文件的内容”或“元数据”的每个更新都同步写入到基础存储设备rwd | 打开以便读取和写入，相对于 “rw”，”rwd” 还要求对“文件的内容”的每个更新都同步写入到基础存储设备 两个重要的方法由以上介绍得知RandomAccessFile既可以读文件，也可以写文件，所以类似于InputStream的read()方法，以及类似于OutputStream的write()方法，RandomAccessFile都具备。除此之外，RandomAccessFile具备两个特有的方法，来支持其随机访问的特性。 RandomAccessFile对象包含了一个记录指针，用以标识当前读写处的位置，当程序新创建一个RandomAccessFile对象时，该对象的文件指针记录位于文件头，当读/写了n个字节后，文件记录指针将会后移n个字节。除此之外，RandomAccessFile还可以自由移动该记录指针。 下面就是RandomAccessFile具有的两个特殊方法，来操作记录指针，实现随机访问： long getFilePointer( ) // 返回文件记录指针的当前位置 void seek(long pos ) // 将文件指针定位到pos位置 写方法主要有：write(),writeBoolean(),writeByte(),writeBytes(),writeChar(),writeChars() 1234567891011121314151617181920212223242526272829void write(byte[] b) //将 b.length 个字节从指定 byte 数组写入到此文件，并从当前文件指针开始。 void write(byte[] b, int off, int len) //将 len 个字节从指定 byte 数组写入到此文件，并从偏移量 off 处开始。 void write(int b) //向此文件写入指定的字节。 void writeBoolean(boolean v) //按单字节值将 boolean 写入该文件。 void writeByte(int v) //按单字节值将 byte 写入该文件。 void writeBytes(String s) //按字节序列将该字符串写入该文件。 void writeChar(int v) //按双字节值将 char 写入该文件，先写高字节。 void writeChars(String s) //按字符序列将一个字符串写入该文件。 void writeDouble(double v) //使用 Double 类中的 doubleToLongBits 方法将双精度参数转换为一个 long，然后按八字节数量将该 long 值写入该文件，先定高字节。 void writeFloat(float v) //使用 Float 类中的 floatToIntBits 方法将浮点参数转换为一个 int，然后按四字 读方法主要有： read(),readBoolean(),readByte(),readChar(),readDouble(),readFloat(),readFully(),readInt(),readLine() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950int read() 从此文件中读取一个数据字节。 int read(byte[] b) 将最多 b.length 个数据字节从此文件读入 byte 数组。 int read(byte[] b, int off, int len) 将最多 len 个数据字节从此文件读入 byte 数组。 boolean readBoolean() 从此文件读取一个 boolean。 byte readByte() 从此文件读取一个有符号的八位值。 char readChar() 从此文件读取一个字符。 double readDouble() 从此文件读取一个 double。 float readFloat() 从此文件读取一个 float。 void readFully(byte[] b) 将 b.length 个字节从此文件读入 byte 数组，并从当前文件指针开始。 void readFully(byte[] b, int off, int len) 将正好 len 个字节从此文件读入 byte 数组，并从当前文件指针开始。 int readInt() 从此文件读取一个有符号的 32 位整数。 String readLine() 从此文件读取文本的下一行。 long readLong() 从此文件读取一个有符号的 64 位整数。 short readShort() 从此文件读取一个有符号的 16 位数。 int readUnsignedByte() 从此文件读取一个无符号的八位数。 int readUnsignedShort() 从此文件读取一个无符号的 16 位数。 String readUTF() 从此文件读取一个字符串。 demo1123456789101112131415161718192021222324252627282930313233343536373839import java.io.File;import java.io.IOException;import java.io.RandomAccessFile; public class Test&#123; static void testWrite() throws IOException &#123; File file=new File(\"D:\\\\test.txt\"); if(!file.exists())&#123; file.createNewFile(); &#125; RandomAccessFile raf=new RandomAccessFile(file, \"rw\"); System.out.println(\"文件指针位置：\"+raf.getFilePointer()); raf.writeInt(20);//写入一个int System.out.println(\"文件指针位置：\"+raf.getFilePointer()); raf.writeBoolean(true);//写入一boolean raf.close();//关闭文件 &#125; static void TestRead() throws IOException&#123; File file=new File(\"D:\\\\test.txt\"); //随机文件对象 RandomAccessFile raf=new RandomAccessFile(file, \"rw\"); //写入一个int int in = raf.readInt(); System.out.println(in); //写入一boolean boolean flag= raf.readBoolean(); System.out.println(flag); raf.close();//关闭文件 &#125; public static void main(String[] args) throws IOException&#123; testWrite(); TestRead(); &#125; &#125; 运行结果：1234文件指针位置：0文件指针位置：420true demo21234567891011121314151617181920212223242526272829303132333435363738394041import java.io.FileNotFoundException; import java.io.RandomAccessFile; public class test2 &#123; public static void main(String[] args) &#123; try &#123; //实例化随机存储流,不需要创建文件的路径 RandomAccessFile Raf = new RandomAccessFile(\"file\", \"rw\"); //创建一个字符串数组并初始化 String[] name = new String[3]; name[0] = \"JAVA\"; name[1] = \"android\"; name[2] = \"C++\"; //遍历数组 for(int i = 0;i&lt;name.length;i++)&#123; //使用随机流将数组写出去 Raf.writeUTF(name[i]); &#125; //添加元素 Raf.seek(Raf.length()); Raf.writeUTF(\"SSH\"); //使用seek将Raf.length()执行数组的第一个 Raf.seek(0); //遍历使用偏移量来遍历,每移动一下就打印出数据 while(Raf.getFilePointer()&lt;Raf.length())&#123; System.out.println(Raf.readUTF()); &#125; &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; 运行结果：1234JAVAandroidC++SSH 运用场景 断点续传 快速定位文件某一行 …","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.devcheng.net/tags/Java/"},{"name":"RandomAccessFile类","slug":"RandomAccessFile类","permalink":"http://www.devcheng.net/tags/RandomAccessFile类/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"base64出现空格问题的解决方案","slug":"base64出现空格问题的解决方案","date":"2019-06-27T13:27:36.000Z","updated":"2020-01-04T03:58:45.207Z","comments":true,"path":"post/54aeaf8d.html","link":"","permalink":"http://www.devcheng.net/post/54aeaf8d.html","excerpt":"","text":"使用背景项目中有一个参数是 byte[]，在构建 http请求的时候不便参数的传输，于是就想到了 使用base64进行编码之后当成字符串进行传输。 接下来就用自己写了一个http工具类，代码如下（片段）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 参数方式post发送 . * * @param simpleHttpRequest 请求 * @return 响应 */public static SimpleHttpResponse post(SimpleHttpRequest simpleHttpRequest) &#123; try &#123; HttpClient httpClient = buildHttpClient(simpleHttpRequest); PostMethod method = new PostMethod(simpleHttpRequest.getUrl()); method.addRequestHeader(\"Connection\", \"close\"); // 服务端应答完毕自动关闭连接 method.addRequestHeader(\"Content-Type\", \"application/x-www-form-urlencoded\"); if (simpleHttpRequest.getHttpHeader() != null) &#123; for (Map.Entry&lt;String, String&gt; entry : simpleHttpRequest.getHttpHeader().entrySet()) &#123; method.addRequestHeader(entry.getKey(), entry.getValue()); &#125; &#125; if (simpleHttpRequest.getParams() != null &amp;&amp; simpleHttpRequest.getParams().size() &gt; 0) &#123; NameValuePair[] nameValuePairs = new NameValuePair[simpleHttpRequest.getParams().size()]; int i = 0; for (Map.Entry&lt;String, Object&gt; entry : simpleHttpRequest.getParams().entrySet()) &#123; nameValuePairs[i++] = new NameValuePair(entry.getKey(), (String) entry.getValue()); &#125; method.addParameters(nameValuePairs); String content = StringUtils.parseMapToParamsStr(simpleHttpRequest.getParams()); RequestEntity requestEntity = new ByteArrayRequestEntity(content.getBytes(\"UTF-8\")); method.setRequestEntity(requestEntity); &#125; int status = httpClient.executeMethod(method); String response = null; if (status == HttpStatus.SC_OK) &#123; response = method.getResponseBodyAsString(); &#125; return new SimpleHttpResponse(status, response); &#125; catch (HttpException e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage(), e); &#125;&#125; 项目启动之后，参数都传递过去了，没什么毛病。但是呢，会出现一个问题，byte[] 用base64编码之后可能会出现一些 “+” 加号，使用自定义的 httpUtils 请求的时候，会把 “+” 变成空格。 使用base64编码之后的 byte[]字符串 123XRxZSKo4/oSH1tHOKOzYbFigK0Nq5vJP3RKSsPA8y9EplsdMMZTv+jW94v7bcU/28eaM6u1I9MSEsWFrs5JrhyXqvpztMxk6y/77qR7RuClpp4A+TXOyCdHKsA/aGxluA6gsvuQaDSHNNQ1pWBzsKldslMDtF1IGCRQJSyzxtnU= 使用httpUtils 获取的 byte[] 字符串123XRxZSKo4/oSH1tHOKOzYbFigK0Nq5vJP3RKSsPA8y9EplsdMMZTv jW94v7bcU/28eaM6u1I9MSEsWFrs5JrhyXqvpztMxk6y/77qR7RuClpp4A TXOyCdHKsA/aGxluA6gsvuQaDSHNNQ1pWBzsKldslMDtF1IGCRQJSyzxtnU= 问题的原因找到了，那接下来如何解决呢？ 解决方案解决方案 一将加密后的空格全部替换为 ‘+’ 号，replace(“ “, “+”)； 或者，将将加密后的字符串替换为 “%2B”， 再将 “%2B”替换回 ‘+’ 号，replace(“%2B”, “+”) 解决方案 二使用 post方式提交的时候，参数为 json形式。 具体代码如下：1234567891011121314151617181920212223242526272829303132333435363738/** * post请求 json参数 * @param url 请求地址 * @param params json参数 * @return */public static String doPost(String url, JSONObject params)&#123; String strResult = &quot;&quot;; // 1. 获取默认的client实例 CloseableHttpClient client = HttpClients.createDefault(); // 2. 创建httppost实例 HttpPost httpPost = new HttpPost(url); httpPost.addHeader(&quot;Content-Type&quot;, &quot;application/json;charset=utf-8&quot;); try &#123; httpPost.setEntity(new StringEntity(params.toJSONString(),&quot;utf-8&quot;)); CloseableHttpResponse resp = client.execute(httpPost); try &#123; // 7. 获取响应entity HttpEntity respEntity = resp.getEntity(); strResult = EntityUtils.toString(respEntity, &quot;UTF-8&quot;); &#125; finally &#123; resp.close(); &#125; &#125; catch (ClientProtocolException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; client.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return strResult;&#125; 使用 post请求json参数这个方法，具体代码：123456String url = &quot;http://127.0.0.1:8080/v1/auth&quot;;JSONObject params = new JSONObject();params.put(&quot;type&quot;,String.valueOf(userType));params.put(&quot;data&quot;,encodeData);params.put(&quot;user&quot;,userName);String responseBody = HttpUtils.doPost(url, params); 以上两种解决方法，均可以解决这个问题。 base64编码，解码我用的是 sun.misc.BASE64Decoder开始我还以为 切换成 其他的 base64 类库就不会有这个问题，我尝试了Apache Commons Codec的Base64 然后编码出来的字符串是一样的。 纯属工作笔记记录，如有错误，烦请指出！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"base64","slug":"base64","permalink":"http://www.devcheng.net/tags/base64/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"spring boot中的ApplicationRunner和CommandLineRunner","slug":"spring-boot中的ApplicationRunner和CommandLineRunner","date":"2019-06-15T03:26:36.000Z","updated":"2020-01-04T04:02:46.229Z","comments":true,"path":"post/651c4ef8.html","link":"","permalink":"http://www.devcheng.net/post/651c4ef8.html","excerpt":"","text":"导言在某些场景中，可能会需要到项目启动完成之后就需要初始化数据，读取配置文件，数据库信息等等业务需求。在spring boot中已经给我们提供了对应的接口，这两个接口是CommandLineRunner和ApplicationRunner。他们的执行时机为容器启动完成的时候。 这两个接口中有一个run方法，我们只需要实现这个方法即可。这两个接口的不同之处在于：ApplicationRunner中run方法的参数为ApplicationArguments，而CommandLineRunner接口中run方法的参数为String数组。 ApplicationRunner123456@Componentpublic class AppRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println(\"这个是测试ApplicationRunner接口\"); &#125; CommandLineRunner123456789@Component@Order(value = 1)public class AgentApplicationRun implements CommandLineRunner &#123; @Override public void run(String... strings) throws Exception &#123; System.out.println(\"这个是测试CommandLineRunner接口\"); &#125;&#125; 当接口有多个实现类时，提供了@order注解实现自定义执行顺序，也可以实现Ordered接口来自定义顺序。注意：数字越小，优先级越高，也就是@Order(1)注解的类会在@Order(2)注解的类之前执行","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"ApplicationRunner","slug":"ApplicationRunner","permalink":"http://www.devcheng.net/tags/ApplicationRunner/"},{"name":"CommandLineRunner","slug":"CommandLineRunner","permalink":"http://www.devcheng.net/tags/CommandLineRunner/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Java基础笔记整合","slug":"Java基础笔记整合","date":"2019-06-07T15:03:07.000Z","updated":"2020-01-04T04:00:41.696Z","comments":true,"path":"post/e207f62a.html","link":"","permalink":"http://www.devcheng.net/post/e207f62a.html","excerpt":"","text":"记录最基础 最容易忘记的笔记一.JAVA基础1.1 JAVA异常知识点Java把异常当作对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。下一层分为Error和Exception; 1.1.1 ErrorError类是指java运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。 1.1.2 ExceptionException又有两个分支，一个是运行时异常RuntimeException，一个是CheckedException。 1.1.2.1 RuntimeException如：NullPointerException、ClassCastException；一个是检查异常CheckedException，如I/O错误导致的IOException、SQLException。 RuntimeException是那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。如果出现RuntimeException，那么一定是程序员的错误。 1.1.2.2 CheckedException一般是外部错误，这种异常都发生在编译阶段，Java编译器会强制程序去捕获此类异常，即会出现要求你把这段可能出现异常的程序进行try catch，该类异常一般包括几个方面： 试图在文件尾部读取数据 试图打开一个错误格式的URL 试图根据给定的字符串查找class对象，而这个字符串表示的类并不存在 1.1.3 异常的处理方式抛出异常有三种形式，一是throw,一个throws，还有一种系统自动抛异常 12345678910public static void main(String[] args) &#123; String s = \"abc\"; if(s.equals(\"abc\")) &#123; throw new NumberFormatException(); &#125; else &#123; System.out.println(s); &#125; &#125; int div(int a,int b) throws Exception&#123; return a/b;&#125; 1.1.4 Throw和throws的区别 位置不同 throws用在函数上，后面跟的是异常类，可以跟多个；而throw用在函数内，后面跟的是异常对象。 功能不同： throws用来声明异常，让调用者只知道该功能可能出现的问题，可以给出预先的处理方式；throw抛出具体的问题对象，执行到throw，功能就已经结束了，跳转到调用者，并将具体的问题对象抛给调用者。也就是说throw语句独立存在时，下面不要定义其他语句，因为执行不到。 throws表示出现异常的一种可能性，并不一定会发生这些异常；throw则是抛出了异常，执行throw则一定抛出了某种异常对象。 两者都是消极处理异常的方式，只是抛出或者可能抛出异常，但是不会由函数去处理异常，真正的处理异常由函数的上层调用处理。 2.1 值类型,引用类型..2.1.1 值类型(基本数据类型)就是基本数据类型 基本数据类型常被称为四类八种 四类： 1，整型 2，浮点型 3，字符型 4，逻辑型 八种： 1，整型3种 byte，short，int，long 2，浮点型2种 float，double 3，字符型1种 char 4，逻辑型1种 boolean tips:Byte、Short、Integer、Long、Character这5种包装类都默认创建了数值[-128,127]的缓存数据。 当对这5个类型的数据不在这个区间内的时候，将会去创建新的对象，并且不会将这些新的对象放入常量池中。 Float 和Double 没有实现常量池。 2.1.2 引用类型(引用数据类型)四类八种基本类型外，所有的类型都称为引用类型（数组，类，接口，字符串） 2.1.3 值传递基本数据类型赋值都属于值传递,值传递传递的是实实在在的变量值,是传递原参数的拷贝,值传递后，实参传递给形参的值，形参发生改变而不影响实参。 对应的代码1234567891011121314151617181920212223242526272829public class ReferencePkValue2 &#123; public static void main(String[] args) &#123; ReferencePkValue2 t = new ReferencePkValue2(); int a=99; t.test1(a);//这里传递的参数a就是按值传递 System.out.println(a); MyObj obj=new MyObj(); t.test2(obj);//这里传递的参数obj就是引用传递 System.out.println(obj.b); &#125; public void test1(int a)&#123; a=a++; System.out.println(a); &#125; public void test2(MyObj obj)&#123; obj.b=100; System.out.println(obj.b); &#125;&#125;输出是：9999100100 tips:String, Integer, Double等immutable的类型特殊处理，可以理解为传值，最后的操作不会修改实参对象。(JAVA不可变类(immutable)机制与String的不可变性) 2.1.4 引用传递引用类型之间赋值属于引用传递。引用传递传递的是对象的引用地址,也就是它的本身(自己最通俗的理解)。引用传递：传的是地址，就是将实参的地址传递给形参，形参改变了，实参当然被改变了，因为他们指向相同的地址。对应的代码12345678910111213141516171819202122232425262728public class ReferencePkValue1 &#123; public static void main(String[] args)&#123; ReferencePkValue1 pk=new ReferencePkValue1(); //String类似基本类型，值传递，不会改变实际参数的值 String test1=\"Hello\"; pk.change(test1); System.out.println(test1); //StringBuffer和StringBuilder等是引用传递 StringBuffer test2=new StringBuffer(\"Hello\"); pk.change(test2); System.out.println(test2.toString()); &#125; public void change(String str)&#123; str=str+\"world\"; // 但是在这里 System.out.println(str);的话 结果就是 Helloworld &#125; public void change(StringBuffer str)&#123; str.append(\"world\"); &#125;&#125;输出是：Hello Helloworld 3.1 Java克隆对象的三种方式1 直接赋值2 浅克隆（浅拷贝）3 深克隆（深拷贝） 3.1.1 浅克隆（浅拷贝）定义：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝 3.1.2 深克隆（深拷贝）定义：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容 tips: 深克隆和浅克隆的区别由定义既可知，在引用数据类型是进行了引用的传递还是创建新的对象。 3.1.3 工具类克隆对象3.1.3.1 apache的BeanUtils 工具类使用org.apache.commons.beanutils.BeanUtils进行对象深入复制时候，主要通过向BeanUtils框架注入新的类型转换器，因为默认情况下，BeanUtils对复杂对象的复制是引用。123456789101112131415161718192021222324252627282930public static void beanUtilsTest() throws Exception &#123; // 注册转化器 BeanUtilsBean.getInstance().getConvertUtils().register(new ArbitrationConvert(), ArbitrationDO.class); Wrapper wrapper = new Wrapper(); wrapper.setName(\"copy\"); wrapper.setNameDesc(\"copy complex object!\"); wrapper.setArbitration(newArbitrationDO()); Wrapper dest = new Wrapper(); // 对象复制 BeanUtils.copyProperties(dest, wrapper); // 属性验证 wrapper.getArbitration().setBizId(\"1\"); System.out.println(wrapper.getArbitration() == dest.getArbitration()); System.out.println(wrapper.getArbitration().getBizId().equals(dest.getArbitration().getBizId()));&#125; public class ArbitrationConvert implements Converter &#123; @Override public &lt;T&gt; T convert(Class&lt;T&gt; type, Object value) &#123; if (ArbitrationDO.class.equals(type)) &#123; try &#123; return type.cast(BeanUtils.cloneBean(value)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125;&#125; 实验发现，使用org.apache.commons.beanutils.BeanUtils复制引用时，主和源的引用为同一个，即改变了主的引用属性会影响到源的引用，所以这是一种浅拷贝。 tips:需要注意的是，apache的BeanUtils中，以下类型如果为空，会报错（org.apache.commons.beanutils.ConversionException: No value specified for…） 3.1.3.2 apache的PropertyUtils 工具类PropertyUtils的copyProperties()方法几乎与BeanUtils.copyProperties()相同，主要的区别在于后者提供类型转换功能，即发现两个JavaBean的同名属性为不同类型时，在支持的数据类型范围内进行转换，PropertyUtils不支持这个功能，它仍然属于浅拷贝。 tips: Apache提供了 SerializationUtils.clone(T)，T对象需要实现 Serializable 接口，他属于深拷贝。 3.1.3.3 spring的BeanUtils 工具类Spring中的BeanUtils，其中实现的方式很简单，就是对两个对象中相同名字的属性进行简单get/set，仅检查属性的可访问性。源码片段:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static void copyProperties(Object source, Object target) throws BeansException &#123; copyProperties(source, target, (Class)null, (String[])null); &#125; public static void copyProperties(Object source, Object target, Class&lt;?&gt; editable) throws BeansException &#123; copyProperties(source, target, editable, (String[])null); &#125; public static void copyProperties(Object source, Object target, String... ignoreProperties) throws BeansException &#123; copyProperties(source, target, (Class)null, ignoreProperties); &#125; private static void copyProperties(Object source, Object target, Class&lt;?&gt; editable, String... ignoreProperties) throws BeansException &#123; Assert.notNull(source, \"Source must not be null\"); Assert.notNull(target, \"Target must not be null\"); Class actualEditable = target.getClass(); if(editable != null) &#123; if(!editable.isInstance(target)) &#123; throw new IllegalArgumentException(\"Target class [\" + target.getClass().getName() + \"] not assignable to Editable class [\" + editable.getName() + \"]\"); &#125; actualEditable = editable; &#125; PropertyDescriptor[] targetPds = getPropertyDescriptors(actualEditable); List ignoreList = ignoreProperties != null?Arrays.asList(ignoreProperties):null; PropertyDescriptor[] var7 = targetPds; int var8 = targetPds.length; for(int var9 = 0; var9 &lt; var8; ++var9) &#123; PropertyDescriptor targetPd = var7[var9]; Method writeMethod = targetPd.getWriteMethod(); if(writeMethod != null &amp;&amp; (ignoreList == null || !ignoreList.contains(targetPd.getName()))) &#123; PropertyDescriptor sourcePd = getPropertyDescriptor(source.getClass(), targetPd.getName()); if(sourcePd != null) &#123; Method readMethod = sourcePd.getReadMethod(); if(readMethod != null &amp;&amp; ClassUtils.isAssignable(writeMethod.getParameterTypes()[0], readMethod.getReturnType())) &#123; try &#123; if(!Modifier.isPublic(readMethod.getDeclaringClass().getModifiers())) &#123; readMethod.setAccessible(true); &#125; Object ex = readMethod.invoke(source, new Object[0]); if(!Modifier.isPublic(writeMethod.getDeclaringClass().getModifiers())) &#123; writeMethod.setAccessible(true); &#125; writeMethod.invoke(target, new Object[]&#123;ex&#125;); &#125; catch (Throwable var15) &#123; throw new FatalBeanException(\"Could not copy property \\'\" + targetPd.getName() + \"\\' from source to target\", var15); &#125; &#125; &#125; &#125; &#125; &#125; tips： 成员变量赋值是基于目标对象的成员列表, 并且会跳过ignore的以及在源对象中不存在的, 所以这个方法是安全的, 不会因为两个对象之间的结构差异导致错误, 但是必须保证同名的两个成员变量类型相同。 3.1.3.4 dozer [Dozer（http://dozer.sourceforge.net/）]能够实现深拷贝。Dozer是基于反射来实现对象拷贝，反射调用set/get 或者是直接对成员变量赋值 。 该方式通过invoke执行赋值，实现时一般会采用beanutil, Javassist等开源库。 3.1.3.5 MapStrcutMapStrcut属于编译期的对象复制方案，它能够动态生成set/get代码的class文件 ，在运行时直接调用该class文件。该方式实际上扔会存在set/get代码，只是不需要自己写了。12345@Mapper(componentModel = \"spring\")public interface MonitorAppGroupIdcDTOMapper &#123; MonitorAppGroupIdcDTOMapper MAPPER = Mappers.getMapper(MonitorAppGroupIdcDTOMapper.class); void mapping(MonitorAppGroupIdcDTO source, @MappingTarget MonitorAppGroupIdcDTO dest);&#125; 3.1.3.6 BeanCopier基于CGlib实现Bean拷贝，可以通过缓存BeanCopier的实例来提高性能。12345678BeanCopier b = getFromCache(sourceClass,targetClass); //从缓存中取long start = System.currentTimeMillis();List&lt;ShopCouponModel&gt; modelList = new ArrayList&lt;&gt;();for (ShopCouponEntity src : entityList) &#123; ShopCouponModel dest = new ShopCouponModel(); b.copy(src, dest, null); modelList.add(dest);&#125; 3.1.3.7 fastjson和GSON使用fastjson和GSON主要是通过对象json序列化和反序列化来完成对象复制，这里只是提供一种不一样的对象拷贝的思路 3.1.3.8 序列化（深clone一中实现）在Java语言里深复制一个对象，常常可以先使对象实现Serializable接口，然后把对象（实际上只是对象的一个拷贝）写到一个流里，再从流里读出来，便可以重建对象。 性能测试123456789101112131415161718192021222324252627282930313233343536373839NewNovelMode des = null ;NewNovelMode ori = buildModel();Gson gson = new Gson(); int count = 100000;//org.springframework.beans.BeanUtils.copyPropertieslong s = System.currentTimeMillis();for(int i=0;i&lt;count;i++)&#123; des = new NewNovelMode(); org.springframework.beans.BeanUtils.copyProperties(ori, des);&#125;System.out.println(\"springframework BeanUtils cost:\"+(System.currentTimeMillis() - s));// System.out.println(new Gson().toJson(des)); //org.apache.commons.beanutils.BeanUtilss = System.currentTimeMillis();for(int i=0;i&lt;count;i++)&#123; des = new NewNovelMode(); org.apache.commons.beanutils.BeanUtils.copyProperties(des, ori);&#125;System.out.println(\"apache BeanUtils cost:\"+(System.currentTimeMillis() - s));// System.out.println(new Gson().toJson(des)); //gson转换s = System.currentTimeMillis();for(int i=0;i&lt;count;i++)&#123; des = gson.fromJson(gson.toJson(ori), NewNovelMode.class);&#125;System.out.println(\"gson cost:\"+(System.currentTimeMillis() - s));// System.out.println(new Gson().toJson(des)); //Pojo转换类s = System.currentTimeMillis();PojoUtils&lt;NewNovelMode, NewNovelMode&gt; pojoUtils = new PojoUtils&lt;NewNovelMode, NewNovelMode&gt;();for(int i=0;i&lt;count;i++)&#123; des = new NewNovelMode(); pojoUtils.copyPojo(ori,des);&#125;System.out.println(\"Pojoconvert cost:\"+(System.currentTimeMillis() - s));// System.out.println(new Gson().toJson(des)); 性能对比： BeanCopier &gt; BeanUtils. 其中BeanCopier的性能高出另外两个100数量级。 BeanUtils（简单，易用） BeanCopier（加入缓存后和手工set的性能接近） Dozer（深拷贝） fastjson（特定场景下使用） 4.1 JAVA 集合Java 集合类存放在 Java.util包中，主要有3中：Set（集），list(列表包括Queue)，Map(映射) Collection： Collection是集合List，Set，Queue的最基本的接口。 Iterator: 迭代器，可以通过迭代器遍历集合中的数据。 Map： 是映射表的最基础的接口。 [] [] 4.1.1 ListJava的List是非常常用的数据类型。 List是有序的Collection。 Java List一共三个实现类：分别是ArrayList、Vector和LinkedList。[] 4.1.2 ArrayList（数组）ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。 数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要将已经有数组的数据复制到新的存储空间中。 当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。 因此，它适合随机查找和遍历，不适合插入和删除。 4.1.3 Vector（数组实现、线程同步）Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector， 避免多线程同时写而引起的不一致性，但实现同步需要很高的花费， 因此，访问它比访问ArrayList慢。 4.1.4 LinkList（链表）LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。 另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素， 可以当作堆栈、队列和双向队列使用。 名字 描述 List 1. 需要保留存储顺序，并保留重复数据，使用 List ‘’ 2.查询较多，使用ArrayList ‘’ 3.存储较多，使用LinkedList ‘’ 4.线程安全，使用Vector 4.1.2 SetSet注重独一无二的性质,该体系集合用于存储无序(存入和取出的顺序不一定相同)元素，值不能重复。 对象的相等性本质是对象hashCode值（java是依据对象的内存地址计算出的此序号）判断的， 如果想要让两个不同的对象视为相等的，就必须覆盖Object的hashCode方法和equals方法。 4.1.2.1 HashSet（Hash表）哈希表边存放的是哈希值。HashSet存储元素的顺序并不是按照存入时的顺序（和List显然不同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。 元素的哈希值是通过元素的hashcode方法来获取的, HashSet首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals方法 如果 equls结果为true ，HashSet就视为同一个元素。如果equals 为false就不是同一个元素。 4.1.2.2 TreeSet（二叉树） TreeSet()是使用二叉树的原理对新add()的对象按照指定的顺序排序（升序、降序），每增加一个对象都会进行排序，将对象插入的二叉树指定的位置。 Integer和String对象都可以进行默认的TreeSet排序，而自定义类的对象是不可以的，自己定义的类必须实现Comparable接口，并且覆写相应的compareTo()函数，才可以正常使用。 在覆写compare()函数时，要返回相应的值才能使TreeSet按照一定的规则来排序 比较此对象与指定对象的顺序。如果该对象小于、等于或大于指定对象，则分别返回负整数、零或正整数。 4.1.2.3 LinkHashSet（HashSet+LinkedHashMap）对于LinkedHashSet而言，它继承与HashSet、又基于LinkedHashMap来实现的。 LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承与HashSet，其所有的方法操作上又与HashSet相同 因此LinkedHashSet 的实现上非常简单，只提供了四个构造方法，并通过传递一个标识参数，调用父类的构造器，底层构造一个LinkedHashMap来实现， 在相关操作上与父类HashSet的操作相同，直接调用父类HashSet的方法即可。 4.1.3 Map 4.1.3.1 HashMap（数组+链表+红黑树）HashMap根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。 如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。 上图中，每个绿色的实体是嵌套类 Entry 的实例，Entry 包含四个属性：key, value, hash 值和用于单向链表的 next。 capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。 loadFactor：负载因子，默认为 0.75。 threshold：扩容的阈值，等于 capacity * loadFactor Java8 对 HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+红黑树 组成。 根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话， 需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。 为了降低这部分的开销，在 Java8 中，当链表中的元素超过了 8 个以后，会将链表转换为红黑树， 在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。 4.1.3.2 HashTable（线程安全）Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable， 并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。 Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 4.1.3.3 TreeMap（可排序）TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。 如果使用排序的映射，建议使用TreeMap。 在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 4.1.3.4 LinkHashMap（记录插入顺序）LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 4.1.3.5 ConcurrentHashMapSegment段 ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一些。整个 ConcurrentHashMap 由一个个 Segment 组成， Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为分段锁。注意，行文中，我很多地方用了“槽”来代表一个 segment。 线程安全（Segment 继承 ReentrantLock 加锁） ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。 并行度（默认16） concurrencyLevel：并行级别、并发数、Segment 数，怎么翻译不重要，理解它。 默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment上。 这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。 Java8 对 ConcurrentHashMap 进行了比较大的改动,Java8 也引入了红黑树。 5.1 Java 多线程并发5.1.0 JAVA并发知识库图 5.1.1 JAVA线程实现/创建方式5.1.1.1 继承Thread类Thread类本质上是实现了Runnable接口的一个实例，代表一个线程的实例。 启动线程的唯一方法就是通过Thread类的start()实例方法。 start()方法是一个native方法，它将启动一个新线程，并执行run()方法。12345678910public class MyThread extends Thread &#123; public void run() &#123; System.out.println(\"MyThread.run()\"); &#125; &#125; MyThread myThread1 = new MyThread(); myThread1.start(); 5.1.1.2 实现Runnable接口如果自己的类已经extends另一个类，就无法直接extends Thread，此时，可以实现一个Runnable接口。 1234567891011121314151617public class MyThread extends OtherClass implements Runnable &#123; public void run() &#123; System.out.println(\"MyThread.run()\"); &#125; &#125;//启动MyThread，需要首先实例化一个Thread，并传入自己的MyThread实例： MyThread myThread = new MyThread(); Thread thread = new Thread(myThread); thread.start(); //事实上，当传入一个Runnable target参数给Thread后，Thread的run()方法就会调用target.run() public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; 5.1.1.3 ExecutorService、Callable、Future有返回值线程有返回值的任务必须实现Callable接口，类似的，无返回值的任务必须Runnable接口。 执行Callable任务后，可以获取一个Future的对象，在该对象上调用get就可以获取到Callable任务返回的Object了，再结合线程池接口ExecutorService就可以实现传说中有返回结果的多线程了。1234567891011121314//创建一个线程池ExecutorService pool = Executors.newFixedThreadPool(taskSize); // 创建多个有返回值的任务 List&lt;Future&gt; list = new ArrayList&lt;Future&gt;(); for (int i = 0; i &lt; taskSize; i++) &#123; Callable c = new MyCallable(i + \" \"); // 执行任务并获取Future对象 Future f = pool.submit(c); list.add(f); &#125; // 关闭线程池 pool.shutdown(); // 获取所有并发任务的运行结果 for (Future f : list) &#123; // 从Future对象上获取任务的返回值，并输出到控制台 System.out.println(\"res：\" + f.get().toString()); &#125; 5.1.1.4 基于线程池的方式线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建，不需要的时候销毁，是非常浪费资源的。那么我们就可以使用缓存的策略，也就是使用线程池。12345678910111213141516// 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); while(true) &#123; threadPool.execute(new Runnable() &#123; // 提交多个线程任务，并执行 @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \" is running ..\"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125; 5.1.2 四种线程池Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。 5.1.2.1 newCachedThreadPool创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。 调用 execute 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。 终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源 5.1.2.2 newFixedThreadPool创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。 如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止， 那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之前，池中的线程将一直存在。 工作代码实例1234567891011121314151617181920212223242526// 线程池private ExecutorService pool = Executors.newFixedThreadPool(50);/** * 三期拆相册 * @param queryModel * @param userId * @return */public int[] countOrderNum2(String queryModel, int userId) &#123; int[] ret = new int[] &#123; 0, 0, 0, 0 &#125;; Map&lt;String, Object&gt; map = getParamMap(queryModel, userId, null, null); map.put(\"userId\", userId); CompletableFuture&lt;Integer&gt; integerCompletableFuture = CompletableFuture.supplyAsync(() -&gt; &#123; HashMap&lt;String,Object&gt; map2 = new HashMap&lt;&gt;(); map2.putAll(map); map2.put(\"queryType\", 1); return orderMapper.countOrderNum2(map2); &#125;, pool); ret[0]=integerCompletableFuture.join(); return ret;&#125; 5.1.2.3 newScheduledThreadPool创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。 工作代码实例123456789101112131415161718 private static ScheduledExecutorService SCHEDULE_POOL = Executors.newScheduledThreadPool(2); /** * 计算云相册使用费和委拍服务费 */private void recalculatePhotographerOrderFee(Long orderId, Long userId) &#123; /** * xxx demo... */ // 因为事务的问题 需延迟重算摄影师人数 这段代码执行之后 事务需要在1s内提交完成 所以需要保证这段代码 是在事务的最后执行 SCHEDULE_POOL.schedule(() -&gt; &#123; // 重新计算摄影师人数 itOrderSourceNumService.recalculatePhotographerOrderSourceNum(orderId); &#125;, 1, TimeUnit.SECONDS);&#125; 5.1.2.4 newSingleThreadExecutorExecutors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程）,这个线程池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去！ 5.1.3 线程生命周期当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。 在线程的生命周期中，它要经过新建(New)、就绪（Runnable）、运行（Running）、阻塞(Blocked)和死亡(Dead)5种状态。 尤其是当线程启动以后，它不可能一直”霸占”着CPU独自运行，所以CPU需要在多条线程之间切换，于是线程状态也会多次在运行、阻塞之间切换。 5.1.3.1 新建状态（NEW）当代码中使用new关键字创建了一个线程之后，该线程就处于新建状态，此时仅由JVM为其分配内存，并初始化其成员变量的值。 5.1.3.2 就绪状态（RUNNABLE）当线程对象调用了start()方法之后，该线程处于就绪状态。Java虚拟机会为其创建方法调用栈和程序计数器，等待调度运行。 5.1.3.3 运行状态（RUNNING）如果处于就绪状态的线程获得了CPU，开始执行run()方法的线程执行体，则该线程处于运行状态。 5.1.3.4 阻塞状态（BLOCKED）阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。 阻塞的情况分三种： 等待阻塞（o.wait-&gt;等待对列）：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。 同步阻塞(lock-&gt;锁池) 运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。 其他阻塞(sleep/join) 运行(running)的线程执行Thread.sleep(longms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。 当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。 5.1.3.5 线程死亡（DEAD）线程会以下面三种方式结束，结束后就是死亡状态。 正常结束 1. run()或call()方法执行完成，线程正常结束。 异常结束 2. 线程抛出一个未捕获的Exception或Error。 调用stop 3. 直接调用该线程的stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用。 5.1.4 终止线程4种方式 正常运行结束程序运行结束，线程自动结束。 使用退出标志退出线程一般run()方法执行完，线程就会正常结束，然而，常常有些线程是伺服线程。它们需要长时间的运行，只有在外部某些条件满足的情况下，才能关闭这些线程。 使用一个变量来控制循环，例如：最直接的方法就是设一个boolean类型的标志，并通过设置这个标志为true或false来控制while循环是否退出， 代码示例：12345678public class ThreadSafe extends Thread &#123; public volatile boolean exit = false; public void run() &#123; while (!exit)&#123; //do something &#125; &#125; &#125; Interrupt方法结束线程使用interrupt()方法来中断线程有两种情况:1.线程处于阻塞状态：如使用了sleep,同步锁的wait,socket中的receiver,accept等方法时，会使线程处于阻塞状态。当调用线程的interrupt()方法时，会抛出InterruptException异常。阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后break跳出循环状态，从而让我们有机会结束这个线程的执行。通常很多人认为只要调用interrupt方法线程就会结束，实际上是错的， 一定要先捕获InterruptedException异常之后通过break来跳出循环，才能正常结束run方法。 2.线程未处于阻塞状态：使用isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置true，和使用自定义的标志来控制循环是一样的道理。123456789101112public class ThreadSafe extends Thread &#123; public void run() &#123; while (!isInterrupted())&#123; //非阻塞过程中通过判断中断标志来退出 try&#123; Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出 &#125;catch(InterruptedException e)&#123; e.printStackTrace(); break;//捕获到异常之后，执行break跳出循环 &#125; &#125; &#125;&#125; stop方法终止线程（线程不安全）程序中可以直接使用thread.stop()来强行终止线程，但是stop方法是很危险的，就象突然关闭计算机电源，而不是按正常程序关机一样，可能会产生不可预料的结果， 不安全主要是：thread.stop()调用之后，创建子线程的线程就会抛出ThreadDeatherror的错误，并且会释放子线程所持有的所有锁。 一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性， 其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用stop方法来终止线程。 5.1.5 线程相关的两个问题5.1.5.1 sleep与wait 区别 对于sleep()方法，该方法是属于Thread类。而wait()方法，则是属于Object类。 sleep()方法导致了程序暂停执行指定的时间，让出cpu该其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态 在调用sleep()方法的过程中，线程不会释放对象锁。 而当调用wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。 5.1.5.2 start与run区别 start（）方法来启动线程，真正实现了多线程运行。这时无需等待run方法体代码执行完毕，可以直接继续执行下面的代码。 通过调用Thread类的start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 方法run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行run函数当中的代码。 Run方法运行结束， 此线程终止。然后CPU再调度其它线程。 如有你觉得也是基础的未写出来的，可以给我留言哦！我会加上来的！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.devcheng.net/tags/Java基础/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"基于SpringBoot1.5 + MyBatis + Thymeleaf 开发的个人博客源码分享","slug":"基于SpringBoot1-5-MyBatis-Thymeleaf-开发的个人博客源码分享","date":"2019-05-11T05:39:58.000Z","updated":"2020-01-04T04:03:38.864Z","comments":true,"path":"post/a182a993.html","link":"","permalink":"http://www.devcheng.net/post/a182a993.html","excerpt":"","text":"毕设描述这个博客由SpringBoot1.5 + MyBatis + Thymeleaf等技术实现的个人网站，分为前台和完整的后台功能，喜欢的话就赶紧来下载！ 开发环境（运行环境）jdk8+mysql+IntelliJ IDEA+maven 项目采用技术后端 核心框架：SpringBoot 持久层框架：MyBatis 模板框架：Thymeleaf 分页插件：PageHelper 缓存框架：Ehcache Markdown：Commonmark … 前端 JS框架：Jquery CSS框架：Bootstrap 富文本编辑器：editor.md 文件上传：dropzone 弹框插件：sweetalert 其他 七牛云 百度统计 algolia 数据库文件在项目文件里面 项目截图 运行截图http://localhost:8080/ 登录地址http://localhost:8080/admin/login 登录用户名和密码admin / 111111 是否免费收费写码不易，付费后给代码并且提供对应的技术服务支持。 联系我们QQ 搜索我们的群号：816175200 注意事项1.添加了 搜索功能，使用 algolia 2.修复 无配置数据时，页面无法正常打开 3.修复 七牛云上传图片之后，无法正常显示问题 4.添加 新建文章数据保存至 algolia 5.修复 部分其他页面问题 注意点1 下载代码之后，建议更改 七牛云 对应的配置，默认我会开放使用，但不保证我不会改这部分配置！ 注意点2 下载代码之后，建议更改 algolia 对应的配置，默认我会开放使用，但不保证我不会改这部分配置！ 有任何问题，都可以找我，but 不是免费帮助 ！ 最后重申一次，代码是完整的,如若跑不起来请联系我！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"},{"name":"个人博客源码","slug":"个人博客源码","permalink":"http://www.devcheng.net/tags/个人博客源码/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"折腾centos6.5笔记","slug":"折腾centos6-5笔记","date":"2019-04-21T04:01:20.000Z","updated":"2020-01-04T04:05:04.736Z","comments":true,"path":"post/a1be3b5.html","link":"","permalink":"http://www.devcheng.net/post/a1be3b5.html","excerpt":"","text":"1.安装 vmware12 安装完成后，会提示要求输入序列号，序列号已经收集起来了。 VMware Workstation 12序列号：5A02H-AU243-TZJ49-GTC7K-3C61N 2.安装centos6.5 下载 centos6.5下载地址:http://mirrors.163.com/ 问题1：二进制转换与此平台上的长模式不兼容描述： 启动vmware出现：1、二进制转换与此平台长模式不兼容….等等字样；原因： 出现这样的原因一般都是由于系统Virtualization Technology虚拟化技术功能 关闭导致的。 解决方法：以thinkpad t450 为例子，首先选择开机进入bios（t450 F1进入），然后找到 Intel Virtual Technology默认的是disabled 这里回车 更改为enabled。注：Intel Virtual Technology这项有的电脑在configuration里面，在thinkpad t450 里面不是这个地方的哦（具体在哪里我现在也忘记了，不过进入bios后 找Intel Virtual Technology 就可以了） 设好后F10 保存退出 重新启动电脑。 问题2： 无法获取 vmci 驱动程序版本： 句柄无效描述：很多人在使用虚拟机的时候，会出现这个问题，导致无法进入虚拟机解决方法：http://jingyan.baidu.com/article/a3a3f811ea5d2a8da2eb8aa1.html 问题3: no default or ui configuration directive found描述：检测不到任何的默认启动配置 .原因： 查看USB设备的根目录下isolinux文件中，发现有一个syslinux.cfg的文件夹，文件夹内容为空，存在文件isolinux.cfg文件 解决方法： 删除syslinux.cfg文件夹，然后重命名isolinux.cfg为syslinux.cfg，查看syslinux.cfg里里面是否正常存在配置信息，重启服务器注意：实在解决不了，还有一种可能就是你的iso镜像文件坏了，请重新下载一个iso文件重新安装。 问题4：无法将 Ethernet0 连接到虚拟网络”VMnet0” 详细信息可以在 vmware.log&amp;描述：通常是虚拟机没有网络，就会爆这个错误。 解决方法：在 vmware“编辑-&gt;虚拟网络设置”里面，点“恢复默认”可解决。 centos 安装java开发环境 参考资料 http://www.cnblogs.com/shenliang123/archive/2013/07/21/3203278.html centos jdk 安装http://www.cnblogs.com/xiaoluo501395377/archive/2013/04/07/3003278.html centos mysql 安装http://www.2cto.com/database/201305/208114.html centos mysql 安装http://zhizhuofl.blog.163.com/blog/static/69914779201118101254519/ centos 远程连接 mysqlhttp://www.cnblogs.com/sixiweb/archive/2012/11/26/2789458.html centos 安装tomcat6","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"centos6.5","slug":"centos6-5","permalink":"http://www.devcheng.net/tags/centos6-5/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"浅谈多线程之CAS原理","slug":"浅谈多线程之CAS原理","date":"2019-04-14T12:54:32.000Z","updated":"2020-01-04T04:04:09.961Z","comments":true,"path":"post/43ec5f4c.html","link":"","permalink":"http://www.devcheng.net/post/43ec5f4c.html","excerpt":"","text":"前言在Java并发包中有这样一个包，java.util.concurrent.atomic，该包是对Java部分数据类型的原子封装，在原有数据类型的基础上，提供了原子性的操作方法，保证了线程安全。下面以AtomicInteger为例，来看一下是如何实现的。 123456789101112131415161718public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; &#125;&#125;public final int decrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current - 1; if (compareAndSet(current, next)) return next; &#125;&#125; 以这两个方法为例，incrementAndGet方法相当于原子性的i，decrementAndGet方法相当于原子性的–i（根据第一章和第二章我们知道i或–i不是一个原子性的操作），这两个方法中都没有使用阻塞式的方式来保证原子性（如Synchronized），那它们是如何保证原子性的呢，下面引出CAS。 Compare And SwapCAS 指的是现代 CPU 广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。这个指令会对内存中的共享数据做原子的读写操作。简单介绍一下这个指令的操作过程：首先，CPU 会将内存中将要被更改的数据与期望的值做比较。 然后，当这两个值相等时，CPU 才会将内存中的数值替换为新的值。否则便不做操作。最后，CPU 会将旧的数值返回。这一系列的操作是原子的。它们虽然看似复杂，但却是 Java 5 并发机制优于原有锁机制的根本。 简单来说，CAS 的含义是“我认为原有的值应该是什么，如果是，则将原有的值更新为新值，否则不做修改，并告诉我原来的值是多少”。（这段描述引自《Java并发编程实践》） 简单的来说，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。 当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则返回V。这是一种乐观锁的思路，它相信在它修改之前，没有其它线程去修改它；而Synchronized是一种悲观锁，它认为在它修改之前，一定会有其它线程去修改它，悲观锁效率很低。下面来看一下AtomicInteger是如何利用CAS实现原子性操作的。 CAS的ABA问题所谓 ，问题基本是这个样子： 进程P1在共享变量中读到值为A P1被抢占了，进程P2执行 P2把共享变量里的值从A改成了B，再改回到A，此时被P1抢占。 P1回来看到共享变量里的值没有被改变，于是继续执行。 虽然P1以为变量值没有改变，继续执行了，但是这个会引发一些潜在的问题。ABA问题最容易发生在lock free 的算法中的，CAS首当其冲，因为CAS判断的是指针的地址。如果这个地址被重用了呢，问题就很大了。（地址被重用是很经常发生的，一个内存分配后释放了，再分配，很有可能还是原来的地址） 比如上述的DeQueue()函数，因为我们要让head和tail分开，所以我们引入了一个dummy指针给head，当我们做CAS的之前，如果head的那块内存被回收并被重用了，而重用的内存又被EnQueue()进来了，这会有很大的问题。（内存管理中重用内存基本上是一种很常见的行为） 这个例子你可能没有看懂，维基百科上给了一个活生生的例子—— 你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。 这就是ABA的问题。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.devcheng.net/tags/多线程/"},{"name":"CAS原理","slug":"CAS原理","permalink":"http://www.devcheng.net/tags/CAS原理/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"离开了公司，你还有什么","slug":"离开了公司，你还有什么","date":"2019-03-31T08:05:05.000Z","updated":"2020-01-04T04:03:49.577Z","comments":true,"path":"post/43e98a4d.html","link":"","permalink":"http://www.devcheng.net/post/43e98a4d.html","excerpt":"","text":"工作越久，好像越不敢想象没有工作的样子。你有这样的感觉吗？ 12345672007年12月，我从南京回到西安，重新开始寻找工作，一开始我觉得休息上几个月也好，不用着急。可是真到了西安，休息了一个星期就开始恐慌！没工作啊，再也没有收入了，而你的各项支出分毫未减！2014年9月，我离开工作7年的公司，再次开始求职。这一次我想一定要好好规划一下，想好了再做决定，休息三五个月也能接受。可一旦闲下来，不再需要朝九晚五地上下班，忽然觉得心里空荡荡的。离开了工作，似乎什么也没有了！然后，迅速的，又开始因为不再有收入而恐慌了……再后来，只好迅速地去上班了。 我发现，自己已经深陷“工作–薪水–消费–工作–薪水–消费”这种循环而无法自拔了。我们的欲望阈值越来越高，我们的消费水平不断升级，我们越来越不能没有工作了。意识到这一点，让人不寒而栗。于是，我开始琢磨，工作到底给了我什么呢？如果丢掉眼下这份工作，我还有什么？你想过这样的问题吗？ 从上面的问题，我又想到另外一个问题：除了工作和平台，你还有什么？ 现今这个时代，公司已经不再养人，进入一家不错的工作，一干一辈子，哪怕天天混日子也可以终老的时代彻底终结了，我们随时都可能遭遇裁员、公司解散、被炒鱿鱼等状况，从而不得不再次面对求职。 当这个时刻悄然到来，你就不得不面临这个问题：除了工作和平台，我还有什么？ 我们该怎样才能不依赖于工作，以从容自由之心穿行在这欲望的都市里呢？ 也许静下心来盘点一下自己，努力在工作中从下面几个方面积累，能帮助我们获得从容自由： 财富 个人品牌 人脉 爱好 能产生被动收入的资产 财富你觉得什么是财富？或者什么叫有钱？一百万？一千万？还是一个亿？ 其实财富不是用钱来衡量的，而是用时间。所谓财富，是指完全没有工作收入时，保持现在的生活水平，你还能生活多久。 从这个角度看，拥有千万的人，不一定比只有10万块的人财富多。那么，来算一算，你工作这几年，攒下的钱，折算成财富，是多久？ 当你算出你的财富是多久，你就知道在更换工作时，你能承受多久的空档期。一个月，三个月，还是一年，都可以轻松算出来。当你有了空档时间预期，在更换工作时，就没那么慌了。将自己找工作的周期设定得比你的财富周期稍稍短一些（1~3个月），对你能够安心找到适合自己的工作非常有帮助。 所以，我们在工作时，就要了解自己的收入和支出状况，统计每个月的总收入和花销，看看收入减去花销之后的盈余是多少。对于工薪族来说，尤其重要的是分析每个月的花销，看看钱都流向了哪里，哪些地方产生了不必要的开支，有针对性的优化，这样就可以在收入相对稳定的情况下获得更多的积累。日积月累，哪怕你每月只累积1000块，四年也有将近5万块，可以为后面的简单理财提供支持。 个人品牌你在一家公司里一丝不苟地完成上司分派的任务，兢兢业业的工作，离开时，别人对你的印象，是“张三是A公司的软件开发工程师”，还是“张三iOS APP开发能力北京前三”？ 这两者之间，有非常大的不同。前者说明你曾归属于哪里，是与你所在公司绑定的，别人看到的是你服务过的公司，是从公司的角度来看待你，你个人的属性被忽略了。 而后者，说明你拥有了超越公司背景的个人属性，别人首先看到的是你这个人，而不是你在哪个公司工作。只有你拥有了独特的个人属性，与你交往过的人，才可能因为你个人的属性而记住你，才有可能经常想到你，你才有可能走出自己的道路，也才有可能从容行走于职场。 所以，当我们在一家公司尽责工作时，要多想想： 1.当我离开了这里，除了我曾在这里工作过这个原因，还有其它的、独属于我的东西，能够让别人记住我吗？我现在拥有的，哪些是带不走的，哪些是可以伴随我风行天下的？ 2.当你经常这样想时，就会培养出成长的意识，培养出建立个人品牌的意识，就会付出额外的努力，在工作中想方设法历练自己，力图在公司的平台上，在出色完成工作的同时，淬炼独属于自己的能力和资源。 123如果你想建立个人品牌，我曾写过一篇“这8种武器点亮程序员的个人品牌”的文章，也许有帮助。如果你想修炼自己的可迁移能力，“转行不必从0开始，7成积累能迁移”可能有点参考意义。另外，有一篇文章“别错把平台当成你的本事”也非常值得阅读。 人脉我们和公司的很多同事，虽然天天见面，却往往只是点点头扯一下嘴角，此外便再无交流，所以，大多数时候，同事是我们最熟悉的陌生人。 而同事，其实是我们可以积攒的最重要的人脉，也是最方便发展的。 很多人创业时，都会寻找以前共事过的、信得过的老同事；很多人离开原公司发展后，遇到合适的机会，也会不自觉地想起老同事中那些与机会匹配的人并主动与他们联系；也有一些人离开公司后，会因为种种原因而和老公司发生业务往来，此时往往是之前关系不错的同事能够促成业务合作的成功；还有一些人会把同事关系延伸到生活中，把同事处成亲密的朋友…… 我们参加工作后，一周7天中的5天，5天中每天最重要的8~9个小时，都是和同事一起度过的。同事真真正正是我们的近邻，应该珍惜这种关系，诚心加以维护，沉淀自己的人脉。 要想从同事关系中沉淀人脉，第一点就是前面讲到的——拥有个人品牌。也就是说，别人想到你时，不是面目模糊的A公司的市场人员（这样你离开A公司就没人记得你了），而是鲜活的善于处理复杂客户关系的张三或最善于开发新客户的李四。这样别人就更容易注意到你，更容易与你交流，也更容易记得你。 独特的个人标签有助于你在众人的心智中占据一席之地，双赢思维则会让你在与同事的交往与协作中变得大受欢迎——因为能做到这点的人实在是太少了，大多数人都是只考虑自己的目标，总是请求别人帮忙完成自己的事情而不考虑给对方“礼物”。所以，如果你能够在与人的交往与协作中，多多考虑对方的目标，做事时能够多多考虑会给对方带来什么影响、能不能帮助对方实现他的目标，这样你将创造更为融洽的关系。 还有一点对于沉淀同事关系也非常重要，那就是——了解你的同事发现他们的特点与喜好。如果你知道天天与你一起工作的同事们的喜好，比如他们喜欢什么信息，喜欢什么运动，有没有小孩子，喜欢哪个明星，那就可以产生工作内容之外的交流，彼此的关系自然就会加深。你身边是不是有这样一两位同事，让你觉得和他们特别谈得来，让你特别愿意和他们聊天呢？你也可以成为这样的同事。 人脉关系，是你在公司的平台上可以发掘的，独属于你的收获，即便你离开了这里，它们依然会伴随着你前进，甚至会在某个人生拐角处突然给你带来意外的惊喜。 兴趣爱好事业、家庭、健康、身心灵，这四个方面组成了一个人的生活，使得每个人的生活都是多元中心的，只有你真正做到多元，做到四象共赢，才会有圆满幸福的人生。 工作是我们获取经济来源的重要手段，也是我们实现自我价值的必经途径，能够对我们的心灵产生重要的影响。然而影响我们心灵的，却不只有工作，我们还当找到另外的滋养心灵的事情，至少一件，可以让你持续去做，持续助益于心灵的事情。 这件事情，应该是这样的：即便没有经济收入，你也一直愿意做下去。这就是你的兴趣所在，是你爱好的事情。 一个人活在世上，必须有自己真正爱好的事情，才会活得有意思。这爱好完全是出于他的真性情，而不是为了某种外在的利益，例如金钱、名声之类。他喜欢做这件事情，只是因为他觉得事情本身非常美好，他被事情的美好所吸引。 如果一个人干的事情恰好是他喜欢的，又能带来可观的收益，养活自己、养活家人，那他真真是幸运儿！ 而多数时候，我们没那么幸运，难免会被挣钱养家这种生活的压力拉扯着做自己不愿意做的事情，难免不快乐。这时我们的心灵难免就会被工作磨损（哪怕是你喜欢的工作，长时间做同一件事也会磨损心灵），我们就特别需要通过另外一件事来保养我们的身心。 是的，保养身心。我们就像一部机器，需要不断地自我修复和保养，否则就会像一直开一直开却从不保养的汽车那样快速报废。 做自己爱好的事情，就是对自己的保养。当你做这样的事情时，能够全身心的投入，享受当下，甚至会体验到心流，这会让你的心灵得到必需的放松、滋养和成长。 希望我们都能在努力工作的同时，葆有自己的一项爱好。当你能够像小王子驯养玫瑰那样投入地去作一件事时，你的生活就会显得特别美好。 被动收入 陷入“工作–薪水–消费–工作–薪水–消费”这种循环会让我们像一个陀螺一样旋转，无法停下来。即便偶尔停下来，也会觉得恐慌。 工资收入的最大特点就是：一旦你停止工作，收入就没有了。所以靠工资，你无法真正摆脱上面的感觉和状态。要想跳脱出来，只有创造你的被动收入。 所谓被动收入，就是你什么事儿也不干也还会不断产生的收入。那么，有哪些形式的被动收入呢？看看这些： 存款 证书 股票 基金 房屋 版税 视频课程 广告位 期货 企业合伙人 怎样才能创造被动收入呢？其实有很多途径，比如： 获得所在公司的股权或股票，像华为、腾讯、阿里的很多员工都有股票分红，有时分红甚至会超过自己的薪水； 克制贪婪和欲望，合理规划收支，保证月有盈余，累积资本。用累积的资本获得信托、股票、基金等资产，进而获得被动收入； 考取建造师、营养师等含金量高的证书，可以托管，每年有不少收入； 购买住宅或商铺用于出租，获得租金； 写作歌词、剧本、小说、专业图书等，获得版权收入； 打造个人博客、个人站点、公众号、头条号等，拥有广告位，赚取广告收入；或者制作视频，获取流量，进而获得广告收入； 汇总你的知识、经验，形成课程，放到在线教育平台上，获得长期销售收入； 通过资金、技术成为企业合伙人； 有很多很多种方法，都可以帮你创造被动收入，放开心中的隐藏假设，多想，多看，多琢磨，你一定会找到途径创造属于你自己的被动收入。当你的被动收入达到一定量级，哪怕你不工作，也可以很好的生活下去。 小结如果你能在工作中积累： 财富 个人品牌 人脉 爱好 能产生被动收入的资产 就能够走出独属于你个人的道路来。但是很多事情说起来容易，做起来是千难万难，所以，最重要是开始，有了第一步，慢慢就会有第二步。就让我们从上面这些要素中挑选一个小小的，小小的点（比如每月拿到薪水先转存1000块到一个雷打不动的账户，比如每天晚上想想今天有什么收获明天要做什么），开始行动吧。 原文链接出自于：https://www.jianshu.com/p/d1f3002c2f5f","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"职业规划","slug":"职业规划","permalink":"http://www.devcheng.net/tags/职业规划/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"oracle中for update和for update nowait的区别","slug":"oracle中for-update和for-update-nowait的区别","date":"2019-03-30T10:35:31.000Z","updated":"2020-01-04T04:01:18.168Z","comments":true,"path":"post/c86dda7a.html","link":"","permalink":"http://www.devcheng.net/post/c86dda7a.html","excerpt":"","text":"前言首先一点，如果只是select 的话，Oracle是不会加任何锁的，也就是Oracle对 select 读到的数据不会有任何限制，虽然这时候有可能另外一个进程正在修改表中的数据，并且修改的结果可能影响到你目前select语句的结果，但是因为没有锁，所以select结果为当前时刻表中记录的状态。 如果加入了for update， 则Oracle一旦发现（符合查询条件的）这批数据正在被修改，则不会发出该select语句查询，直到数据被修改结束（被commit），马上自动执行这个select语句。 同样，如果该查询语句发出后，有人需要修改这批数据（中的一条或几条），它也必须等到查询结束后（commit）后，才能修改。 for update nowait和 for update 都会对所查询到得结果集进行加锁，所不同的是，如果另外一个线程正在修改结果集中的数据， for update nowait 不会进行资源等待，只要发现结果集中有些数据被加锁，立刻返回 “ORA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源”。 for update 和 for update nowait 加上的是一个行级锁，也就是只有符合where条件的数据被加锁。如果仅仅用update语句来更改数据时，可能会因为加不上锁而没有响应地、莫名其妙地等待，但如果在此之前，for update NOWAIT语句将要更改的数据试探性地加锁，就可以通过立即返回的错误提示而明白其中的道理，或许这就是For Update和NOWAIT的意义之所在。 经过测试，以for update 或 for update nowait方式进行查询加锁，在select的结果集中，只要有任何一个记录在加锁，则整个结果集都在等待系统资源（如果是nowait，则抛出相应的异常）。 for update nowait 与 for update 的目的锁定表的所有行，排斥其他针对这个表的写操作。确保只有当前事务对指定表进行写操作。 for update nowait和 for update的区别别的事务要对这个表进行写操作时，是等待一段时间还是马上就被数据库系统拒绝而返回.制定采用nowait方式来进行检索，所以当发现数据被别的session锁定中的时候，就会迅速返回ORA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源。 所以在程序中我们可以采用nowait方式迅速判断当前数据是否被锁定中，如果锁定中的话，就要采取相应的业务措施进行处理。如何理解上面的话. 开启一会话 (就是开一个sqlwindow)select empno,ename from emp where empno=’7369’ for update nowait ; 得到下面结果集: empno ename 7369 smith开启另一会话select empno,ename from emp where empno=’7369’ for update nowait ;返回RA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源 上面会话都提交commit; 1234567891011开启一会话, select empno,ename from emp where empno=&apos;7369&apos; for update ; 得到下面结果集: empno ename 7369 smith 开启另一会话 select empno,ename from emp where empno=&apos;7369&apos; for update;阻塞，不返回错误。 提交第一个会话，第二个回话自动执行 提交第二个会话 for update: 当第一个session最后commit或者rollback之后，第二个session中的检索结果就是自动跳出来，并且也把数据锁定住. 开启一会话：select empno,ename from emp where empno=”7369” for update；得到下面结果集: empno ename 7369 smith 开启另一个会话， pdate emp set ename=’ALLEN’ where empno=”7396”; 阻塞。提交第一个会话， update 语句执行再开启一会话update emp set ename=”SMITH” where empno=’7396’;同样阻塞，虽然第一个会话因为提交而释放了锁，但是第二个会话中的update 又给这一行加锁了; for update nowait:当你第一个session放开锁定以后,第二个session才能正常运行。当你第二个session语句运行后，数据又被你第二个session语句锁定住了，这个时候只要你第二个session语句后还没有commit，别的session照样不能对数据进行锁定更新等等。 对比区别：select * from TTable for update 锁定表的所有行，只能读不能写 select * from TTable1 where pkid = 1 for update 只锁定pkid=1的行 select * from Table1 a join Table2 b on a.pkid=b.pkid for update 锁定两个表的所有记录 select * from Table1 a join Table2 b on a.pkid=b.pkid where a.pkid = 10 for update 锁定两个表的中满足条件的行 select * from Table1 a join Table2 b on a.pkid=b.pkid where a.pkid = 10 for update of a.pkid 只锁定Table1中满足条件的行 for update 是把所有的表都锁点 for update of 根据of 后表的条件锁定相对应的表 关于NOWAIT(如果一定要用FOR UPDATE，我更建议加上NOWAIT) 当有LOCK冲突时会提示错误并结束STATEMENT而不是在那里等待(比如:要查的行已经被其它事务锁了,当前的锁事务与之冲突,加上nowait,当前的事务会结束会提示错误并立即结束 STATEMENT而不再等待). 如果加了for update后 该语句用来锁定特定的行（如果有where子句，就是满足where条件的那些行）。当这些行被锁定后，其他会话可以选择这些行，但不能更改或删除这些行，直到该语句的事务被commit语句或rollback语句结束为止。 因为FOR UPDATE子句获得了锁，所以COMMIT将释放这些锁。当锁释放了，该游标就无效了。就是这些区别了关于oracle中的select…for update of columns 问题，如下：select * from emp where empno = 7369 for update; 会对表中员工编号为7369的记录进行上锁。其他用户无法对该记录进行操作，只能查询。 select * from emp where empno = 7369 for update of sal;这条语句是不是意味着只对表中的7369 这一行的sal字段的数据进行了上锁，其他数据则可以被其他用户做更新操作呢。学员测试结果为二条语句的效果是一样的。其他用户对整行都无法更新，那么是不是意味着 for update of columns这句没有什么意义呢？ 从单独一张表的操作来看，上面二条语句的效果确实是相同的。但是如果涉及到多表操作的时候 for update of columns就起到了非常大的作用了。现假定有二个用户，scott和mm , scott执行语句：select from emp e,dept d where e.deptno = d.deptno for update; –对二张表都进行了整表锁定mm执行语句：select from scott.dept for update wait 3; –试图锁定scott用户的dept表 结果是： ERROR 位于第 1 行: ORA-30006: 资源已被占用; 执行操作时出现 WAIT 超时现在，scott用户先进行解锁rollback,再在for update语句后面加上of columns，进行测试 scott执行语句：select from emp e,dept d where e.deptno = d.deptno for update of sal ; mm执行语句：select from scott.dept for update wait 3; 结果是： 成功锁定了dept表的数据.mm再次执行语句：select * from scott.emp for update wait 3;结果是： ERROR 位于第 1 行: ORA-30006: 资源已被占用; 执行操作时出现 WAIT 超时 通过这段代码案例，我们可以得到结论，for update of columns 用在多表连接锁定时，可以指定要锁定的是哪几张表，而如果表中的列没有在for update of 后面出现的话，就意味着这张表其实并没有被锁定，其他用户是可以对这些表的数据进行update操作的。这种情况经常会出现在用户对带有连接查询的视图进行操作场景下。用户只锁定相关表的数据，其他用户仍然可以对视图中其他原始表的数据来进行操作。 Oracle 的for update行锁 SELECT…FOR UPDATE 语句的语法如下： SELECT … FOR UPDATE [OF column_list][WAIT n|NOWAIT][SKIP LOCKED];其中： OF 子句用于指定即将更新的列，即锁定行上的特定列。WAIT 子句指定等待其他用户释放锁的秒数，防止无限期的等待。 “使用FOR UPDATE WAIT”子句的优点如下：１防止无限期地等待被锁定的行；２允许应用程序中对锁的等待时间进行更多的控制。３对于交互式应用程序非常有用，因为这些用户不能等待不确定４若使用了skip locked，则可以越过锁定的行，不会报告由wait n 引发的‘资源忙’异常报告 示例:create table t(a varchar2(20),b varchar2(20));insert into t values(‘1’,’1’);insert into t values(‘2’,’2’);insert into t values(‘3’,’3’);insert into t values(‘4’,’4’); 现在执行如下操作：在plsql develope中打开两个sql窗口，在1窗口中运行sql select * from t where a=’1’ for update;在2窗口中运行sql1 select * from t where a=’1’;这一点问题也没有，因为行级锁不会影响纯粹的select语句 再运行sql2 select * from t where a=’1’ for update;则这一句sql在执行时，永远处于等待状态，除非窗口1中sql被提交或回滚。如何才能让sql2不等待或等待指定的时间呢？ 我们再运行sql3 select from t where a=’1’ for update nowait; 则在执行此sql时，直接报资源忙的异常。若执行 select from t where a=’1’ for update wait 6; 则在等待6秒后，报 资源忙的异常。 如果我们执行sql4 select * from t where a=’1’ for update nowait skip Locked; 则执行sql时，即不等待，也不报资源忙异常。 现在我们看看执行如下操作将会发生什么呢？ 在窗口1中执行： select * from t where rownum&lt;=3 nowait skip Locked; 在窗口2中执行： select * from t where rownum&lt;=6 nowait skip Locked; select for update 也就如此了吧，insert、update、delete操作默认加行级锁，其原理和操作与select for update并无两样。 select for update of，这个of子句在牵连到多个表时，具有较大作用，如不使用of指定锁定的表的列，则所有表的相关行均被锁定，若在of中指定了需修改的列，则只有与这些列相关的表的行才会被锁定。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"for update","slug":"for-update","permalink":"http://www.devcheng.net/tags/for-update/"},{"name":"oracle","slug":"oracle","permalink":"http://www.devcheng.net/tags/oracle/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Java阻塞队列(BlockingQueue)","slug":"Java阻塞队列-BlockingQueue","date":"2019-03-23T03:54:58.000Z","updated":"2020-01-04T04:00:55.433Z","comments":true,"path":"post/faee62e7.html","link":"","permalink":"http://www.devcheng.net/post/faee62e7.html","excerpt":"","text":"前言 在新增的Concurrent包中，BlockingQueue很好的解决了多线程中，如何高效安全“传输”数据的问题。 通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利。 本文详细介绍了BlockingQueue家庭中的所有成员，包括他们各自的功能以及常见使用场景。 认识BlockingQueue阻塞队列，顾名思义，首先它是一个队列，而一个队列在数据结构中所起的作用大致如下图所示： 从上图我们可以很清楚看到，通过一个共享的队列，可以使得数据由队列的一端输入，从另外一端输出；常用的队列主要有以下两种：（当然通过不同的实现方式，还可以延伸出很多不同类型的队列，DelayQueue就是其中的一种） 先进先出（FIFO）：先插入的队列的元素也最先出队列，类似于排队的功能。从某种程度上来说这种队列也体现了一种公平性。后进先出（LIFO）：后插入队列的元素最先出队列，这种队列优先处理最近发生的事件。 多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和“消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。假设我们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地解决他们之间的数据共享问题。但如果生产者和消费者在某个时间段内，万一发生数据处理速度不匹配的情况呢？理想情况下，如果生产者产出数据的速度大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的数据处理完毕，反之亦然。然而，在concurrent包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。好在此时，强大的concurrent包横空出世了，而他也给我们带来了强大的BlockingQueue。（在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒）下面两幅图演示了BlockingQueue的两个常见阻塞场景： 如上图所示：当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。 如上图所示：当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。这也是我们在多线程环境下，为什么需要BlockingQueue的原因。作为BlockingQueue的使用者，我们再也不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切BlockingQueue都给你一手包办了。既然BlockingQueue如此神通广大，让我们一起来见识下它的常用方法： BlockingQueue的核心方法： 放入数据： offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.（本方法不阻塞当前执行方法的线程） offer(E o, long timeout, TimeUnit unit),可以设定等待的时间，如果在指定的时间内，还不能往队列中加入BlockingQueue，则返回失败。 put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续。 获取数据： poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null; poll(long timeout, TimeUnit unit)：从BlockingQueue取出一个队首的对象，如果在指定时间内,队列一旦有数据可取，则立即返回队列中的数据。否则知道时间超时还没有数据可取，返回失败。 take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到BlockingQueue有新的数据被加入; drainTo():一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个数）,通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。 常见BlockingQueue 在了解了BlockingQueue的基本功能后，让我们来看看BlockingQueue家庭大致有哪些成员？ BlockingQueue成员详细介绍 ArrayBlockingQueue 基于数组的阻塞队列实现，在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。 ArrayBlockingQueue在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。 ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。而在创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。 LinkedBlockingQueue 基于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。 ArrayBlockingQueue和LinkedBlockingQueue是两个最普通也是最常用的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个类足以。 下面的代码演示了如何使用BlockingQueue： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115public class Producer implements Runnable &#123; private volatile boolean isRunning = true; private BlockingQueue queue; private static AtomicInteger count = new AtomicInteger(); private static final int DEFAULT_RANGE_FOR_SLEEP = 1000; public Producer(BlockingQueue queue) &#123; this.queue = queue; &#125; public void run() &#123; String data = null; Random r = new Random(); System.out.println(\"启动生产者线程！\"); try &#123; while (isRunning) &#123; System.out.println(\"正在生产数据...\"); Thread.sleep(r.nextInt(DEFAULT_RANGE_FOR_SLEEP)); data = \"data:\" + count.incrementAndGet(); System.out.println(\"将数据：\" + data + \"放入队列...\"); if (!queue.offer(data, 2, TimeUnit.SECONDS)) &#123; System.out.println(\"放入数据失败：\" + data); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); Thread.currentThread().interrupt(); &#125; finally &#123; System.out.println(\"退出生产者线程！\"); &#125; &#125; public void stop() &#123; isRunning = false; &#125; &#125; /** * 消费者线程 * * */public class Consumer implements Runnable &#123; private BlockingQueue&lt;String&gt; queue; private static final int DEFAULT_RANGE_FOR_SLEEP = 1000; public Consumer(BlockingQueue&lt;String&gt; queue) &#123; this.queue = queue; &#125; public void run() &#123; System.out.println(\"启动消费者线程！\"); Random r = new Random(); boolean isRunning = true; try &#123; while (isRunning) &#123; System.out.println(\"正从队列获取数据...\"); String data = queue.poll(2, TimeUnit.SECONDS); if (null != data) &#123; System.out.println(\"拿到数据：\" + data); System.out.println(\"正在消费数据：\" + data); Thread.sleep(r.nextInt(DEFAULT_RANGE_FOR_SLEEP)); &#125; else &#123; // 超过2s还没数据，认为所有生产线程都已经退出，自动退出消费线程。 isRunning = false; &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); Thread.currentThread().interrupt(); &#125; finally &#123; System.out.println(\"退出消费者线程！\"); &#125; &#125; &#125;/** * 测试类 */public class BlockingQueueTest &#123; public static void main(String[] args) throws InterruptedException &#123; // 声明一个容量为10的缓存队列 BlockingQueue&lt;String&gt; queue = new LinkedBlockingQueue&lt;String&gt;(10); Producer producer1 = new Producer(queue); Producer producer2 = new Producer(queue); Producer producer3 = new Producer(queue); Consumer consumer = new Consumer(queue); // 借助Executors ExecutorService service = Executors.newCachedThreadPool(); // 启动线程 service.execute(producer1); service.execute(producer2); service.execute(producer3); service.execute(consumer); // 执行10s Thread.sleep(10 * 1000); producer1.stop(); producer2.stop(); producer3.stop(); Thread.sleep(2000); // 退出Executor service.shutdown(); &#125;&#125; DelayQueue DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。使用场景： DelayQueue使用场景较少，但都相当巧妙，常见的例子比如使用一个DelayQueue来管理一个超时未响应的连接队列。 PriorityBlockingQueue 基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，内部控制线程同步的锁采用的是公平锁。 SynchronousQueue 一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么对不起，大家都在集市等待。相对于有缓冲的BlockingQueue来说，少了一个中间经销商的环节（缓冲区），如果有经销商，生产者直接把产品批发给经销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式会吞吐量高一些（可以批量买卖）；但另一方面，又因为经销商的引入，使得产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能可能会降低。 声明一个SynchronousQueue有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别: 如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO队列来阻塞多余的生产者和消费者，从而体系整体的公平策略； 但如果是非公平模式（SynchronousQueue默认）：SynchronousQueue采用非公平锁，同时配合一个LIFO队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。 小结 BlockingQueue不光实现了一个完整队列所具有的基本功能，同时在多线程环境下，他还自动管理了多线间的自动等待于唤醒功能，从而使得程序员可以忽略这些细节，关注更高级的功能。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"BlockingQueue","slug":"BlockingQueue","permalink":"http://www.devcheng.net/tags/BlockingQueue/"},{"name":"Java阻塞队列","slug":"Java阻塞队列","permalink":"http://www.devcheng.net/tags/Java阻塞队列/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Intellij IDEA使用@Autowired 注解标红报错解决办法","slug":"Intellij-IDEA使用-Autowired-注解标红报错解决办法","date":"2019-03-14T14:17:08.000Z","updated":"2020-01-04T04:00:15.769Z","comments":true,"path":"post/2af67ce4.html","link":"","permalink":"http://www.devcheng.net/post/2af67ce4.html","excerpt":"","text":"背景在项目里面使用@Autowired注解，进行bean 注入的时候，通常都会标红。如下图： 究其原因就是，Spring bean通过@Autowired注入，spring auto scan配置，在编辑情况下，无法找不到对应的bean，于是提示找不到对应bean的错误。 但是以上标红 build 完成后项目仍可以运行。 解决方法一降低Autowired检测的级别，将Severity的级别由之前的error改成warning或其它可以忽略的级别。具体操作如图: 解决方法二使用 @Resource 注解 两种方法都可以解决这个问题，自行选择即可！ 关于@Autowired和@Resource的区别请点击 @Autowired和@Resource的区别","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Autowired","slug":"Autowired","permalink":"http://www.devcheng.net/tags/Autowired/"},{"name":"Intellij IDEA","slug":"Intellij-IDEA","permalink":"http://www.devcheng.net/tags/Intellij-IDEA/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"如何使用Java打印项目目录结构","slug":"如何使用Java打印项目目录结构","date":"2019-03-13T14:10:19.000Z","updated":"2020-01-04T04:04:24.097Z","comments":true,"path":"post/7a0df1b9.html","link":"","permalink":"http://www.devcheng.net/post/7a0df1b9.html","excerpt":"","text":"背景看见很多代码在GITHUB上都有项目的目录结构，想要介绍一个项目各个包的内容，但又不想手敲目录结构，于是写了个工具类生成目录结构。 可配置项1.忽略文件夹：可以忽略一个或多个文件夹；2.文件夹折叠开关：连续的空文件夹会被默认打印成包名，但可以通过开关打开和关闭；3.是否生成文件：考虑到多数情况只需要生成目录不需要生成具体文件，所以有这个开关，控制是否打印文件。 效果图 源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package com.lvoyee.esblog.utils;import org.apache.commons.lang.StringUtils;import java.io.File;import java.io.FileNotFoundException;import java.util.Arrays;import java.util.HashSet;import java.util.Set;/** * @author: luo_yun * @date: 2019/3/13 19:57 * @description: */public class PackageGenerator &#123; private final static String[] TABS = new String[]&#123;\"└── \", \"├── \", \"│ \", \" \"&#125;; public static String generate(String rootDir) throws Exception &#123; return generate(rootDir, new HashSet&lt;&gt;(), true, false); &#125; public static String generate(String rootDir, Boolean packageCollapse) throws Exception &#123; return generate(rootDir, new HashSet&lt;&gt;(), packageCollapse, false); &#125; public static String generate(String rootDir, Set&lt;String&gt; ignoreDirs) throws Exception &#123; return generate(rootDir, ignoreDirs, true, false); &#125; /** * all directories and files of a specific path * * @param rootDir root dir * @param ignoreDirs a set of dir to ignore. * if parent ignored, all children will be ignored too * @param packageCollapse if true, empty packages will fold to java package name. * like IntelliJ IDEA project outline(default, not flatten packages mode) * default true * @param generateFile if true, file will be generated, otherwise only directory will be generated * default false * @return formatted outline string * @throws Exception */ public static String generate(String rootDir, Set&lt;String&gt; ignoreDirs, Boolean packageCollapse, Boolean generateFile) throws Exception &#123; if (StringUtils.isBlank(rootDir)) &#123; throw new NullPointerException(\"null root dir!\"); &#125; File file = new File(rootDir); if (!file.exists()) &#123; throw new FileNotFoundException(\"root dir not exists!\"); &#125; if (!file.isDirectory()) &#123; throw new IllegalArgumentException(\"root dir is not a directory!\"); &#125; StringBuilder stringBuilder = new StringBuilder(file.getName()); generateChildren(file, stringBuilder, \"\", ignoreDirs, packageCollapse, generateFile); return stringBuilder.toString(); &#125; /** * generate directory structure with recursive function * * @param file dir to generate * @param stringBuilder outer string builder for * @param level depth of file or directory which determines how many blanks to display before this file or directory * @param ignoreDirs a set of dir to ignore * @param packageCollapse if true, empty packages will fold to java package name */ private static void generateChildren(File file, StringBuilder stringBuilder, String level, Set&lt;String&gt; ignoreDirs, Boolean packageCollapse, Boolean generateFile) &#123; File[] childes = file.listFiles(); if (childes == null) &#123; return; &#125; int lastDirIndex = lastDirIndex(childes, ignoreDirs, generateFile); int dirCnt = dirCnt(childes, ignoreDirs, generateFile); if (lastDirIndex &gt;= 0) &#123; if (dirCnt == 1) &#123; if (packageCollapse &amp;&amp; childes[lastDirIndex].isDirectory()) &#123; stringBuilder.append(\".\").append(childes[lastDirIndex].getName()); generateChildren(childes[lastDirIndex], stringBuilder, level, ignoreDirs, packageCollapse, generateFile); return; &#125; else &#123; stringBuilder.append(\"\\n\").append(level).append(TABS[0]).append(childes[lastDirIndex].getName()); generateChildren(childes[lastDirIndex], stringBuilder, level + TABS[3], ignoreDirs, packageCollapse, generateFile); return; &#125; &#125; for (int i = 0; i &lt; childes.length; i++) &#123; if ((childes[i].isDirectory() &amp;&amp; !ignoreDirs.contains(childes[i].getName())) || generateFile) &#123; stringBuilder.append(\"\\n\").append(level); if (i == lastDirIndex) &#123; stringBuilder.append(TABS[0]).append(childes[i].getName()); generateChildren(childes[i], stringBuilder, level + (TABS[3]), ignoreDirs, packageCollapse, generateFile); &#125; else &#123; stringBuilder.append(TABS[1]).append(childes[i].getName()); generateChildren(childes[i], stringBuilder, level + (TABS[2]), ignoreDirs, packageCollapse, generateFile); &#125; &#125; &#125; &#125; &#125; private static int dirCnt(File[] childes, Set&lt;String&gt; ignoreDirs, Boolean generateFile) &#123; int cnt = 0; if (childes == null || childes.length == 0) &#123; return cnt; &#125; for (int i = 0; i &lt; childes.length; i++) &#123; if ((childes[i].isDirectory() &amp;&amp; !ignoreDirs.contains(childes[i].getName())) || generateFile) &#123; cnt++; &#125; &#125; return cnt; &#125; private static int lastDirIndex(File[] childes, Set&lt;String&gt; ignoreDirs, Boolean generateFile) &#123; int index = -1; if (childes == null || childes.length == 0) &#123; return index; &#125; for (int i = 0; i &lt; childes.length; i++) &#123; if ((childes[i].isDirectory() &amp;&amp; !ignoreDirs.contains(childes[i].getName())) || generateFile) &#123; index = i; &#125; &#125; return index; &#125; public static void main(String args[]) throws Exception &#123; System.out.print(generate(System.getProperty(\"user.dir\") + \"/src/main/java\", new HashSet&lt;&gt;(Arrays.asList(\".idea\", \"target\", \".git\")), true, true)); System.out.println(\"\\n\\n------------------------------------------------\\n\"); System.out.print(generate(System.getProperty(\"user.dir\") + \"/src/main/java\", new HashSet&lt;&gt;(Arrays.asList(\".idea\", \"target\", \".git\")), false, false)); &#125;&#125; 有需要的可以直接赋值以上代码，放在自己项目里面充当一个工具类即可！","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.devcheng.net/tags/Java/"},{"name":"目录结构","slug":"目录结构","permalink":"http://www.devcheng.net/tags/目录结构/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"不寻常的String To Map的转换","slug":"不寻常的String-To-Map的转换","date":"2019-03-01T14:23:24.000Z","updated":"2020-01-04T04:03:08.736Z","comments":true,"path":"post/1c93cf.html","link":"","permalink":"http://www.devcheng.net/post/1c93cf.html","excerpt":"","text":"前言在一般的情况下，Java中字符串转Map需要确定一点，待转的字符串是不是json格式的，如果是json格式的则容易处理的多了，直接用Gson 或是 FastJSON 等就可以处理了。 正文那另外一种情况如果需要转的字符串 不是 json 格式的那怎么办呢？举个例子，需要转的字符串是以下这种：1id:1|age:27|name:test|sex:1 以上这样的字符串，那就需要你使用 String中的 split 方法进行分割，然后变成Map既可！ 在说一种情况，由于工作里面碰见的特此也记录一下！我遇到的需要把字符串转Map的字符串是这样的格式：1&#123;id=1,age=2,name=test&#125; 但是有一种特殊的情况，可能里面的一些字段没有值，最后可能需要处理的字符串则变成了这样： 1&#123;id=1,age=,name=&#125; 那这样的情况怎么做呢？ 网上大多数给出的代码的是以下这样的：1234567String str = \"&#123;id=1,age=,name=test&#125;\";String[] strs = str.split(\"=\");Map&lt;String, String&gt; m = new HashMap&lt;String, String&gt;();for(String s:strs)&#123;String[] ms = s.split(\":\"); m.put(ms[0], ms[1]);&#125; 思路是对的，可是面对这样 key=value 且 value 可能没有值得情况，代码是用不了的。原因是就是在分割字符串之后，给map 复制的那句 m.put(ms[0], ms[1]) 这里 ms[1] ，如果分割出来的字段是 age= 没有value 的 那么 ms[1] ,就会报一个 异常，数组越界异常。 根据以上代码则需要做一个特殊的处理，在给map 复制的时候需要判断一下被分割出来的 String[] ms = s.split(“:”); ms 里面有几个元素， 然后根据元素的最大下标去判断。 直接看 特殊处理后的代码： 123456789101112131415161718192021222324252627private static Map&lt;String,Object&gt; getStringToMap(String str)&#123; if (str.startsWith(\"&#123;\")) &#123; str = str.substring(1, str.length()); &#125; if (str.endsWith(\"&#125;\")) &#123; str = str.substring(0, str.length() - 1); &#125; //根据逗号截取字符串数组 String[] str1 = str.split(\",\"); //创建Map对象 Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //循环加入map集合 for (int i = 0; i &lt; str1.length; i++) &#123; //根据\":\"截取字符串数组 String[] str2 = str1[i].split(\"=\"); //str2[0]为KEY,str2[1]为值 // str2.length-1 为下标最大值 if(str2.length-1 == 0)&#123; map.put(str2[0].trim(),\"\"); &#125;else&#123; map.put(str2[0].trim(),str2[1].trim()); &#125; &#125; return map;&#125; 以上代码，就可以 适用于字符串里面的key和value都存在或是key有而value没有值的场景！如下两种字符串实例：1&#123;id=1,age=,name=test&#125; 1&#123;id=1,age=27,name=test&#125; 写到这里，你也许看明白了这个不寻常的字符串就是，value可能没有值的时候转Map的特殊处理，原理就是在给Map赋值的时候使用分割后获取的String []数组的最大下标作文章，从而判断value是否有值，有值的时候取两个元素，没有则给个默认的空字符串。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"String转Map","slug":"String转Map","permalink":"http://www.devcheng.net/tags/String转Map/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"ElasticSearch-实战代码3","slug":"ElasticSearch-实战代码3","date":"2019-02-26T14:17:18.000Z","updated":"2020-01-04T03:59:51.209Z","comments":true,"path":"post/5d047910.html","link":"","permalink":"http://www.devcheng.net/post/5d047910.html","excerpt":"","text":"前言学习了几天ElasticSearch，简单的做了一个实战项目，把学习过程中的各个用法简单的在项目里面体现出来。 开发环境IntelliJ IDEA , JDK 1.8 ElasticSearch版本5.6.2 前端页面模块采用的是 闲言轻博客模板 （https://fly.layui.com/store/layuiXianyan/） 技术栈spring boot , elasticSearch , layui …为了让大家更加直观的看见本项目中使用的版本，直接把项目里面的pom.xml 文件给提供出来！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.lvoyee&lt;/groupId&gt; &lt;artifactId&gt;esblog&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;esblog&lt;/name&gt; &lt;description&gt;lvoyee_es_blog&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--&lt;thymeleaf.version&gt;3.0.2.RELEASE&lt;/thymeleaf.version&gt; &lt;thymeleaf-layout-dialect.version&gt;2.1.1&lt;/thymeleaf-layout-dialect.version&gt;--&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt; &lt;artifactId&gt;transport-netty3-client&lt;/artifactId&gt; &lt;version&gt;5.6.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.commons/commons-lang3 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.7&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 代码结构截图 项目运行截图首页 登录 文章详情 已经完成的功能1.登录2.首页3.文章显示4.点赞5.关于 未完成的功能1.退出2.留言3.搜索 项目如何启动在启动项目之前，务必需要安装好了 elasticsearch,必要的环境细节不多赘述了。 1.找到 elasticsearch 的bin目录下面的 elasticsearch.bat2.启动 grunt servet3.找到项目的 EsblogApplication 启动即可 访问 http://localhost:8080 mapping结构关于的mapping12345678910111213141516171819202122&#123; &quot;mappings&quot;: &#123; &quot;about&quot;: &#123; &quot;dynamic&quot;: false, &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;num&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &#125;, &quot;likenum&quot;:&#123; &quot;type&quot;:&quot;integer&quot; &#125; &#125; &#125; &#125;&#125; 登录用户的mapping12345678910111213141516171819202122&quot;mappings&quot;: &#123; &quot;user&quot;: &#123; &quot;properties&quot;: &#123; &quot;password&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;nickName&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;sex&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;userName&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;createDate&quot;: &#123; &quot;format&quot;: &quot;yyyy-MM-dd || epoch_millis&quot;, &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125;&#125; 文章的mapping12345678910111213141516171819202122232425&#123; &quot;mappings&quot;:&#123; &quot;article&quot;:&#123; &quot;properties&quot;:&#123; &quot;like&quot;:&#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;author&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;title&quot;:&#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;content&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;publish_date&quot;:&#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd || epoch_millis&quot; &#125; &#125; &#125; &#125;&#125; 小结在这个项目中所有的后台功能都是基于elasticsearch 做的，目的就是为了学习如何用 elasticsearch 做数据的 CURD,仅此而已。 还有一些未完成的功能，希望看了我写的代码可以自行学习补加完成，该项目本着学习 elasticsearch 的使用制作而成，多又瑕疵，还望多多包涵。 需要源码的小伙伴，可以加入QQ群领取即可！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://www.devcheng.net/tags/ElasticSearch/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"ElasticSearch-实战代码2","slug":"ElasticSearch-实战代码2","date":"2019-02-24T10:20:37.000Z","updated":"2020-01-04T03:59:36.944Z","comments":true,"path":"post/2a034986.html","link":"","permalink":"http://www.devcheng.net/post/2a034986.html","excerpt":"","text":"前言ElasticSearch提供Json格式的基于HTTP的RESTful API，可通过CURL命令直接请求，也能非常简便的在任何编程语言中使用，官方提供的常用语言客户端可在 https://www.elastic.co/guide/en/elasticsearch/client/index.html 查询下载。 接口请求请求格式：1curl -X &lt;VERB&gt; &apos;&lt;PROTOCOL&gt;://&lt;HOST&gt;:&lt;PORT&gt;/&lt;PATH&gt;?&lt;QUERY_STRING&gt;&apos; -d &apos;&lt;BODY&gt;&apos; 参数 说明 VERB HTTP方法 : GET、 POST、 PUT、 HEAD 或者 DELETE PROTOCOL http 或者 https HOST 集群中任意节点的主机名 PORT 端口号，默认是 9200 PATH API 的终端路径 QUERY_STRING 任意可选的查询字符串参数 BODY JSON格式的请求体 (如果需要) 请求示例：123456curl -X GET &apos;http://localhost:9200/_count?pretty&apos; -d &apos;&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 接口响应Elasticsearch接口返回一个HTTP状态码（如：200 OK）和一个JSON格式的返回值（HEAD请求除外）。上面的CURL请求将返回一个像下面一样的 JSON 体：123456789&#123; &quot;count&quot; : 0, &quot;_shards&quot; : &#123; &quot;total&quot; : 0, &quot;successful&quot; : 0, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;&#125; 如需显示状态码可以使用curl命令的-i参数。 ElasticSearch存储结构与概念文档 DocumentElasticsearch是面向文档的，使用JSON作为序列化格式存储整个对象。user对象文档示例如下：1234567891011&#123; &quot;email&quot;: &quot;john@smith.com&quot;, &quot;first_name&quot;: &quot;John&quot;, &quot;last_name&quot;: &quot;Smith&quot;, &quot;info&quot;: &#123; &quot;bio&quot;: &quot;Eco-warrior and defender of the weak&quot;, &quot;age&quot;: 25, &quot;interests&quot;: [ &quot;dolphins&quot;, &quot;whales&quot; ] &#125;, &quot;join_date&quot;: &quot;2014/05/01&quot;&#125; 实际存储的文档还包含文档的元数据，元数据中的常见元素： 元素 说明 _index 文档在哪个索引存放 _type 文档对象类型 _id 文档唯一标识 _version 数据版本 注意：Type只是Index中的虚拟逻辑分组，不同的Type应该有相似的结构。6.x版只允许每个Index包含一个Type，7.x 版将会彻底移除 Type。 索引 Index索引（Index）在ElasticSearch中是多义词：1、类似数据库概念的存储文档集合的地方叫做索引（名词）2、存储数据到Elasticsearch的行为也叫做索引（动词）3、为了提升数据检索速度使用的倒排索引结构ElasticSearch默认给索引(1)中每个文档的每个属性建立倒排索引(3)使之可以被快速检索。 节点 Node、集群 Cluster和分片 ShardsElasticSearch是分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个实例。单个实例称为一个节点（node），一组节点构成一个集群（cluster）。分片是底层的工作单元，文档保存在分片内，分片又被分配到集群内的各个节点里，每个分片仅保存全部数据的一部分。 Elasticsearch 关键字与SQL关键字对比总结由于Elasticsearch和MongoDB/Redis/Memcache一样，是非关系型数据库。而平常使用的MySql，Oracle，SQLServer 等为关系型数据库，二者有着本质的区别，Es查询语句使用的是DSL语言，关系式数据库使用的是T-SQL，虽然语言不同，但是有时候，一些功能还是有些相似的，为此，整理了一些ES与 关系型数据库中的功能关键字做一下对比。 SQL关键字 Elastsearch 关键字 说明 DataBase Index 数据库名称 Table type 表名称 Row Document 文档 Column Field 字段 T-SQL Query DSL _source 返回指定的列 SELECT * FROM table GET http://… 从……中查询 UPDATE table SET PUT http://… 从……中更新 Where Query 查询范围 ORDER BY Sort 升序ASC、倒序Desc相同 = term 判断等值，精确值查找，用它处理数字（numbers）、布尔值（Booleans）、日期（dates）以及文本（text） In terms 限定一定范围 Not NULL exists IS NULL missing range 限定查询范围，可用于数值或者日期限定 &gt; gt &lt; lt &gt;= gte &lt;= lte bool 组合过滤器 AND must 必须包含 NOT must_not 不能包含 OR should 至少有一个匹配 TOP size 指定返回多少条，ES默认是10条，搭配From可以实现翻页效果 collapse 字段折叠 Join inner_hits 嵌套子查询 结语现在，你已经基本了解ElasticSearch简单概念了，但请不要止步于此；ElasticSearch有着深刻的内涵和丰富的功能等待着你去发现，官方文档是最新最全最好的学习材料了，需要的点击https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 参考链接 : https://www.cnblogs.com/softidea/p/6119354.html","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://www.devcheng.net/tags/ElasticSearch/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"ElasticSearch-实战代码1","slug":"ElasticSearch-实战代码1","date":"2019-02-16T07:32:31.000Z","updated":"2020-01-04T03:59:26.381Z","comments":true,"path":"post/b30a183c.html","link":"","permalink":"http://www.devcheng.net/post/b30a183c.html","excerpt":"","text":"1 安装安装环境 window10 安装目标 ElasticSearch 5.6.2 2 下载ElasticSearch 5.6.2到ES对应的官网下载即可，下载64位（与操作系统一致）解压放在自己学的盘符里。 3 安装node,npm百度下载node，下载64的等待下载完成会是一个.msi文件。 tips: 在windows10中如果双击安装不成功，提示:the installer has encountered an unexpected error installing this package.this may indicate a problem with package.the error code is 2502. 的时候，具体解决方法请戳这个链接。https://jingyan.baidu.com/article/59a015e34f4870f79488652e.html 简洁的说就是把下载的这个 .msi文件，使用cmd 管理员运行找到这个文件的路径 去运行即可安装成功。 安装成功之后,查看 node npm 的版本即可1node -v 1npm -v 4 安装gruntnode , npm 安装成功之后，使用如下命令1npm install -g grunt -cli 执行完毕之后，使用命令查看版本1grunt -version 5 下载 es-heades-head 版本： 2.6 https://github.com/mobz/elasticsearch-head 下载zip,解压到自己的盘 修改点1 找到目录 head/Gruntfile.js： 12345678910connect: &#123; server: &#123; options: &#123; port: 9100, hostname: &apos;*&apos;, // 添加这句 base: &apos;.&apos;, keepalive: true &#125; &#125;&#125; 修改点2 找到目录 head/_site/app.js 1this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://localhost:9200&quot;; 把localhost修改成你es的服务器地址， 如果这里 你就是本地学习的，这一步就用改就是这样既可。 6 修改ElasticSearch的配置 修改点1 找到目录 config/elasticsearch.yml 在配置文件末尾追加如下内容：1234567891011121314# 增加新的参数，这样head插件可以访问eshttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;``` 注意： yml文件设置参数的时候:后面要有一个空格！- 修改点2 操作完 修改点1之后 也在文件后 追加以下内容：``` cluster.name: Lvoyeenode.name: masternode.master: truenetwork.host: 127.0.0.1 7 安装es-head 插件找到你放 es-head 的目录下，使用命令 npm install 也可以用以下命令安装 (使用国内镜像会更快一点) npm install -g cnpm --registry=https://registry.npm.taobao.org 等待运行完成 最后在 es-head 下就可以启动了，执行如下命令 grunt server 启动es 找到 es 安装目录下面的 bin目录，双击 elasticsearch.bat 既可 访问http://localhost:9100就可以访问head插件了。 备注： 1.启动es-head插件命令 grunt server 2.启动es 找到es/bin下面的es.bat 既可 参考链接：https://blog.csdn.net/qq_28988969/article/details/78856599","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://www.devcheng.net/tags/ElasticSearch/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"@Inject和@Autowired以及@Resource区别","slug":"Inject和-Autowired以及-Resource区别","date":"2019-02-14T14:40:44.000Z","updated":"2020-01-04T04:00:02.696Z","comments":true,"path":"post/ca6a35df.html","link":"","permalink":"http://www.devcheng.net/post/ca6a35df.html","excerpt":"","text":"@Injectjavax.inject JSR330 (Dependency Injection for Java) 这是jsr330中的规范，通过AutowiredAnnotationBeanPostProcessor类实现的依赖注入。 @Inject使用如下是@Inject的使用，不加@Named注解，需要配置与变量名一致即可。123@Inject@Named(\"mongo\")private Mongo mongo; @Autowiredorg.springframework.bean.factory Spring @Autowired是Spring提供的注解，通过AutowiredAnnotationBeanPostProcessor 类实现的依赖注入，与@inject二者具有可互换性。 @Autowired的使用@Autowired有个属性为required，可以配置为false，如果配置为false之后，当没有找到相应bean的时候，系统不会抛错.12@Autowiredprivate MongoTemplate mongoTemplate; @Resourcejavax.annotation JSR250 (Common Annotations for Java) 这是jsr250规范的实现，@Resource通过 CommonAnnotationBeanPostProcessor类实现依赖注入。 @Resource的使用@Resource一般会指定一个name属性，如下：12@Resource(name = \"userMapper\")private UserMapper userMapper; 三个注解的相异之处 @Autowired和@Inject基本是一样的，因为两者都是使用AutowiredAnnotationBeanPostProcessor来处理依赖注入。但是@Resource是个例外，它使用的是CommonAnnotationBeanPostProcessor来处理依赖注入。当然，两者都是BeanPostProcessor。 @Autowired和@Inject 默认 autowired by type 可以 通过@Qualifier 显式指定 autowired by qualifier name。 @Resource 默认 autowired by field name 如果 autowired by field name失败，会退化为 autowired by type 可以 通过@Qualifier 显式指定 autowired by qualifier name 如果 autowired by qualifier name失败，会退化为 autowired by field name。但是这时候如果 autowired by field name失败，就不会再退化为autowired by type了。 总结个人在使用上，更偏重使用@Inject，这是jsr330规范的实现，而@Autowired是spring的实现，如果不用spring一般用不上这个，而@Resource则是jsr250的实现，这是多年前的规范。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Inject","slug":"Inject","permalink":"http://www.devcheng.net/tags/Inject/"},{"name":"Autowired","slug":"Autowired","permalink":"http://www.devcheng.net/tags/Autowired/"},{"name":"Resource","slug":"Resource","permalink":"http://www.devcheng.net/tags/Resource/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Java 10的功能和增强功能","slug":"Java-10的功能和增强功能","date":"2019-01-27T12:20:39.000Z","updated":"2020-01-04T04:00:25.089Z","comments":true,"path":"post/5322594a.html","link":"","permalink":"http://www.devcheng.net/post/5322594a.html","excerpt":"","text":"摘要在Java 9发布之后，Java 10很快就出现了。与之前的版本不同，Java 10没有那么多令人兴奋的功能，但它几乎没有重要的更新可以改变您的编码方式，以及其他未来的Java版本。 JEP 286：局部变量类型推断Java现在有var样式声明。它允许您声明局部变量而不指定其类型。变量的类型将从创建的实际对象的类型推断出来。它声称是JDK 10中开发人员唯一真正的功能。例如 Application.java123456var str = \"Hello world\"; //or String str = \"Hello world\"; 在上面的例子中，两个语句都是等价的。在第一个语句中，类型str由类型的赋值String类型决定。 JEP 322：基于时间的发布版本控制从Java 10开始，Oracle已经采用了基于时间的版本字符串方案。版本号的新格式为： $FEATURE.$INTERIM.$UPDATE.$PATCH 与旧版本不同，新的基于时间的版本不会延迟，功能将每六个月发布一次，不会限制版本中的功能。 还有长期版本（LTS）。它主要面向企业客户。LTS版本的产品将提供Oracle的一流和持续支持，并将每三年定位一次。此外，这些版本的更新将至少提供三年。 JEP 304：垃圾收集器接口在早期的JDK结构中，构成垃圾收集器（GC）实现的组件分散在代码库的各个部分中。它在Java 10中发生了变化。现在，它是JVM源代码中的一个干净的接口，可以快速，轻松地集成替代收集器。它将改善不同垃圾收集器的源代码隔离。 这纯粹是重构。以前工作的所有东西都需要在之后工作，性能不应该回归。 JEP 307：G1的并行全GCJava 9引入了G1（垃圾优先）垃圾收集器。G1垃圾收集器旨在避免完整集合，但是当并发集合无法足够快地回收内存时。通过此更改，将发生后退完整GC。 G1的完整GC的当前实现使用单线程标记 - 扫描 - 紧凑算法。此更改将并行化mark-sweep-compact算法并使用相同数量的线程。当收集的并发线程无法足够快地恢复内存时，它将被触发。 可以通过-XX:ParallelGCThreads选项控制线程数。 JEP 316：备用内存设备上的堆分配此更改的目标是使HotSpot VM能够在另一个内存设备（例如用户指定的NV-DIMM）上分配Java对象堆。 要在这样的内存中分配堆，我们可以添加一个新选项-XX:AllocateHeapAt=&lt;path&gt;。此选项将采用文件系统的路径并使用内存映射来实现在内存设备上分配对象堆的所需结果。现有的堆相关标志（如-Xmx，-Xms等）和垃圾收集相关标志将继续像以前一样工作。 JEP 296：将JDK Forest整合到单个存储库中作为此更改的一部分，JDK林的大量存储库被组合到单个存储库中，以简化和简化开发。 在JDK 9有八个回购：root，corba，hotspot，jaxp，jaxws，jdk，langtools，和nashorn。在统一林中，Java模块的代码通常组合在单个顶级src目录下。例如，今天在JDK林中有基于模块的目录，如1234$ ROOT/JDK/src/java.base...$ ROOT/langtools/src/java.compiler... 在整合的林中，此代码组织为 -123$ ROOT/src/java.base$ ROOT/src/java.compiler... JEP 310：应用程序类 - 数据共享此功能的目标是改善启动占用空间，扩展现有的类 - 数据共享（“CDS”）功能，以允许将应用程序类放在共享存档中。 JDK 5中引入的类数据共享允许将一组类预处理为共享存档文件，然后可以在运行时进行内存映射以减少启动时间。当多个JVM共享同一个归档文件时，它还可以减少动态内存占用。 目前，CDS仅允许引导类加载器加载存档类。Application CDS允许内置系统类加载器，内置平台类加载器和自定义类加载器来加载归档类。 指定-XX:+UseAppCDS命令行选项以为系统类加载器，平台类加载器和其他用户定义的类加载器启用类数据共享。 JEP 314：其他Unicode语言标记扩展它的目标是增强java.util.Locale和相关的API，以实现BCP 47语言标签的其他Unicode扩展。最初在Java SE 7中添加了对BCP 47语言标记的支持，支持Unicode语言环境扩展仅限于日历和数字。此JEP将在相关的JDK类中实现最新LDML规范中指定的更多扩展。 此JEP将添加对以下附加扩展的支持： cu (currency type) fw (first day of week) rg (region override) tz (time zone) 修改后的相关API包括：123456789101112java.text.DateFormat::get*Instancejava.text.DateFormatSymbols::getInstancejava.text.DecimalFormatSymbols::getInstancejava.text.NumberFormat::get*Instancejava.time.format.DateTimeFormatter::localizedByjava.time.format.DateTimeFormatterBuilder::getLocalizedDateTimePatternjava.time.format.DecimalStyle::ofjava.time.temporal.WeekFields::ofjava.util.Calendar::&#123;getFirstDayOfWeek,getMinimalDaysInWeek&#125;java.util.Currency::getInstancejava.util.Locale::getDisplayNamejava.util.spi.LocaleNameProvider JEP 319：根证书cacerts密钥库是JDK的一部分，旨在包含一组根证书，这些证书可用于在各种安全协议中使用的证书链中建立信任。但是，JDK源代码中的cacerts密钥库目前是空的。 cacerts密钥库将填充由Oracle Java SE根CA程序的CA颁发的一组根证书。许多供应商已经签署了所需的协议，并且每个供应商都会签署一份将包含的根证书列表。那些未签署协议的人目前不会被包括在内。那些需要更长时间处理的内容将包含在下一个版本中。 这也意味着Oracle和Open JDK二进制文件在功能上都是相同的。诸如TLS之类的关键安全组件将在未来的OpenJDK构建中默认工作。 JEP 317：基于实验Java的JIT编译器此功能使基于Java的JIT编译器Graal可用作Linux / x64平台上的实验性JIT编译器。Graal将使用JDK 9中引入的JVM编译器接口（JVMCI）.Graal已经在JDK中，因此将其作为实验性JIT启用将主要是测试和调试工作。 要将Graal作为JIT编译器启用，请在java命令行上使用以下选项： -XX：+ UnlockExperimentalVMOptions -XX：+ UseJVMCICompilerGraal是从头开始用Java完全重写JIT编译器。以前的JIT编译器是用C ++编写的。 JEP 312：线程局部握手此JEP通过在应用程序线程上执行回调而无需执行全局VM安全点，为改进VM性能奠定了基础。这意味着JVM可以阻止单个线程，而不仅仅是所有线程。 线程局部握手最初将在x64和SPARC上实现。其他平台将回归正常的安全点。新产品选项-XX:ThreadLocalHandshakes（默认值true）允许用户在支持的平台上选择正常安全点。 JEP 313：删除Native-Header生成工具它将javah从JDK中删除该工具，JDK是一个单独的工具，用于在编译JNI代码时生成头文件，因为这可以通过完成javac。 这是另一个Java 10功能，专注于内务管理。 新增的API和选项在Java 10中添加了73个新的API。让我们来看看它们中的一些： API 描述 Optional.orElseThrow() A new method orElseThrow has been added to the Optional class. It is synonymous with and is now the preferred alternative to the existing get method. List.copyOf, Set.copyOf, and Map.copyOf These methods create new collection instances from existing instances. Collectors.toUnmodifiableList，Collectors.toUnmodifiableSet，Collectors.toUnmodifiableMap These methods allow the elements of a Stream to be collected into an unmodifiable collection –jdk.disableLastUsageTracking To disable JRE last usage tracking for a running VM. –add-stylesheet Provides support for the use of multiple stylesheets in the generated documentation. –main-stylesheet To help distinguish the main stylesheet from any additional stylesheets. @summary Tag Added to explicitly specify the text used as the summary of the API description. By default, the summary of an API description is inferred from the first sentence. 删除了API和选项 API 描述 LookAndFeels Runtime.getLocalizedInputStream， Runtime.getLocalizedOutputStream Part of an obsolete internationalization mechanism and have no known uses. RMI Server-Side Multiplex Protocol Support It was disabled in JDK 9 and, now, has been removed. Common DOM APIs The com.sun.java.browser.plugin2.DOM, and sun.plugin.dom.DOMObject APIs have been removed. Applications can use netscape.javascript.JSObject to manipulate the DOM. FlatProfiler Deprecated in JDK 9, has been made obsolete by removing the implementation code. -Xoss, -Xsqnopause, -Xoptimize, -Xboundthreads, and -Xusealtsigs Options removed. policytool The policytool security tool has been removed from the JDK. Deprecated Classes in com.sun.security.auth.** Following classes are removed now com.sun.security.auth.PolicyFile com.sun.security.auth.SolarisNumericGroupPrincipal com.sun.security.auth.SolarisNumericUserPrincipal com.sun.security.auth.SolarisPrincipal com.sun.security.auth.X500Principal com.sun.security.auth.module.SolarisLoginModule com.sun.security.auth.module.SolarisSystem 总体而言，Java 10具有许多我们可能不会在日常编程中使用的功能，但它仍然具有许多功能，这些功能在幕后工作以使其成为重要的里程碑。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Java10","slug":"Java10","permalink":"http://www.devcheng.net/tags/Java10/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"最喜欢Spring Boot的6个功能","slug":"最喜欢Spring-Boot的6个功能","date":"2019-01-19T11:03:15.000Z","updated":"2020-01-04T04:05:10.672Z","comments":true,"path":"post/f6b323e3.html","link":"","permalink":"http://www.devcheng.net/post/f6b323e3.html","excerpt":"","text":"前言使用Spring Boot有一段时间了，从最开始的陌生到上手使用，不得不对Spring Boot给一个大大的赞。 两年前，当我为门铃应用程序构建后端时，我认为试用Docker可能是不错的选择。我很快意识到构建一个部署在Tomcat或Jetty中的传统WAR应用程序的意义不大，我首先看一下Spring Boot提供的内容。 事实证明，很多功能都很棒！ 以下是我最喜欢的6个功能，完全适合现代微服务环境。 外部化配置 (Externalised configuration)这不是一件特别大的事情，但它是一个往往被新人忽视的功能，它可能非常有用。Spring Boot非常灵活，并且在此版本中有详细记录。举个栗子，你可以选择使用ENVIRONMENT_VARIABLES，–command-line-arguments 或者 -Dsystem.properties，最终会在你的字段中注入，如下所示：12@Value(\"$&#123;password&#125;\")private String password; Actuator为了让你获得生产准备，Spring创建了Actuator。对于真正的生产就绪应用程序，你需要能够在应用程序所服务的任何用户面向界面之外查看应用程序。其中一项是健康检查，这很容易自己创建。1234567891011public class MyService extends AbstractHealthIndicator &#123;… @Override protected void doHealthCheck(Health.Builder builder) throws Exception &#123; final String echo = pushNotifier.echo(\"Abcd\"); if (!echo.equals(\"\\\"dcbA\\\"\")) &#123; throw new RuntimeException(\"Response mismatch. Was \" + echo); &#125; builder.up(); &#125;&#125; builder.up()会告诉你的每一builder.down()件事都很好，同时抛出一个例外，或者会告诉某些事情是不对的。添加.withDetail(“…”)以提供更多信息。最后，可以访问应用程序的运行状况 http: //localhost:8080/health。 此外，配置之类的东西可以通过HTTP端点公开。是的，包含受保护事物的常用词的键将被删除。 Fat jarsFat jars不是新鲜事物。我在这里提到它们的原因是它们是使用Docker镜像的一个非常好的替代品。 对，你没有看错,这里说的是Docker的替代品吗！！！ 它与Docker本身无关，但正如LinkedIn前段时间透露的那样，cgroup会在垃圾收集过程中造成异常长的暂停。此外，有时分发简单文件比替代方案容易得多。谁说共享NFS卷包含所有主机上的所有jar文件？或者一些现代的点对点文件共享是一件坏事吗？ Spring提供了一个很好的Maven插件，可以为你提供一切。如果你使用Spring Initializr，它就会为你设置。 自动配置(Auto configuration)约定优于配置。 Java是一种静态和老式的语言，你可以点击你的方式（假设你没有像Emacs这样的东西）。只需看一下org.springframework.boot.autoconfigure.SpringBootApplication 注释。除此之外，它还会导入另外两个注释 12345@EnableAutoConfiguration@ComponentScan(excludeFilters = @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class))public @interface SpringBootApplication &#123; …&#125; 首先，@ComponentScan只要为它们提供通常的@Component注释，就可以扫描当前包和所有子包中的bean 。 @EnableAutoConfiguration稍微复杂一点，但基本上它会确保Spring扫描所有spring.factories属性文件的类路径，这反过来又指向Spring配置注释类。同样，如果这对你来说太神奇了，为你的应用程序提供一个DEBUG=true环境变量来获取实际情况的报告。 Feign Integration你可能听说过Netflix。这是一家视频流媒体公司，但事实证明他们也做了很多不错的技术，甚至更好，他们是开源的。其中一个组件是Feign。Feign基本上是一个HTTP客户端。没什么好奇的，我们已经有很多关于Java的东西了，我对图书馆本身并不是很自以为是，但它很好地融入了Spring。所以基本上，你首先org.springframework.cloud:spring-cloud-starter-feign从Maven Central 添加依赖项。但是为什么他们没有添加自动配置是超出我的。无论如何，只需添加一个 EnableFeignClients配置类。HTTP客户端本身看起来像这样：1234interface Demo&#123; @RequestLine(\"GET /repos/&#123;owner&#125;/&#123;repo&#125;/contributors\") List&lt;Contributor&gt; contributors(@Param(\"owner\") String owner, @Param(\"repo\") String repo);&#125; Feign Integration是Spring Cloud项目的一部分，它还会为你提供断路器，重试和最终指标。 Git commit id能够看到你实际运行的应用程序的有哪些版本,如果你添加git-commit-id-pluginmaven插件和Spring Actuator，那么确切的git commit id将通过/info 执行器端点输出。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.devcheng.net/tags/Spring-Boot/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"数据库中为什么不推荐使用外键约束","slug":"数据库中为什么不推荐使用外键约束","date":"2019-01-17T14:01:09.000Z","updated":"2020-01-04T04:04:38.186Z","comments":true,"path":"post/91322b0c.html","link":"","permalink":"http://www.devcheng.net/post/91322b0c.html","excerpt":"","text":"前言 这个话题也是老生常谈，现在很多人在工作中确实也不会使用外键。包括在阿里的JAVA规范中也有下面这一条： 【强制】不得使用外键与级联，一切外键概念必须在应用层解决。 但是呢，询问他们原因，大多是这么回答的：每次做DELETE 或者UPDATE都必须考虑外键约束，会导致开发的时候很痛苦,测试数据极为不方便。 坦白说，这么说也是对的。但是呢，不够全面，所以开一文来详细说明。 正文首先我们明确一点，外键约束是一种约束，这个约束的存在，会保证表间数据的关系“始终完整”。因此，外键约束的存在，并非全然没有优点。比如使用外键，可以： 保证数据的完整性和一致性； 级联操作方便； 将数据完整性判断托付给了数据库完成，减少了程序的代码量； 然而，鱼和熊掌不可兼得。外键是能够保证数据的完整性，但是会给系统带来很多缺陷。正是因为这些缺陷，才导致我们不推荐使用外键，具体如下： 性能问题假设一张表名为user_tb。那么这张表里有两个外键字段，指向两张表。那么，每次往user_tb表里插入数据，就必须往两个外键对应的表里查询是否有对应数据。如果交由程序控制，这种查询过程就可以控制在我们手里，可以省略一些不必要的查询过程。但是如果由数据库控制，则是必须要去这两张表里判断。 并发问题在使用外键的情况下，每次修改数据都需要去另外一个表检查数据,需要获取额外的锁。若是在高并发大流量事务场景，使用外键更容易造成死锁。 扩展性问题这里主要是分为两点： 做平台迁移方便，比如你从Mysql迁移到Oracle，像触发器、外键这种东西，都可以利用框架本身的特性来实现，而不用依赖于数据库本身的特性，做迁移更加方便。 分库分表方便，在水平拆分和分库的情况下，外键是无法生效的。将数据间关系的维护，放入应用程序中，为将来的分库分表省去很多的麻烦。 技术问题使用外键，其实将应用程序应该执行的判断逻辑转移到了数据库上。那么这意味着一点，数据库的性能开销变大了，那么这就对DBA的要求就更高了。很多中小型公司由于资金问题，并没有聘用专业的DBA，因此他们会选择不用外键，降低数据库的消耗。 相反的，如果该约束逻辑在应用程序中，发现应用服务器性能不够，可以加机器，做水平扩展。如果是在数据库服务器上，数据库服务器会成为性能瓶颈，做水平扩展比较困难。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.devcheng.net/tags/数据库/"},{"name":"外键约束","slug":"外键约束","permalink":"http://www.devcheng.net/tags/外键约束/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"BeanUtils.copyProperties()用法及区别","slug":"BeanUtils-copyProperties-用法及区别","date":"2019-01-05T06:19:50.000Z","updated":"2020-01-04T03:58:57.619Z","comments":true,"path":"post/1845fd74.html","link":"","permalink":"http://www.devcheng.net/post/1845fd74.html","excerpt":"","text":"BeanUtils简述 BeanUtils提供对Java反射和自省API的包装。其主要目的是利用反射机制对JavaBean的属性进行处理。如果一个JavaBean通常包含了大量的属性，很多情况下，对JavaBean的处理导致大量get/set代码堆积，增加了代码长度和阅读代码的难度。 BeanUtils.copyProperties() 用法这两个类在不同的包下面，而这两个类的copyProperties()方法里面传递的参数赋值是相反的。详细的看下文描述: 例如： a,b为对象 BeanUtils.copyProperties(a, b); 在org.springframework.beans.BeanUtils里面结果为：a拷贝到b看内部方法定义代码:12345public static void copyProperties(Object source, Object target) throws BeansException &#123; copyProperties(source, target, null, (String[])null); &#125; tips : source 源文件，target 目标文件 在org.apache.commons.beanutils.BeanUtils里面 结果为：b拷贝到a看内部方法定义代码：12345public static void copyProperties(Object dest, Object orig) throws IllegalAccessException, InvocationTargetException &#123; BeanUtilsBean.getInstance().copyProperties(dest, orig); &#125; tips: dest（英译：“蒸馏”，可理解为空白文件，目标文件），original原始的，源文件。 由以上得知，引用包出处不一样，意思就不一样，使用时需要注意的是哪个包下面的。","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"BeanUtils.copyProperties","slug":"BeanUtils-copyProperties","permalink":"http://www.devcheng.net/tags/BeanUtils-copyProperties/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"JDK1.8的几个新特性你知道多少","slug":"JDK1-8的几个新特性你知道多少","date":"2019-01-04T13:54:22.000Z","updated":"2020-01-04T04:01:02.008Z","comments":true,"path":"post/42432443.html","link":"","permalink":"http://www.devcheng.net/post/42432443.html","excerpt":"","text":"前言在本篇博文中，将简单的介绍一下Java 8中 concat，count，sorted ，distinct stream API 的代码例子。 Stream.concatconcat() 是Stream API中的一个静态方法。它连接两个流对象并返回结果流对象。在我们的示例中，我们有两个列表，它们被转换为流，然后连接起来。123456789101112package com.concretepage.util.stream;import java.util.Arrays;import java.util.List;import java.util.stream.Stream;public class ConcatDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list1 = Arrays.asList(\"A1\",\"A2\",\"A3\"); List&lt;String&gt; list2 = Arrays.asList(\"B1\",\"B2\",\"B3\"); Stream&lt;String&gt; resStream = Stream.concat(list1.stream(), list2.stream()); resStream.forEach(s-&gt;System.out.println(s)); &#125;&#125; 运行结果，如下：123456A1A2A3B1B2B3 Stream.countcount() 方法只计算流对象中的元素。它返回长值。在我们的代码示例中，我们有一个列表，将其转换为流，然后对其应用count方法。 123456789101112package com.concretepage.util.stream;import java.util.Arrays;import java.util.List;import java.util.function.Predicate;public class CountDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList(\"AA\",\"AB\",\"CC\"); Predicate&lt;String&gt; predicate = s-&gt; s.startsWith(\"A\"); long l= list.stream().filter(predicate).count(); System.out.println(\"结果为:\"+l); &#125;&#125; 运行结果，如下：1结果为:2 Stream.sortedstream api中的sorted() 法根据自然顺序对stream元素进行排序。我们还可以通过comparator对象来获取自定义排序。 123456789package com.concretepage.util.stream;import java.util.Arrays;import java.util.List;public class SortedDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList(\"DC\",\"CD\",\"AD\"); list.stream().sorted().forEach(s-&gt;System.out.println(s)); &#125;&#125; 运行结果：123ADCDDC Stream.distinctStream API中的distinct（）方法返回带有distinct元素的流。distinct元素由对象类的equal方法决定。12345678910package com.concretepage.util.stream;import java.util.Arrays;import java.util.List;public class DistinctDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList(\"AA\",\"AA\",\"BB\"); long l = list.stream().distinct().count(); System.out.println(\"结果为:\"+l); &#125;&#125; 运行结果：1结果为：2 更多的jdk8 新特性以后用到了，还会继续写对应的博文记录，本篇就暂时记录这些，如果疑问欢迎留言一起探讨！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"JDK1.8","slug":"JDK1-8","permalink":"http://www.devcheng.net/tags/JDK1-8/"},{"name":"新特性","slug":"新特性","permalink":"http://www.devcheng.net/tags/新特性/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"MySQL无法保存emoji表情的终极解决方案","slug":"MySQL无法保存emoji表情的终极解决方案","date":"2018-12-22T05:30:35.000Z","updated":"2020-01-04T04:01:11.874Z","comments":true,"path":"post/85862eef.html","link":"","permalink":"http://www.devcheng.net/post/85862eef.html","excerpt":"","text":"问题背景在公司里面需要做一个留言板的功能，拿到产品的需求三下五除二的就把表结构就设计出来了，在以往的开发经验中毫无疑问的就把表字符集设置为了utf8。于是就碰到在留言中一旦含有emoji表情的就无法保存到数据库里，就会提示下面这个异常：1java.sql.SQLException: Incorrect string value: '/xF0/x9F/x92/x94' for colum n 'content' at row 1at 问题的前世今生在最开始设计表结构的时候，采用的 utf8在MySQL中的 utf8 最多支持的是3个字节，而我们要保存的emoji表情是4个字节，所以就保存不到数据库里面。 经过一番查询资料，我们只要更改字符编码即可，那问题又来了，更改字符编码选择哪一个呢？ 认识 utf8md4MySQL在5.5.3之后增加了这个utf8mb4的编码，mb4就是most bytes 4的意思，它专门用来兼容四字节的unicode。好在utf8mb4是utf8的超集，除了将编码改为utf8mb4外不需要做其他转换。当然，为了节省空间，一般情况下使用utf8也就足够了。 MySQL无法保存emoji表情的终极解决方案 MySQL 配置文件修改找你安装Mysq路径下的配置文件my.ini 或者是default.ini 配置文件，修改一下内容。1234[mysql] default-character-set=utf8mb4 [mysqld] character-set-server=utf8mb4 修改完成后，记得重启mysql ！ 修改 数据库的字符集可以使用MySQL客户端连接数据库，修改数据库的字符集utf8mb4 – UTF-8 Unicode 修改 表的字符集 和 对应字段的字符集utf8mb4 做完以上的修改之后，可以现在对应的字段中保存一个emoji表情实验一下，看能否保存成功。如果能保存成功则说明我们设置正确了！ 确保MySQL connection的版本 ，连接串确认MySQL connection要高于5.1.13 否则仍然不能试用utf8mb4。 连接串1spring.datasource.url=jdbc:mysql://localhost:3306/test?characterEncoding=utf8&amp;characterSetResults=utf8&amp;autoReconnect=true&amp;failOverReadOnly=false 在项目中往往都会加上 characterEncoding=utf8 , 如果还不能保存emoji表情，这里也去掉。 以上就是解决方法，如果有不正确的地方，欢迎指出！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.devcheng.net/tags/MySQL/"},{"name":"emoji表情","slug":"emoji表情","permalink":"http://www.devcheng.net/tags/emoji表情/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"Java基础面试题之值传递","slug":"Java基础面试题之值传递","date":"2018-12-20T13:19:54.000Z","updated":"2020-01-04T04:00:48.184Z","comments":true,"path":"post/34d2bb5f.html","link":"","permalink":"http://www.devcheng.net/post/34d2bb5f.html","excerpt":"","text":"两个关于值传递面试问题1.java中是值传递还是引用传递？2.值传递和引用传递的区别是什么？ 这两个问题，在一般的面试过程中很容易问到，无论你是去应聘初级，中级还是高级程序员。在现实生活中，往往工作时间久的程序员很容易忽略这些基础面试题。一个不小心就在阴沟里面翻了船… 以上两个问题，大家可以自行去问度娘或谷歌了。除了以上两个问题，部分公司会以书面的笔试题出对应的试题，请看下面： 几个关于值传递笔试问题 第一题12345678910public class Test1 &#123; public static void change(int a)&#123; a=50; &#125; public static void main(String[] args) &#123; int a=10; change(a); System.out.println(a); &#125;&#125; 问题： 输出的 a 为多少？ 第二题12345678910public class Test2 &#123; public static void change(int []a)&#123; a[0]=50; &#125; public static void main(String[] args) &#123; int []a=&#123;10,20&#125;; change(a); System.out.println(a[0]); &#125;&#125; 问题： 这里输出的 a 为多少？ 3.第三题123456789101112131415161718class Emp &#123; public int age;&#125;public class Test3 &#123; public static void change(Emp emp) &#123; emp.age = 50; emp = new Emp(); emp.age=100; &#125; public static void main(String[] args) &#123; Emp emp = new Emp(); emp.age = 100; change(emp); System.out.println(emp.age); &#125;&#125; 问题： 这里输出的 emp.age 为多少？ 4.第四题12345678910111213141516class Emp &#123; public int age;&#125;public class Test4 &#123; public static void change(Emp emp) &#123; emp.age=100; &#125; public static void main(String[] args) &#123; Emp emp = new Emp(); emp.age = 50; change(emp); System.out.println(emp.age); &#125;&#125; 问题： 注意看代码啊，这里输出的 emp.age 又又是多少？ 5.第五题1234567891011public class Test5 &#123; public static void change(String s)&#123; s=\"zhangsan\"; &#125; public static void main(String[] args) &#123; String s=new String(\"lisi\"); change(s); System.out.println(s); &#125;&#125; 问题： 最后的输出的字符串是啥？ 小声说一句 Java中只存在值传递，只存在值传递！！！ 如果你有兴趣，请把你做的结果留言出来哦！","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.devcheng.net/tags/Java/"},{"name":"值传递","slug":"值传递","permalink":"http://www.devcheng.net/tags/值传递/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"rabbitmq学习教程","slug":"rabbitmq学习教程","date":"2018-12-10T10:55:30.000Z","updated":"2020-01-04T04:01:54.600Z","comments":true,"path":"post/c9d5cd3b.html","link":"","permalink":"http://www.devcheng.net/post/c9d5cd3b.html","excerpt":"","text":"rabbitmq学习教程花了一段时间，写了一个自己在学习rabbitmq的入门学习教程。总共有6个章节，每一个章节都有对应的一个知识点，并且包含了代码。 内容预览 第一章介绍了rabbitmq,如何在windows环境中安装，配置等等 第二章接触入门模式 “hello world” 第三章学习Work queues模式 第四章学习Publish/Subscribe (发布订阅模式） 第五章学习路由模式（Routing） 第六章学习广播订阅模式（topic） 学习教程中的代码托管地址：https://git.dev.tencent.com/yicheng2018/rabbitmq_demo.git","categories":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://www.devcheng.net/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://www.devcheng.net/tags/消息队列/"}],"keywords":[{"name":"codeshare","slug":"codeshare","permalink":"http://www.devcheng.net/categories/codeshare/"}]},{"title":"月薪8K和月薪30K的程序员差距在哪","slug":"月薪8K和月薪30K的程序员差距在哪","date":"2018-12-07T09:55:44.000Z","updated":"2020-01-04T04:04:56.345Z","comments":true,"path":"post/32452853.html","link":"","permalink":"http://www.devcheng.net/post/32452853.html","excerpt":"","text":"写在前面同样是程序员，有人月薪8k有人月薪30k，从数字上看确实差距蛮大的。月薪30000，是不是看得大家都掉口水，甚至有改行做程序猿的想法。千万不要轻易入坑!做程序员的时间长了，总是会出现：脾气暴躁，无法进行有效的沟通，使用易于误解的专业术语，对自己的事情处理不好。心情狂躁的时候，甚至会有砸键盘、砸电脑的冲动。而且，能拿到月薪30k的程序猿只是少数人。 刚入职时普通程序员：只看重工资的高低，不注重发展空间、个人成长，没有想过学习丰富的工作经验和职业技能，习惯即可汇报。优秀程序员：相信只要有丰富的经验，以后无论到哪都能赢得高薪，踏踏实实的去学习，提升业务技能。 对待问题普通程序员：在工作中会发现各种各样的问题，他们往往以抱怨的态度去对待，而没有想方法去解决，积极应对，甚至找出最佳方案去优化。优秀程序员：在工作过程中，碰到问题会冷静的分析原因，并通过各种手段去解决，慢慢培养了一种解决问题的思维和能力。 对于执行普通程序员：对于交代的问题本着能做就做，不能做就慢慢磨，执行效果较差，消极，无时间观念。或者只知道一味的执行。优秀程序员：上司交代的事情积极去解决，遇到问题会积极与上司沟通请示，及时反馈进度，按时甚至提前完成。 对于班后普通程序员：往往通过看电视、打打游戏等方式度过，认为上班时做工作，下班就该享受生活，缺乏学习热情。优秀程序员：下班后会抽出时间回顾今天一天的工作内容，反思不足之处，并规划好第二天的工作内容。同时花一定时间学习，给自己充电。 对于规划普通程序员：没有职业规划，得过且过，无所谓，没有思后顾之忧。优秀程序员：有自己的职业规划，知道自己想要什么，也知道如何去努力，实现。 综上所述，8000与30000的差距还是有好多因素的，要想拿30000的高薪，不仅仅是埋头码代码，还要抬头看方向，在实战中不停提升自己的学习力、竞争力，找到好的平台，才能摆脱薪资低、工作量又大的情况。","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"程序员","slug":"程序员","permalink":"http://www.devcheng.net/tags/程序员/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"浅谈程序员该如何自我成长","slug":"浅谈程序员该如何自我成长","date":"2018-11-17T13:06:17.000Z","updated":"2020-01-04T04:04:04.561Z","comments":true,"path":"post/252ff1d1.html","link":"","permalink":"http://www.devcheng.net/post/252ff1d1.html","excerpt":"","text":"对于程序员该如何自我成长，这是一个人人都能掺和话题，作为一名在坑里挣扎了五年的码农，我也一直在探索、一直在思考、一直在总结，作为一名码农到底该怎么成长，不再被35岁这个魔咒所恐吓。 提前规划未来几年的职业发展在最开始的时候看清楚自己想要做什么，沉下心去做一件事。如果没有的话，光看着别人打怪升级，不断地学到新的知识，那时候你就会变得很焦虑。其实，最重要的是，怎么能够在未来的时间里真正充实自己，让自己真正学到东西。制定一个职业规划，则就确保了自己的方向，只要方向是对的，结果就不会是错的。 不断的学习做为程序员，一旦停止学习就会被淘汰。之前在群里比较流行一张图片，大体内容就是某种语言一直在更新迭代，有位比较滑稽的网友就提了一个issues说到“求不要更新了，老子学不动了”。这也说明了一点，在技术领域每一年都有各种各样的技术出现，很多大厂更是有自己的一套技术栈。 利用好业余时间有一大部分人，周末或是下班之后的时间都会选择看看电视，玩游戏等娱乐去了。当然这里不是说下班之后就不能娱乐，这里而是推荐大家利用好业余时间去学习或是认知工作以外的一些新技术。 善于总结成长的路上，什么时候才是真的成长呢？举个栗子，最开始遇到的这个问题，各种谷歌各种度娘折腾了半天解决了这个问题，如果把这个过程用自己的方式总结下来，下次或未来遇到类似的有一个借鉴的方法。能让自己快速的解决掉这个问题，这就是成长的表现。 最直接的方式，就是用语(bo)言(ke)记录下来，古人言：好记性，不如烂笔头。 建立人脉有一个说法叫幸运三连。 上学时遇到一位好老师；工作时遇到一位好师傅；成家时遇到一个好伴侣。 那如何能找到一个好师傅，闻道有先后，一个公司里面总有技术好的，像他们学习。建立良好的人脉关系，在工作中遇到什么困难也能提到事半功倍。 小结成长之路没有捷径只有自己一点一滴的学习，一点一滴的付出，才有成长。","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"程序员成长","slug":"程序员成长","permalink":"http://www.devcheng.net/tags/程序员成长/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]},{"title":"博客SEO优化之链接持久化","slug":"博客SEO优化之链接持久化","date":"2018-10-06T09:52:40.000Z","updated":"2020-01-04T04:03:01.816Z","comments":true,"path":"post/55553214.html","link":"","permalink":"http://www.devcheng.net/post/55553214.html","excerpt":"","text":"未优化方案我们都知道，使用hexo编译的站点打开文章的url是：sitename/year/mounth/day/title四层的结构，这样的url结构很不利于seo，爬虫就会经常爬不到我们的文章，所以，有的博客给的解决方案是： 将url直接改成sitename/title的形式，并且title最好是用英文，在根目录的配置文件下。具体修改permalink如下：12345678# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://www.devcheng.netroot: /#permalink: :year/:month/:day/:title/#permalink: :posts/:category/:year-:month-:day-:title.htmlpermalink: title.htmlpermalink_defaults: 这样写的弊端就是，没次写文章的时候你之能写个英文的title，翻阅了其他资料我发现有更好的方法。 推荐方案具体操作如下，使用 hexo-abbrlink这个插件。先安装这个插件，命令如下：1npm install hexo-abbrlink --save 站点配置文件里:1234permalink: post/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 到此就配置完成了，重新新建文章也不用局限于标题了。是一种比较奈斯的方法，值得你这样配置为了你的站点的SEO。可以点击我的博客查看效果-www.devcheng.net","categories":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.devcheng.net/tags/hexo/"},{"name":"seo","slug":"seo","permalink":"http://www.devcheng.net/tags/seo/"}],"keywords":[{"name":"blogshare","slug":"blogshare","permalink":"http://www.devcheng.net/categories/blogshare/"}]},{"title":"伊成博客的第一篇文章","slug":"伊成博客的第一篇文章","date":"2018-10-05T06:37:52.000Z","updated":"2020-01-04T04:04:47.049Z","comments":true,"path":"post/b392f55c.html","link":"","permalink":"http://www.devcheng.net/post/b392f55c.html","excerpt":"","text":"写在前面其实最开始写博客可能是在csdn写的，记得是在2013年开始陆陆续续的写了一些博客。在这个过程中，只是单纯在这个平台记录一下自己工作中的一些问题，解决的过程。 到后来遇到了一个最代码的网站，里面也可以写博客，所以呢在这个平台上也开始写了一些文章。还有一些其他的博客平台，就不一一列举了。 用了这些平台，让我感觉最大的一个“不爽”的地方，就是你发表的一些文章需要审核的，反正就得按照人家的规则走。于是在2015年注册了一个域名买了一个便宜的服务器玩了2年，自己搭建博客。写任何自己想说的话（当然不是违法的言语），这样就觉得没有受制于人了。 就这样从购买域名，网站备案，搭建博客，运营网站。2年时间也学到了很多东西，时间到了之后域名没有续费，在我看来经历一些，成长了，这便是收货。 新想法有一段时间，觉得花了2年时间从入门到了解，为什么不继续坚持下去呢？说白了, emmm … .. .域名加服务器（便宜一点的）这些都是钱哦，所以…后来发现了，有朋友在用github在搭建免费的博客，看了一波资料之后，我也尝试的搭建了一个，但是有一个问题，github 是国外的在国内访问真的很慢，无论你咋去加速。遂弃之.. 新方案既然国外的github 很慢，那有没有更好的方案呢。于是就发现了一个coding，搭建什么的和github 是一样的。所以选用了 hexo + coding 搭建个人博客。对于记录工作中的一些经验，技术是足够了！ 搭建问题小结源码在coding 托管，在腾讯云购的域名，在做域名绑定的时候需要注意一点，在coding里面绑定域名一定要是这样的，举个例子www.devcheng.net, 不能写成 devcheng.net 不然会一只绑定不了，有任何问题可以加入我们的群哦！","categories":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://www.devcheng.net/tags/博客/"}],"keywords":[{"name":"codelife","slug":"codelife","permalink":"http://www.devcheng.net/categories/codelife/"}]}]}